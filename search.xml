<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>ASC20-21回顾 - 大家都〇等于大家都没〇</title>
    <url>/2021/05/15/ASC20-21%E5%9B%9E%E9%A1%BE-%E5%A4%A7%E5%AE%B6%E9%83%BD%E3%80%87%E7%AD%89%E4%BA%8E%E5%A4%A7%E5%AE%B6%E9%83%BD%E6%B2%A1%E3%80%87/</url>
    <content><![CDATA[<p>ASC20好死不死决赛场地就在妮可，痛失旅游机会。祸不单行，ASC20取消，合并为ASC20-21，公费旅游机会-=2。雪上加霜，疫情还顺手把晚宴给整没了。<del>没有机票，酒店，和大吃大喝的比赛能叫比赛吗！</del></p>
<h2 id="day-0">Day 0</h2>
<p>Day0当然是传统艺能——装机的一天。忘了赛前咋规划的了，好像是计划上午要装好机的样子。作为垃圾佬出身的垃圾佬，哦不是，作为垃圾佬出身的运维，装机 应 该 能 分分钟装好，<del>我的装机经验丰富到装烂过一张1080和Xeon Phi（自豪）</del>。结果好家伙，不知道浪潮从哪里捡来这个鬼才设计师，把显卡供电线设计得贼鸡儿短，要大力出奇迹才能把显卡安装在推荐的GPU1和GPU2位置，为了省事我就把显卡装在了GPU1，3位置上了，反正显卡拓扑都差不多，一个NUMA一张卡，理 论 上 没啥问题。</p>
<p>关于装系统的方案，我们从一些人的血的教训以及我自己的血泪史中得出结论，不预装系统到硬盘上。当年我的NAS（垃圾服务器）的硬盘运行在AHCI模式，但HPE的BIOS也是鬼才，读不到AHCI模式下的硬盘的温度（只能读到RAID下的），于是就让风扇狂转。我就把硬盘设置成RAID模式，结果发现硬盘一个区域消失了，报分区表错误，尺寸对不上，最后我不得不把文件拷出来，改模式格式化，再写回去，因此我一直怀疑配RAID阵列有未知的副作用。所以我做了个自动安装的镜像，还整了五个U 盘，这样就能一边装系统，一边装另一台的硬件。</p>
<p>系统装好了，nvidia-smi一看，有一个节点的A100申必消失了。其他队员和浪潮的人老在叭叭说不按推荐的装法是不是会有问题啊，要不要再把显卡的装法改回去啊。我重新插了A100，还是不认卡，吓得我以为刷新了被我害死的硬件的价值的最高记录，7.5w一张的美国金卡还可以买一堆1080了。仔细一看，发现是GPU3位置上的A100认不出，结果挪到GPU2上就认出来了。虽然我坚持认为GPU1，3位装法没问题，暴力装显卡电源线可能伤硬件<del>（更伤手）</del>，但还是把显卡装回1，2位了，<del>（不过这次我不去装显卡线了）</del>，大概只有浪潮知道为什么GPU3位不能装GPU了。<del>（供电缩水了吗？）</del></p>
<p>换好显卡位置了，发现有个节点红星闪闪放光芒，亮红灯，进BMC一看，警告有高速PCIe设备运行在低速模式下。拆机重装，感觉安装Riser的手感怪怪的，排查了一阵子，看到一根线的标签卡在Riser的插槽里。好家伙鬼才设计师，标签贴在哪里不好，非得贴在那根线上，还刚好在那个高度上。</p>
<p>期间，为了能通过无线连接集群，不知道谁直接从学校某处掏出了一个长得非常嚣张的硕大的路由器，因此被其他学校认为我们有滥用主场优势的嫌疑，但这玩意虽然看起来很强，可它是TP-Link啊。</p>
<p>折腾了大半天，到差不多四点了，才准备开始跑HPL。为了给其他队上一课，在气势上不能输，功耗的数值必须要大，直接打算跑五机十卡。按下回车，数秒后，功耗下降了。哦，原来是跳闸了。又开机了，压了功耗，又开始跑了，又跳了。虽然作为东道主，我们早就知道跑到7kw会跳闸，但我们应该没跑到这个数啊，过一阵子才意识到，插线板也需要做 负 载 均 衡。给了两路供电，但前五个节点服务器基本全在吸同一路的电，这才蚌埠住了。</p>
<p>跳闸是小事，但不知道为什么BeeGFS好像没见过这种场面，在跳闸之后就很难抢救回来了，折腾了半天，还是没治，放弃治疗了。求稳还是得看NFS，什么BeeGFS，Ceph这种花里胡哨的还是得爬。NFS唯一的毛病就是在存储节点的NFS服务重启的时候，其他的节点一挂载就崩了。我们有另一个运维来管理存储节点，我管理其他的。因为他懒得写好fstab去自动挂载一块xfs盘，每次重启后都要手动mount一下再重启一次NFS服务，在这个期间我只要挂载NFS盘就能触发经典Race condition。这种情况居然连续出现了两次，一崩就重启，重启完就Race condition崩了。最后我按着他的头老老实实把fstab写好了，这样就没必要重启NFS服务了。</p>
<p>插曲：妮可食堂又开始丢人了，这整的什么盒饭啊。THU队上来就问外卖怎么点，SJTU的队员指着饭盒说：你们平时吃的就这？后来才知道这些盒饭是教工食堂整出来的玩意（AP以下的教工还挺惨），由于被吐槽过多，计算中心直接跟食堂说你们别整那些水果饮料了，把饭做好吃点吧。总之这四天成为了我这学期吃得最健康的几天。不知道是不是我在采访里喷饭堂的言论被副校长看到了，他还打了个电话问计算中心大家吃得怎么样。答曰，没出事。</p>
<figure>
<img data-src="/images/pasted-70.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>由于嫌弃Grafana太重了，（主要是不会配），晚上在手搓Dashboard，硬是用DHTMLX搓出了一个还看得过去的面板，用Flask和 文 件 系 统 数 据 库 <del>（一个json文件存数据）</del>搓了一个简单的后端，并部署到了一块Jetson Nano上。至于什么网页端的功耗控制，明年再写吧。现场写了几个破烂脚本去手动调功耗和风扇速度，再用clusterssh手动执行。至于自动功耗控制，不存在的。</p>
<figure>
<img data-src="/images/pasted-71.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<center>
<i>什么NODE，DETAIL，CONSOLE都是不存在的！</i>
</center>
<h2 id="day-1">Day 1</h2>
<p>Day 1是最后一天装机配环境的日子了，Day 2以后就是正式比赛，不能重启超功耗了。开机，IP全变了，不知道信息中心搞什么飞机，DHCP租约期还没有某些队员连续不睡觉的时间长，每天还得重配hosts文件。</p>
<p>昨天晚上突然意识到还没检查CPU的C State和P State（再次感谢某人的血泪史），dmesg一看发现<code>intel_idle: does not run on family 6 model</code>，考虑到新硬件的兼容性，我们已经上了Ubuntu 18.04的5.4 HWE内核了，难道这还不够新？<code>cpupower idle-info</code>里果然没有C6 State。一顿搜索找到了Ubuntu 18.04可以用的5.10内核的deb包，于是决定单独拉一个节点过来受害。新内核装好了以后，<code>intel_idle</code>是没问题了，C6也应该有了，但NVIDIA的内核模块没有被重新编译，最关键的是没省多少电，也不知道为什么，保守起见，还是不上新内核了。可能是非CPU消耗的功耗太多了，再从CPU挤挤，省出来了那点功耗估计是非CPU功耗的零头。</p>
<blockquote>
<p>待机控制的建议阅读：</p>
<ul>
<li><a href="https://support.huawei.com/enterprise/en/doc/EDOC1000039573/b029a50b/advanced-power-management-configuration">https://support.huawei.com/enterprise/en/doc/EDOC1000039573/b029a50b/advanced-power-management-configuration</a></li>
<li><a href="https://wiki.bu.ost.ch/infoportal/_media/embedded_systems/ethercat/controlling_processor_c-state_usage_in_linux_v1.1_nov2013.pdf">https://wiki.bu.ost.ch/infoportal/_media/embedded_systems/ethercat/controlling_processor_c-state_usage_in_linux_v1.1_nov2013.pdf</a></li>
<li><a href="https://vstinner.github.io/intel-cpus.html">https://vstinner.github.io/intel-cpus.html</a></li>
</ul>
</blockquote>
<p>关于内存，早就看到有些队给所有机器满上了，可能是上一届ASC让他们得了内存不足PTSD吧。我们还担心内存功耗很大，借了的内存必须在比赛的时候全插上，就先借了32条，能插满两个节点（两节点自带32条），然后测了一下，结果内存的峰值功耗还没有GPU待机功耗大。（最后插满的四节点内存峰值功耗也就100W内吧，工作人员老拿内存功耗说事，还以为功耗有多夸张呢。）于是就决定给四节点满上了，强迫症开心了，没有空着的内存插槽了，但这个时候工作人员又不让借了，说借内存需要确定比赛机器最终配置以后才能把内存拿给你，这种不明说的怕不是刚拍屁股想出来的规则真tm坑。</p>
<p>给节点上好内存的时候，有一个节点又红星闪闪放光芒，BMC说有几根内存条有毛病。把内存全拔了，调换顺序重插一遍。BMC说另外几根内存有毛病，烂掉的内存数量倒是少一点了。我们怀疑是内存金手指氧化了，上一次ASC19我队表演了一手现场擦显卡金手指，还给救活了，所以决定今年表演一手现场擦内存条金手指。擦了一个小时，痛失了半截橡皮擦后，重新插上内存，开机，红灯，BMC的报错和上次一毛一样，还是那几个槽的内存烂了，但是这些槽上的内存已经被调换了，每次内存条都被插到一个随机的位置上，想想这些内存都是新的，应该也不是氧化的问题。我们也懒得这个时候换机器了，等确认机器配置以后再换，正好这个节点也可以当做三带一方案里的那个load resistance，负责耗电就行，不影响我们测三机六卡。</p>
<p>最后测出来三机六卡和四机八卡同功耗限制下跑HPL的成绩差不太多，但四机八卡的HPCG的成绩远好于三机六卡，毕竟众所周知HPL吃浮点计算能力，HPCG吃总内存带宽，内存读写功耗又远低于浮点计算功耗。</p>
<p>五点左右的时候确定了最终配置，满内存四机八卡，其他队的方案估计也差不多。今年的机子属实大火炉，待机400W满载1kW+，单节点还只能上两GPU（把有线网卡废了理论上能上三GPU），所以应该整不出太多花活，白准备了十多张美国金卡了。六点的时候按最终方案配置好了，还剩下了一点时间测测HPL和我的QuEST。晚上因为之前两天每天只睡四个小时，就决定啥也不干了，直接躺床去世。</p>
<h2 id="day-2">Day 2</h2>
<p>早上不想起床，感觉没自己什么事（其实跑HPL的那个人指望我去压功耗），就决定来一手可控迟到，多睡了半个小时（其实已经睡了差不多九个小时了）。在路上想着我是不是最后一个到场的，结果并不是，甚至还是前几个到场了的。<del>大家都迟到了等于我没迟到</del></p>
<figure>
<img data-src="/images/pasted-72.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>八点开始的比赛，十一点就要交HPL的成绩，九点才开始调HPL。第一次跑，就跑出了一个比预期好的成绩，第二次跑更好了。我说要不就交了吧，刚启动的机器比较凉，但跑HPL的那个人是个赌狗，后来机器不负众望，一次跑得比一次烂，甚至还出现了超功耗的情况。后来实在顶不住了，他说最后再跑一次，我把机子多冷却了一会，结果，自然是，跑出了一个史低。最后一次是不可能最后一次的，那肯定是又说着最后再跑一次又准备跑一次，我看不下去了，就去吃了个茶歇，想着我走开，没人去控制风扇和功耗，他就不能立刻跑HPL，机子就可以多冷却一会，结果远远地看到那个人敲着我的电脑自己开始跑HPL，拖住他的计划大失败，我还是得跑回去接手功耗控制，毕竟没有写读HPL的log来调功耗的脚本，全靠手动实现多阶段的功耗控制。emmm，最后，呃，跑出了个史高，太草了，赌狗的大胜利。至于HPCG，我们最初就计划跑一次HPCG，跑出结果就完事了。</p>
<p>大概十点交了HPL成绩，拿到了当天其他的赛题。PRESTO给了几十个GB的输入数据，突然我就慌了啊，不是说没有吃IO的应用吗，我们共享存储可是NFS over 1Gbps Ethernet，光是分发这些数据都难顶。这个时候想到了三个解决方案，用MPI分发数据到本地SSD上，让PRESTO从本地SSD读取数据；配置IP over IB，然后用scp分发数据到本地SSD上，或者NFS over IP over IB；配置NFS over RDMA。第一个方案，懒得写MPI程序。第二个方案，因为残留的BeeGFS可能阻止IB服务的重启，可能会炸。第三个方案，可能可行。找了两个在别的地方的节点，试着配了一下，载入NFS over RDMA内核模块没问题，但是mount的时候就失败了，在dmesg里看到这个内核模块已经爆炸了，所以第三个方案也不行。这个时候让PRESTO试着跑起来了，读取共享存储的数据，但dstat发现以太网卡其实没啥流量，也就是说根本没必要管共享存储的IO问题。</p>
<p>之后还出了一个事故，跑HPL那个人为了测MPI是不是正常的，又跑了一次HPL，结果把之前准备用来提交的HPL输出数据给覆盖了，好在最后不影响成绩。</p>
<p>PRESTO那边折腾了半天魔改的多机版，又是折腾出了纯MPI的，发现还没有单节点来得快，结果拖到了很晚才开始正式跑PRESTO。惊为天人的是，大家一顿操作猛如虎，还是成功的在最后几十分钟把所有的算例跑完了。</p>
<p>不过跑是跑下来了，提交文件的时候又出问题了，输出文件太大了。我们先后经历了U盘存不下，拷得慢等问题，最后换成了某位热心的工作人员提供的移动SSD硬盘，但还是慢。最令人窒息的事情是卡在了umount命令上，iostat看到一直有数据写入移动硬盘，又刚好听到了国防科大硬拔U盘造成了数据损坏，不得不重新复制的悲报，所以大家也没敢硬拔，只好躺在地上无所事事。直到七点半，实在是等不下去了，因为国防科大队已经重新复制完文件溜了。所以只能硬拔，格式化，重新复制。这一次用了rsync，而不是用的cp，复制速度终于符合SSD的表现了，腰不疼了，腿不酸了，umount也有劲了。</p>
<p>晚上大家都没吃<del>（除了我）</del>，老师就让我们用破解版饭卡去西餐厅吃，今天加班不亏。</p>
<h2 id="day-3">Day 3</h2>
<p>其实我Day 2的主要工作基本上就是压功耗，也就是说没啥事，Day 3就有我的QuEST了，所以这一天没<del>怎么</del>迟到。拿到算例一看，好家伙最少模拟34位量子比特，显存直接爆炸了。刚好八卡共320G的显存也就够模拟一个33位的量子比特，出题人一定是故意的。算例四的量子比特位倒是挺少，20多位，但是模拟了一堆量子比特，内存占用算下来等效于模拟一个35~36位的量子比特。最后决定还是跑CPU版的，自己魔改出来的分布式多GPU版本根本用不上。</p>
<p>一开始决定给AI题先跑，因为之前的情报显示我可能需要现场改QuEST多GPU的代码，因为决赛会提供一个加了料的QuEST的源代码，加了几个门。Day 3前一天晚上AI组的同学自信得一批，说绝对稳如老狗，因为原先题目说在BERT模型上搞，他们就对着BERT做了一堆优化，效果好像还不错。结果Day 3早上，组委会给了个ALBERT，好家伙，名字里倒确实有BERT这四个字，他们做的优化不仅是 白 搞 了，他们现在还得去改代码把优化手段删掉，然后发现了loss根本不收敛。不过他们业务能力极强，用了一个小时把bug修了。折腾到大概十二点开始训练模型，决赛最多允许训练到三个Epoch，一个Epoch大概需要训练半个小时，训练前两个Epoch屁事没有，最后一个Epoch还差一分钟训练完的时候居然超功耗了，没办法，还是得把程序鲨了。其实可以用在训练中保存的checkpoint来推理，但是因为不是正常退出，有一个关键的用来判定训练时间的log没有打出来，所以之前的结果还是白给了，虽然有人提出可以 人 脑 生 成 一个log，但估计不太合规，还是算了。此时已经一点半了，不跑别的就来不及了。</p>
<p>在AI训练的时候，我在现场对他们提供的加料版QuEST的源代码做CPU优化。一年前的时候我们就发现MPI和OMP混合比纯MPI快不少，但是用mpirun启动混合模式的程序就非常痛苦，特别是Intel MPI。OpenMPI好歹给了<code>map-by</code>和<code>bind-to</code>选项，Intel MPI调了半天genv的变量都没有让MPI给OMP留出指定数量的核心，而且Intel的<code>-print-rank-map</code>的输出非常抽象，因为就没输出什么有用的信息。所以计划用slurm辅助Intel MPI启动混合模式的程序，结果这个时候有一个节点的slurm崩掉了（那个节点曾因为忘记开风扇过热关过机），什么<code>slurmd -c</code>都不好使，所以又花了一些时间去抢救slurm，过了几十分钟，不知道为什么slurm又活过来了。准备开始跑QuEST的第一个算例量子傅里叶变换了，按下mpirun，过了几秒就崩了，报ulimit太小，但是我魔改的系统已经把ulimit开到unlimited了。好家伙，最后发现解决方案居然是换root用户跑，大概二十分钟就跑出结果了。</p>
<p>然后是第二个算例，这个算例是量子傅里叶正逆变换，而且它的量子比特位数比第一个大了1位，所以估计需要四倍于第一个算例的时间，但跑了一个小时程序还没有结束，感觉不太对劲了。我们开始讨论要不要结束程序，考虑到沉没成本过高，我坚持让程序跑完。过了一阵子，去检查了一下log，发现在计算开始半小时左右slurm报告它kill掉了什么东西，看了一眼htop，程序似乎还在“正常”跑，所以我以为slurm没kill成功。程序跑了一小时二十分的时候，感觉太不对劲了，又开始讨论要不要结束程序，这个时候我还是不太想杀死它，打算让AI训练和QuEST一起跑。又过了一阵子，仔细检查htop，这才发现QuEST每个节点都只剩下了三个rank，有一个rank与世长辞了，应该是被slurm害死的那个进程，QuEST再见了您内。</p>
<p>至于QuEST的第三个算例，这玩意光是编译就挺麻烦的。虽然组委会给了Makefile，但是QuEST已经迁移到了CMake了，那个Makefile只能编译出一堆错误。而且这个算例和其他不一样，其他算例基本上是一个cpp文件，这个算例是几个cpp文件和一个py内鬼，这个内鬼不仅让编译变得困难（依赖Python的头文件），估计还能起到拖慢程序的重大作用。不过我们第二个算例都跑不下来，就没第三个算例什么事了。</p>
<p>这个时候距离比赛结束还有大概1个小时，神秘应用能编译，但只能跑单线程，估计跑不完一个算例。所以大家稍加思索，最后决定保AI。AI那边本来应该没有什么大问题，至少跑完一个Epoch是没问题的。但不知道为什么，跑到三四百秒的时候进程被杀死了。又跑了一次，又被杀死了，原因不明，只见屏幕上有个Ctrl-C，但其他人都声称没有误触或者结束进程，难道是slurm杀疯了？也不太可能啊。但不管怎么说，我们的时辰快到了。好在AI组改代码去捕获Keyboard Interrupt，然后保存模型，把log打出来。原本的目的是为了让训练能跑多久跑多久，跑不完就Ctrl-C，结果让那个训练了400秒的模型成功保存下来。测试发现那玩意的准确率还有78%，训练三个Epoch也才85%。虽然准确率丢了点分，但时间分拿满了啊。Anyway，反正没别的东西交了，最后就把这个400秒的模型交上去了。</p>
<h2 id="day-4">Day 4</h2>
<p>又是早起的一天，答辩无事发生，发挥比赛场上好多了，不愧是南方pre大学。下午领奖，就记住了宣传片里我队恶臭的口号，还有妮可坟头的招生广告。rank第五，别的奖项一个都没捞到，看在全队成员都是第一次打线下的现场赛的份上，这成绩还说得过去。赛前还吹牛批说要拿广东第一，最后倒是喜提广东倒数第一，深圳第一倒是保住了，因为也不存在深圳第二。不过Day 3崩成这样还能排第五，看起来大家都崩了，大家都崩等于大家都没崩！</p>
<p>后来吹水的时候听到了有人用了多GPU版的QuEST跑了几个算例，想了想确实很容易就可以写出来一部分Rank的StateVector放在显存上，一部分Rank的放在内存上的程序，这样显存爆了的情况下还可以让GPU和CPU一起算。之前没参加过ASC的现场赛，还是太年轻，我居然会去期待组委会是一群好人。组委会的恶趣味还包括年年都搞气象模型这种恶心东西，神秘应用可以读写PB级别的数据，还好没梭哈神秘应用，不然我们那个玩具级NFS必然顶不住。我最气愤的其实是组委会把晚宴取消了，晚上又得去吃学校里的茶餐厅了，每次比完超算比赛就去茶餐厅也太难顶了，西餐厅人均100的餐标也就能吃个夜宵。</p>
]]></content>
  </entry>
  <entry>
    <title>ASC20 &amp; NVIDIA DLI CUDA C/C++基础培训笔记</title>
    <url>/2020/01/19/ASC20-NVIDIA-DLI-CUDA-C-C-%E5%9F%BA%E7%A1%80%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="day2-nvidia-dli-加速计算基础-cuda-cc">Day2 NVIDIA DLI 加速计算基础 —— CUDA C/C++</h2>
<h3 id="systems-management-interface">Systems Management Interface</h3>
<p>命令查询有关此 GPU 的信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>
<h3 id="writing-application-code-for-the-gpu">Writing Application Code for the GPU</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">CPUFunction</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;This function is defined to run on the CPU.\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">GPUFunction</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;This function is defined to run on the GPU.\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  CPUFunction();</span><br><span class="line"></span><br><span class="line">  GPUFunction&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">  cudaDeviceSynchronize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>__global__ void GPUFunction()</code>
<ul>
<li>使用<code>__global__</code>关键字定义的函数需要返回 void 类型</li>
</ul></li>
<li><code>GPUFunction&lt;&lt;&lt;1, 1&gt;&gt;&gt;()</code>
<ul>
<li>使用 &lt;&lt;&lt; ... &gt;&gt;&gt; 语法提供执行配置</li>
<li>通过执行配置指定线程层次结构</li>
</ul></li>
</ul>
<h3 id="compiling-and-running-accelerated-cuda-code">Compiling and Running Accelerated CUDA Code</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nvcc -arch=sm_70 -o hello-gpu 01-hello/01-hello-gpu.cu -run</span><br></pre></td></tr></table></figure>
<ul>
<li><code>-arch</code>
<ul>
<li><a href="http://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#gpu-feature-list">虚拟架构特性</a></li>
<li><a href="http://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#gpu-feature-list">GPU特性</a></li>
</ul></li>
</ul>
<h3 id="block-dimensions">Block Dimensions</h3>
<p>惯用表达式<code>threadIdx.x + blockIdx.x * blockDim.x</code></p>
<h3 id="allocating-memory">Allocating Memory</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// CPU-only</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> N = <span class="number">2</span>&lt;&lt;<span class="number">20</span>;</span><br><span class="line"><span class="keyword">size_t</span> size = N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> *a;</span><br><span class="line">a = (<span class="keyword">int</span> *)<span class="built_in">malloc</span>(size);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use `a` in CPU-only program.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">free</span>(a);</span><br><span class="line"><span class="comment">// Accelerated</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> N = <span class="number">2</span>&lt;&lt;<span class="number">20</span>;</span><br><span class="line"><span class="keyword">size_t</span> size = N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> *a;</span><br><span class="line"><span class="comment">// Note the address of `a` is passed as first argument.</span></span><br><span class="line">cudaMallocManaged(&amp;a, size);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use `a` on the CPU and/or on any GPU in the accelerated system.</span></span><br><span class="line"></span><br><span class="line">cudaFree(a);</span><br></pre></td></tr></table></figure>
<h3 id="manual-memory-allocation-and-copying">Manual Memory Allocation and Copying</h3>
<ul>
<li>cudaMalloc 为 GPU 分配内存
<ul>
<li>防止 GPU 分页错误</li>
</ul></li>
<li>cudaMallocHost 为 CPU 分配内存
<ul>
<li>钉固内存或锁页内存</li>
<li>cudaFreeHost 命令释放钉固内存</li>
<li>cudaMemcpy 命令均可拷贝（而非传输）内存</li>
</ul></li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> *host_a, *device_a;        <span class="comment">// Define host-specific and device-specific arrays.</span></span><br><span class="line">cudaMalloc(&amp;device_a, size);   <span class="comment">// `device_a` is immediately available on the GPU.</span></span><br><span class="line">cudaMallocHost(&amp;host_a, size); <span class="comment">// `host_a` is immediately available on CPU, and is page-locked, or pinned.</span></span><br><span class="line"></span><br><span class="line">initializeOnHost(host_a, N);   <span class="comment">// No CPU page faulting since memory is already allocated on the host.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// `cudaMemcpy` takes the destination, source, size, and a CUDA-provided variable for the direction of the copy.</span></span><br><span class="line">cudaMemcpy(device_a, host_a, size, cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">kernel&lt;&lt;&lt;blocks, threads, <span class="number">0</span>, someStream&gt;&gt;&gt;(device_a, N);</span><br><span class="line"></span><br><span class="line"><span class="comment">// `cudaMemcpy` can also copy data from device to host.</span></span><br><span class="line">cudaMemcpy(host_a, device_a, size, cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">verifyOnHost(host_a, N);</span><br><span class="line"></span><br><span class="line">cudaFree(device_a);</span><br><span class="line">cudaFreeHost(host_a);          <span class="comment">// Free pinned memory like this.</span></span><br></pre></td></tr></table></figure>
<h3 id="using-streams-to-overlap-data-transfers-and-code-execution">Using Streams to Overlap Data Transfers and Code Execution</h3>
<ul>
<li>cudaMemcpyAsync
<ul>
<li>仅对主机而言为异步</li>
<li>默认情况下，在默认流中执行，对于在 GPU 上执行的其他 CUDA 操作而言，该执行操作为阻碍操作</li>
<li>将非默认流看作可选的第 5 个参数，可以与其他 CUDA 操作并发执行</li>
</ul></li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> N = <span class="number">2</span>&lt;&lt;<span class="number">24</span>;</span><br><span class="line"><span class="keyword">int</span> size = N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> *host_array;</span><br><span class="line"><span class="keyword">int</span> *device_array;</span><br><span class="line"></span><br><span class="line">cudaMallocHost(&amp;host_array, size);               <span class="comment">// Pinned host memory allocation.</span></span><br><span class="line">cudaMalloc(&amp;device_array, size);                 <span class="comment">// Allocation directly on the active GPU device.</span></span><br><span class="line"></span><br><span class="line">initializeData(host_array, N);                   <span class="comment">// Assume this application needs to initialize on the host.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> numberOfSegments = <span class="number">4</span>;                  <span class="comment">// This example demonstrates slicing the work into 4 segments.</span></span><br><span class="line"><span class="keyword">int</span> segmentN = N / numberOfSegments;             <span class="comment">// A value for a segment&#x27;s worth of `N` is needed.</span></span><br><span class="line"><span class="keyword">size_t</span> segmentSize = size / numberOfSegments;    <span class="comment">// A value for a segment&#x27;s worth of `size` is needed.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// For each of the 4 segments...</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numberOfSegments; ++i)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// Calculate the index where this particular segment should operate within the larger arrays.</span></span><br><span class="line">  segmentOffset = i * segmentN;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Create a stream for this segment&#x27;s worth of copy and work.</span></span><br><span class="line">  cudaStream_t stream;</span><br><span class="line">  cudaStreamCreate(&amp;stream);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Asynchronously copy segment&#x27;s worth of pinned host memory to device over non-default stream.</span></span><br><span class="line">  cudaMemcpyAsync(&amp;device_array[segmentOffset],  <span class="comment">// Take care to access correct location in array.</span></span><br><span class="line">                  &amp;host_array[segmentOffset],    <span class="comment">// Take care to access correct location in array.</span></span><br><span class="line">                  segmentSize,                   <span class="comment">// Only copy a segment&#x27;s worth of memory.</span></span><br><span class="line">                  cudaMemcpyHostToDevice,</span><br><span class="line">                  stream);                       <span class="comment">// Provide optional argument for non-default stream.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Execute segment&#x27;s worth of work over same non-default stream as memory copy.</span></span><br><span class="line">  kernel&lt;&lt;&lt;number_of_blocks, threads_per_block, <span class="number">0</span>, stream&gt;&gt;&gt;(&amp;device_array[segmentOffset], segmentN);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// `cudaStreamDestroy` will return immediately (is non-blocking), but will not actually destroy stream until</span></span><br><span class="line">  <span class="comment">// all stream operations are complete.</span></span><br><span class="line">  cudaStreamDestroy(stream);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="grid-size-work-amount-mismatch">Grid Size Work Amount Mismatch</h3>
<p>线程执行时不会尝试访问超出范围的数据元素</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">__global__ <span class="title">some_kernel</span><span class="params">(<span class="keyword">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> idx = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (idx &lt; N) <span class="comment">// Check to make sure `idx` maps to some value within `N`</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// Only do work if it does</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="data-sets-larger-than-the-grid">Data Sets Larger than the Grid</h3>
<p>网格跨度循环</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">__global <span class="keyword">void</span> <span class="title">kernel</span><span class="params">(<span class="keyword">int</span> *a, <span class="keyword">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> indexWithinTheGrid = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="keyword">int</span> gridStride = gridDim.x * blockDim.x;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = indexWithinTheGrid; i &lt; N; i += gridStride)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// do work on a[i];</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="error-handling">Error Handling</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">cudaError_t err;</span><br><span class="line">err = cudaMallocManaged(&amp;a, N)                    <span class="comment">// Assume the existence of `a` and `N`.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (err != cudaSuccess)                           <span class="comment">// `cudaSuccess` is provided by CUDA.</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Error: %s\n&quot;</span>, cudaGetErrorString(err)); <span class="comment">// `cudaGetErrorString` is provided by CUDA.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * This launch should cause an error, but the kernel itself</span></span><br><span class="line"><span class="comment"> * cannot return it.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line">someKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">-1</span>&gt;&gt;&gt;();  <span class="comment">// -1 is not a valid number of threads.</span></span><br><span class="line"></span><br><span class="line">cudaError_t err;</span><br><span class="line">err = cudaGetLastError(); <span class="comment">// `cudaGetLastError` will return the error from above.</span></span><br><span class="line"><span class="keyword">if</span> (err != cudaSuccess)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Error: %s\n&quot;</span>, cudaGetErrorString(err));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>CUDA Error Handling Function</strong></p>
<p>创建一个包装 CUDA 函数调用的宏</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;assert.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> cudaError_t <span class="title">checkCuda</span><span class="params">(cudaError_t result)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (result != cudaSuccess) &#123;</span><br><span class="line">    <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;CUDA Runtime Error: %s\n&quot;</span>, cudaGetErrorString(result));</span><br><span class="line">    assert(result == cudaSuccess);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * The macro can be wrapped around any function returning</span></span><br><span class="line"><span class="comment"> * a value of type `cudaError_t`.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line">  checkCuda( cudaDeviceSynchronize() )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="grids-and-blocks-of-2-and-3-dimensions">Grids and Blocks of 2 and 3 Dimensions</h3>
<p>可以将网格和线程块定义为最多具有3个维度。定义二维或三维网格或线程块，可以使用 CUDA 的 dim3 类型</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">threads_per_block</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">number_of_blocks</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">someKernel&lt;&lt;&lt;number_of_blocks, threads_per_block&gt;&gt;&gt;();</span><br></pre></td></tr></table></figure>
<p>someKernel 内部的变量 gridDim.x、gridDim.y、blockDim.x 和 blockDim.y 均将等于 16</p>
<h3 id="profile-an-application-with-nvprof">Profile an Application with nvprof</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nvcc -arch=sm_70 -o single-thread-vector-add 01-vector-add/01-vector-add.cu -run</span><br><span class="line">nvprof ./single-thread-vector-add</span><br></pre></td></tr></table></figure>
<h3 id="querying-gpu-device-properties">Querying GPU Device Properties</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> deviceId;</span><br><span class="line">cudaGetDevice(&amp;deviceId);</span><br><span class="line"></span><br><span class="line">cudaDeviceProp props;</span><br><span class="line">cudaGetDeviceProperties(&amp;props, deviceId);</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * `props` now contains several properties about the current device.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> computeCapabilityMajor = props.major;</span><br><span class="line"><span class="keyword">int</span> computeCapabilityMinor = props.minor;</span><br><span class="line"><span class="keyword">int</span> multiProcessorCount = props.multiProcessorCount;</span><br><span class="line"><span class="keyword">int</span> warpSize = props.warpSize;</span><br></pre></td></tr></table></figure>
<h3 id="asynchronous-memory-prefetching">Asynchronous Memory Prefetching</h3>
<p>异步内存预取，来减少页错误和按需内存迁移成本</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> deviceId;</span><br><span class="line">cudaGetDevice(&amp;deviceId);                                         <span class="comment">// The ID of the currently active GPU device.</span></span><br><span class="line"></span><br><span class="line">cudaMemPrefetchAsync(pointerToSomeUMData, size, deviceId);        <span class="comment">// Prefetch to GPU device.</span></span><br><span class="line">cudaMemPrefetchAsync(pointerToSomeUMData, size, cudaCpuDeviceId); <span class="comment">// Prefetch to host. `cudaCpuDeviceId` is a</span></span><br><span class="line">                                                                  <span class="comment">// built-in CUDA variable.</span></span><br></pre></td></tr></table></figure>
<h3 id="creating-utilizing-and-destroying-non-default-cuda-streams">Creating, Utilizing, and Destroying Non-Default CUDA Streams</h3>
<ul>
<li>CUDA 流行为
<ul>
<li>给定流中的操作会按序执行</li>
<li>就不同非默认流中的操作而言，无法保证其会按彼此之间的任何特定顺序执行</li>
<li>阻碍其他流的运行直至其自身已运行完毕</li>
</ul></li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">cudaStream_t stream;       <span class="comment">// CUDA streams are of type `cudaStream_t`.</span></span><br><span class="line">cudaStreamCreate(&amp;stream); <span class="comment">// Note that a pointer must be passed to `cudaCreateStream`.</span></span><br><span class="line"></span><br><span class="line">someKernel&lt;&lt;&lt;number_of_blocks, threads_per_block, <span class="number">0</span>, stream&gt;&gt;&gt;(); <span class="comment">// `stream` is passed as 4th EC argument.</span></span><br><span class="line"></span><br><span class="line">cudaStreamDestroy(stream); <span class="comment">// Note that a value, not a pointer, is passed to `cudaDestroyStream`.</span></span><br></pre></td></tr></table></figure>
<h3 id="gpu-programming-model-hardware-mapping">GPU Programming Model &amp; Hardware Mapping</h3>
<table>
<thead>
<tr class="header">
<th>Model</th>
<th>Hardware</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Thread</td>
<td>SP aka CUDA Core</td>
</tr>
<tr class="even">
<td>Block</td>
<td>SM / SMX</td>
</tr>
<tr class="odd">
<td>Grid</td>
<td>GPU aka Device</td>
</tr>
<tr class="even">
<td>Global Memory</td>
<td>DRAM</td>
</tr>
<tr class="odd">
<td>Shared Memory</td>
<td>SM内部存储</td>
</tr>
</tbody>
</table>
<p>注意： Thread不是实际的执行单元</p>
<h4 id="warp">Warp</h4>
<ul>
<li>每一个Warp有32条Thread</li>
<li>Sharing instructions</li>
<li>Dynamically scheduled by SM</li>
<li>Executed when operands ready</li>
<li>在编写程序的过程中不涉及到Warp，即对程序员透明</li>
</ul>
<p>潜在的性能损失 - Warp Divergent</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>GPU</tag>
        <tag>HPC</tag>
      </tags>
  </entry>
  <entry>
    <title>Building OpenWrt from Scratch for ARM64 UEFI ACPI VM</title>
    <url>/2022/02/26/Building-OpenWrt-from-Scratch-for-ARM64-UEFI-ACPI-VM/</url>
    <content><![CDATA[<p>OpenWrt doesn't provide a combined disk image for ARM virtual machines, unlike what they did for x86 VMs. Meanwhile, their official ARM64 kernel release can't boot in UEFI environment. But we can still make it work by compiling it from source and building a disk image manually.</p>
<p>Since Arm community has various opinions on how to boot an Arm machine, such as UEFI + ACPI (widely used by commercial Arm servers as well as modern x86 systems), U-Boot + Device Tree (mostly used by embedded devices with limited resouces), and even UEFI + Device Tree (like Huawei L420 notebook I owned), I would suggest that don't expect OpenWrt will provide official support for UEFI + ACPI systems in recent days as it is designed to run on tiny routers.</p>
<h2 id="compile-kernel-and-rootfs-from-source">Compile Kernel and Rootfs from Source</h2>
<p>Don't be scared. With the help of <code>buildroot</code>, which could automatically prepare the cross-compilation toolchain we need, this step is much simple nowadays.</p>
<blockquote>
<p>Note: My test environment is Ubuntu 21.10 ARM64 on Apple M1 Pro. It doesn't matter if you use a machine with a different system or architecture like AMD64, but you may need to take a few extra steps if so.</p>
</blockquote>
<h3 id="install-dependencies">Install Dependencies</h3>
<p>For Debian / Ubuntu users,</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install build-essential ccache ecj fastjar file g++ gawk \</span><br><span class="line">gettext git java-propose-classpath libelf-dev libncurses5-dev \</span><br><span class="line">libncursesw5-dev libssl-dev python python2.7-dev python3 unzip wget \</span><br><span class="line">python3-distutils python3-setuptools python3-dev rsync subversion \</span><br><span class="line">swig time xsltproc zlib1g-dev </span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: The content of this sub-section is copied from the <a href="https://openwrt.org/docs/guide-developer/toolchain/install-buildsystem">official guide</a>. Take a look at it if this command is not applicable for your system.</p>
</blockquote>
<h3 id="download-the-source-code">Download the Source Code</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://git.openwrt.org/openwrt/openwrt.git</span><br><span class="line"><span class="built_in">cd</span> openwrt</span><br><span class="line">git tag</span><br><span class="line">git checkout v21.02.2</span><br><span class="line">./scripts/feeds update -a</span><br></pre></td></tr></table></figure>
<h3 id="configure-the-project">Configure the Project</h3>
<ol type="1">
<li>Import the official configuration.</li>
</ol>
<p>To save our effort, it is a good idea to modify an existing configuration instead of creating a new one.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://downloads.openwrt.org/releases/21.02.2/targets/armvirt/64/config.buildinfo</span><br><span class="line">cp config.buildinfo .config</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>Add UEFI ACPI support.</li>
</ol>
<p>Open file <code>target/linux/armvirt/config-5.4</code>, and append the following lines to the end of file.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CONFIG_EFI_STUB=y</span><br><span class="line">CONFIG_EFI=y</span><br><span class="line">CONFIG_EFI_VARS=y</span><br><span class="line">CONFIG_ARCH_SUPPORTS_ACPI=y</span><br><span class="line">CONFIG_ACPI=y</span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>Launch Memuconfig.</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">make menuconfig</span><br><span class="line">make kernel_menuconfig</span><br></pre></td></tr></table></figure>
<p>Tweak the configuration as you like, but you should clearly understand the consequence before you turn on and off something. Keeping default options is also fine.</p>
<blockquote>
<p>Note: These commands will build the whole toolchain from source for the first time they are executed. The compilation process is very slow.</p>
</blockquote>
<h3 id="build-the-kernel-and-rootfs">Build the Kernel and Rootfs</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">make -j $(nproc) defconfig download clean world</span><br></pre></td></tr></table></figure>
<p>It will compile the kernel and all of the selected pre-installed utilities, then generate an EFI binary of Linux Kernel and an Ext4 / SquashFS partition image of Rootfs.</p>
<h3 id="verify-the-firmware-image">Verify the Firmware Image</h3>
<p>The exciting moment comes. Let's test the kernel and rootfs we just built.</p>
<ol type="1">
<li>Install QEMU.</li>
</ol>
<p>For Ubuntu users, I would suggest to install virt-manager instead, which offers a helpful GUI wizard for QEMU.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt install virt-manager</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>Launch a virtual machine.</li>
</ol>
<p>The magical QEMU allows virtual machines to boot a kernel without a bootloader. That is a great feature enables us to test the kernel's functionality at the early stage.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">qemu-system-aarch64 -m 512 -nographic -cpu cortex-a72 -smp 1 -M virt -kernel ~/openwrt/bin/targets/armvirt/64/openwrt-21.02.2-armvirt-64-Image-initramfs -bios /usr/share/qemu-efi-aarch64/QEMU_EFI.fd</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: <code>Image-initramfs</code> is the kernel binary while it integrates the OpenWrt's Rootfs as <code>initramfs</code>, so this virtual machine will lose data each time it reboots.</p>
</blockquote>
<blockquote>
<p>Note: If you encounter this issue,</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">EFI stub: Booting Linux Kernel...</span><br><span class="line">EFI stub: ERROR: Failed to relocate kernel</span><br><span class="line">EFI stub: ERROR: Failed to relocate kernel</span><br></pre></td></tr></table></figure>
<p>The solution is to increase the memory capacity of your virtual machine. Empirically, it should be at least 256 MB.</p>
</blockquote>
<h2 id="build-the-disk-image">Build the Disk Image</h2>
<p>Considered that data loss is not acceptable, while not every hypervisor is capable of launching a kernel directly, we should put everything we built into a disk, or virtual machine's disk image.</p>
<p>To keep things simple, let's start from building a raw disk image, which is one of the virtual disk formats supported by QEMU.</p>
<h3 id="create-an-empty-disk-image">Create an Empty Disk Image</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ dd <span class="keyword">if</span>=/dev/zero of=disk.img bs=1M count=1024</span><br><span class="line">1024+0 records <span class="keyword">in</span></span><br><span class="line">1024+0 records out</span><br><span class="line">1073741824 bytes (1.1 GB, 1.0 GiB) copied, 0.958229 s, 1.1 GB/s</span><br></pre></td></tr></table></figure>
<p>This command will create an empty disk image. Feel free to replace the value of <code>count</code> to change the size of the disk. (size = 1 MB * 1024 = 1 GB)</p>
<h3 id="partition-mount-and-format-the-disk-image">Partition, Mount, and Format the Disk Image</h3>
<ol type="1">
<li>Partition the disk.</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ fdisk disk.img</span><br><span class="line"></span><br><span class="line">Welcome to fdisk (util-linux 2.36.1).</span><br><span class="line">Changes will remain <span class="keyword">in</span> memory only, until you decide to write them.</span><br><span class="line">Be careful before using the write <span class="built_in">command</span>.</span><br><span class="line"></span><br><span class="line">Device does not contain a recognized partition table.</span><br><span class="line">Created a new DOS disklabel with disk identifier 0xb89701e3.</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): g</span><br><span class="line">Created a new GPT disklabel (GUID: 43B50BB3-20FD-3D4B-BFE1-50B5016F8059).</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): n</span><br><span class="line">Partition number (1-128, default 1):</span><br><span class="line">First sector (2048-2097118, default 2048):</span><br><span class="line">Last sector, +/-sectors or +/-size&#123;K,M,G,T,P&#125; (2048-2097118, default 2097118): +100M</span><br><span class="line"></span><br><span class="line">Created a new partition 1 of <span class="built_in">type</span> <span class="string">&#x27;Linux filesystem&#x27;</span> and of size 100 MiB.</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): t</span><br><span class="line">Selected partition 1</span><br><span class="line">Partition <span class="built_in">type</span> or <span class="built_in">alias</span> (<span class="built_in">type</span> L to list all): uefi</span><br><span class="line">Changed <span class="built_in">type</span> of partition <span class="string">&#x27;Linux filesystem&#x27;</span> to <span class="string">&#x27;EFI System&#x27;</span>.</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): n</span><br><span class="line">Partition number (2-128, default 2):</span><br><span class="line">First sector (206848-2097118, default 206848):</span><br><span class="line">Last sector, +/-sectors or +/-size&#123;K,M,G,T,P&#125; (206848-2097118, default 2097118):</span><br><span class="line"></span><br><span class="line">Created a new partition 2 of <span class="built_in">type</span> <span class="string">&#x27;Linux filesystem&#x27;</span> and of size 923 MiB.</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): p</span><br><span class="line">Disk disk.img: 1 GiB, 1073741824 bytes, 2097152 sectors</span><br><span class="line">Units: sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disklabel <span class="built_in">type</span>: gpt</span><br><span class="line">Disk identifier: 43B50BB3-20FD-3D4B-BFE1-50B5016F8059</span><br><span class="line"></span><br><span class="line">Device      Start     End Sectors  Size Type</span><br><span class="line">disk.img1    2048  206847  204800  100M EFI System</span><br><span class="line">disk.img2  206848 2097118 1890271  923M Linux filesystem</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): w</span><br><span class="line">The partition table has been altered.</span><br><span class="line">Syncing disks.</span><br></pre></td></tr></table></figure>
<p>A new GPT partition table with two partitions is written to the disk image.</p>
<ol start="2" type="1">
<li>Mount the disk image as a logical disk.</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ sudo losetup -Pf disk.img</span><br><span class="line">tonny@vm:~$ lsblk</span><br><span class="line">NAME                      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">loop5                       7:5    0    1G  0 loop</span><br><span class="line">├─loop5p1                 259:4    0  100M  0 part</span><br><span class="line">└─loop5p2                 259:5    0  923M  0 part</span><br></pre></td></tr></table></figure>
<p>OS has recognized the two partitions, <code>loop5p1</code> and <code>loop5p2</code>.</p>
<ol start="3" type="1">
<li>Format the partitions.</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~/mnt$ sudo mkfs.vfat /dev/loop5p1</span><br><span class="line">mkfs.fat 4.2 (2021-01-31)</span><br></pre></td></tr></table></figure>
<p>We don't need to format the second partition (Rootfs) for now, because we can directly restore the partition image of Rootfs instead, which is already formatted with Ext4 File System.</p>
<ol start="4" type="1">
<li>Mount ESP partition.</li>
</ol>
<p>ESP partition contains the EFI executables of bootloaders (e.g., GRUB), as well as its configuration files. We can also put the kernel binary here.</p>
<blockquote>
<p>Note: Some Linux distributions, like Ubuntu, will put their kernel in a third partition.</p>
</blockquote>
<p>Unlike Rootfs, OpenWrt Build System won't generate an ESP partition image for ARM64 platform. That means we have to build ESP partition manually.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~/mnt$ mkdir -p ~/mnt/esp</span><br><span class="line">tonny@vm:~/mnt$ sudo mount /dev/loop5p1 ~/mnt/esp</span><br></pre></td></tr></table></figure>
<h3 id="restore-rootfs-partition-image">Restore Rootfs Partition Image</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ sudo dd <span class="keyword">if</span>=~/openwrt/bin/targets/armvirt/64/openwrt-21.02.2-armvirt-64-rootfs-ext4.img of=/dev/loop5p2 bs=1M</span><br><span class="line">104+0 records <span class="keyword">in</span></span><br><span class="line">104+0 records out</span><br><span class="line">109051904 bytes (109 MB, 104 MiB) copied, 0.613318 s, 178 MB/s</span><br><span class="line">tonny@vm:~$ sudo resize2fs /dev/loop5p2</span><br><span class="line">resize2fs 1.46.3 (27-Jul-2021)</span><br><span class="line">Resizing the filesystem on /dev/loop5p2 to 236283 (4k) blocks.</span><br><span class="line">The filesystem on /dev/loop5p2 is now 236283 (4k) blocks long.</span><br></pre></td></tr></table></figure>
<p>The size of Rootfs image is about 128 MB, which implies that the file system inside will assume the partition size is about 128 MB. The size of our Rootfs partition is likely larger than this number, so we should notify the filesystem there is a change on the partition size.</p>
<h3 id="install-grub-to-esp-partition">Install GRUB to ESP Partition</h3>
<h4 id="install-arm64-grub-to-host">Install ARM64 GRUB to Host</h4>
<p>For Ubuntu users,</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt install grub-efi-arm64-bin</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: If your Host's architecture isn't ARM64, Apt may fail to find this package. Fortunately, thanks to Multiarch feature, we can easily install a package for other architectures. Take Ubuntu AMD64 as an example.</p>
<ol type="1">
<li>Request for ARM64 architecture's packages.</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo dpkg --add-architecture arm64</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>Add an Apt Repository for ARM64.</li>
</ol>
<p>Modify the file <code>/etc/apt/source.list</code> and add a ARM64 repository. Pay attention that ARM64 and AMD64 don't share the same repository, so we also need to add a filter for each repository. Here is an example.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">deb [ arch=amd64 ] https://mirrors.ustc.edu.cn/ubuntu/ impish main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src [ arch=amd64 ] https://mirrors.ustc.edu.cn/ubuntu/ impish main restricted universe multiverse</span></span><br><span class="line"></span><br><span class="line">deb [ arch=amd64 ] https://mirrors.ustc.edu.cn/ubuntu/ impish-security main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src [ arch=amd64 ] https://mirrors.ustc.edu.cn/ubuntu/ impish-security main restricted universe multiverse</span></span><br><span class="line"></span><br><span class="line">deb [ arch=amd64 ] https://mirrors.ustc.edu.cn/ubuntu/ impish-updates main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src [ arch=amd64 ] https://mirrors.ustc.edu.cn/ubuntu/ impish-updates main restricted universe multiverse</span></span><br><span class="line"></span><br><span class="line">deb [ arch=amd64 ] https://mirrors.ustc.edu.cn/ubuntu/ impish-backports main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src [ arch=amd64 ] https://mirrors.ustc.edu.cn/ubuntu/ impish-backports main restricted universe multiverse</span></span><br><span class="line"></span><br><span class="line">deb [ arch=arm64 ] https://mirrors.ustc.edu.cn/ubuntu-ports/ impish main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src [ arch=arm64 ] https://mirrors.ustc.edu.cn/ubuntu-ports/ impish main restricted universe multiverse</span></span><br><span class="line"></span><br><span class="line">deb [ arch=arm64 ] https://mirrors.ustc.edu.cn/ubuntu-ports/ impish-security main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src [ arch=arm64 ] https://mirrors.ustc.edu.cn/ubuntu-ports/ impish-security main restricted universe multiverse</span></span><br><span class="line"></span><br><span class="line">deb [ arch=arm64 ] https://mirrors.ustc.edu.cn/ubuntu-ports/ impish-updates main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src [ arch=arm64 ] https://mirrors.ustc.edu.cn/ubuntu-ports/ impish-updates main restricted universe multiverse</span></span><br><span class="line"></span><br><span class="line">deb [ arch=arm64 ] https://mirrors.ustc.edu.cn/ubuntu-ports/ impish-backports main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src [ arch=arm64 ] https://mirrors.ustc.edu.cn/ubuntu-ports/ impish-backports main restricted universe multiverse</span></span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>Install ARM64 GRUB</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install grub-efi-arm64-bin</span><br></pre></td></tr></table></figure>
</blockquote>
<h4 id="generate-efi-executable">Generate EFI Executable</h4>
<ol type="1">
<li>Check Partition's UUIDs.</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ lsblk -o PATH,UUID,PARTUUID /dev/loop5</span><br><span class="line">PATH         UUID                                 PARTUUID</span><br><span class="line">/dev/loop5</span><br><span class="line">/dev/loop5p1 CF95-2044                            3754ccb7-1920-2b41-9962-af81ac6a04b2</span><br><span class="line">/dev/loop5p2 ff313567-e9f1-5a5d-9895-3ba130b4a864 e09a20c3-0ea7-0c48-b653-0482facd93db</span><br></pre></td></tr></table></figure>
<p>Those UUIDs will be referred by the GRUB configurations.</p>
<ol start="2" type="1">
<li>Write Early-stage GRUB Configuration.</li>
</ol>
<p>Create a new file <code>~/grub-early.cfg</code>, and write the following lines. This configuration will be hardcoded into GRUB's EFI binary.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">search.fs_uuid CF95-2044 root</span><br><span class="line"><span class="built_in">set</span> prefix=(<span class="variable">$root</span>)<span class="string">&#x27;/boot&#x27;</span></span><br><span class="line">configfile <span class="variable">$prefix</span>/grub.cfg</span><br></pre></td></tr></table></figure>
<p>Replace the UUID with your <code>loop5p1</code>'s.</p>
<ol start="3" type="1">
<li>Make GRUB EFI Executable.</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># tonny@vm:~$ sudo mount /dev/loop5p1 ~/mnt/esp</span></span><br><span class="line">tonny@vm:~$ sudo mkdir -p ~/mnt/esp/EFI/BOOT/</span><br><span class="line">tonny@vm:~$ <span class="built_in">cd</span> ~/mnt/esp/EFI/BOOT/</span><br><span class="line">tonny@vm:~/mnt/esp/EFI/BOOT$ sudo grub-mkimage -c ~/grub-early.cfg -p /boot -o BOOTAA64.EFI -O arm64-efi boot chain configfile fat linux ls part_gpt reboot serial efi_gop search_fs_uuid</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: It is not recommended to use <code>grub-install</code> here. One of its typical usages is,</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo grub-install --target=arm64-efi --efi-directory ~/mnt/esp --bootloader-id=GRUB --boot-directory ~/mnt/esp/boot/</span><br></pre></td></tr></table></figure>
<p>The hidden disgusting thing is, if you use GRUB provided by Ubuntu, this command will hardcode an important GRUB variable <code>prefix='/EFI/ubuntu'</code> to the EFI binary, and there is no way to change it.</p>
</blockquote>
<h4 id="write-second-stage-grub-configuration">Write Second-stage GRUB Configuration</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~/mnt/esp/EFI/BOOT$ <span class="built_in">cd</span> ../..</span><br><span class="line">tonny@vm:~/mnt/esp$ sudo mkdir boot</span><br><span class="line">tonny@vm:~/mnt/esp$ <span class="built_in">cd</span> boot/</span><br><span class="line">tonny@vm:~/mnt/esp/boot$ sudo nano grub.cfg <span class="comment"># or other text editor you feel comfortable with</span></span><br></pre></td></tr></table></figure>
<p>The content of <code>grub.cfg</code> is,</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">serial --unit=0 --speed=115200 --word=8 --parity=no --stop=1 --rtscts=off</span><br><span class="line">terminal_input console serial; terminal_output console serial</span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> default=<span class="string">&quot;0&quot;</span></span><br><span class="line"><span class="built_in">set</span> timeout=<span class="string">&quot;5&quot;</span></span><br><span class="line"></span><br><span class="line">menuentry <span class="string">&quot;OpenWrt&quot;</span> &#123;</span><br><span class="line">	linux /boot/vmlinuz root=PARTUUID=e09a20c3-0ea7-0c48-b653-0482facd93db rootwait   console=tty0 console=ttyS0,115200n8 noinitrd</span><br><span class="line">&#125;</span><br><span class="line">menuentry <span class="string">&quot;OpenWrt (failsafe)&quot;</span> &#123;</span><br><span class="line">	linux /boot/vmlinuz failsafe=<span class="literal">true</span> root=PARTUUID=e09a20c3-0ea7-0c48-b653-0482facd93db rootwait   console=tty0 console=ttyS0,115200n8 noinitrd</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Replace <strong>PARTUUIDs</strong> (not UUIDs) with your <code>loop5p2</code>'s.</p>
<h3 id="copy-linux-kernel">Copy Linux Kernel</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~/mnt/esp/boot$ sudo cp ~/openwrt/bin/targets/armvirt/64/openwrt-21.02.2-armvirt-64-Image vmlinuz</span><br></pre></td></tr></table></figure>
<h3 id="verify-the-disk-image">Verify the Disk Image</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~/mnt/esp/boot$ <span class="built_in">cd</span> ~</span><br><span class="line">tonny@vm:~$ qemu-system-aarch64 -m 512 -nographic -cpu cortex-a72 -smp 1 -M virt -bios /usr/share/qemu-efi-aarch64/QEMU_EFI.fd -drive format=raw,file=disk.img</span><br></pre></td></tr></table></figure>
<p>If everything goes well, you could see your kernel is running happily. Enjoy it!</p>
<blockquote>
<p>Note: You don't have to unmount the disk before launching the virtual machine. But you should sync the disk to make sure all the data cached in memory is written back.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~/mnt/esp/boot$ sync</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="clean-up">Clean up</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~/mnt$ sudo umount ~/mnt/esp</span><br><span class="line">tonny@vm:~/mnt$ sudo losetup -d /dev/loop5</span><br></pre></td></tr></table></figure>
<h2 id="launch-vm-with-virt-manager">Launch VM with Virt-Manager</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~/mnt$ virt-manager</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: Sometimes <code>vert-manager</code> requires permissions to run.</p>
</blockquote>
<p>The recommended configuration:</p>
<ul>
<li>Step 1:
<ul>
<li>Architecture: <code>aarch64</code></li>
<li>Machine Type: <code>virt</code></li>
<li>Import existing disk image</li>
</ul></li>
<li>Step 2:
<ul>
<li>Browse ➡️ Add pool <code>Home</code> ➡️ Choose Volume <code>disk.img</code></li>
<li>Choose OS: Generic Linux / OS</li>
</ul></li>
<li>Step 3:
<ul>
<li>Memory: &gt;= 256 MB</li>
<li>CPU: Any</li>
</ul></li>
<li>Step 4:
<ul>
<li><strong>Customize configuration before install</strong></li>
<li>Network (LAN Port): Bridge / Macvtap Bridge</li>
</ul></li>
<li>Configuration
<ul>
<li><strong>Overview/Firmware: <code>UEFI aarch64</code></strong></li>
</ul></li>
</ul>
<blockquote>
<p>Note: You can't change the firmware type after pre-install configuration.</p>
</blockquote>
<h2 id="references">References</h2>
<ul>
<li><a href="https://gist.github.com/tstellanova/dea7593a7dfe4f48432a58cb007e7056">https://gist.github.com/tstellanova/dea7593a7dfe4f48432a58cb007e7056</a></li>
<li><a href="https://forum.openwrt.org/t/arm64-armvirt64-uefi-efi-openwrt-target/82740">https://forum.openwrt.org/t/arm64-armvirt64-uefi-efi-openwrt-target/82740</a></li>
<li><a href="https://forum.openwrt.org/t/how-to-install-openwrt-as-a-new-os-in-the-grub-menu/97465">https://forum.openwrt.org/t/how-to-install-openwrt-as-a-new-os-in-the-grub-menu/97465</a></li>
<li><a href="https://wiki.ubuntu.com/ARM64/QEMU">https://wiki.ubuntu.com/ARM64/QEMU</a></li>
<li><a href="https://wiki.archlinux.org/title/GRUB">https://wiki.archlinux.org/title/GRUB</a></li>
<li><a href="https://openwrt.org/docs/guide-user/virtualization/qemu">https://openwrt.org/docs/guide-user/virtualization/qemu</a></li>
<li><a href="https://krinkinmu.github.io/2020/11/21/EFI-aarch64.html">https://krinkinmu.github.io/2020/11/21/EFI-aarch64.html</a></li>
<li><a href="https://soha.moe/post/make-uefi-compatible-openwrt-disk-image.html">https://soha.moe/post/make-uefi-compatible-openwrt-disk-image.html</a></li>
<li><a href="https://git.openwrt.org/?p=openwrt/openwrt.git;hb=refs/heads/openwrt-21.02;a=blob;f=package/boot/grub2/Makefile">https://git.openwrt.org/?p=openwrt/openwrt.git;hb=refs/heads/openwrt-21.02;a=blob;f=package/boot/grub2/Makefile</a></li>
<li><a href="https://www.cxyzjd.com/article/u010875635/74289971">https://www.cxyzjd.com/article/u010875635/74289971</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Design of TensorFlow XLA Sharding System</title>
    <url>/2021/08/04/Design-of-TensorFlow-XLA-Sharding-System/</url>
    <content><![CDATA[<p>Recently, a SOTA sharding approach, GSPMD/GShard, was proposed and it provides an intuitive interface to partition a large array on arbitrary dimensions, while utilizing sharding propagation algorithms to automatically infer the partitioning strategy for tensors without user-specified sharding specifications. This document introduces the design and the implementation of XLA Sharding System.</p>
<figure>
<img data-src="/images/pasted-92.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h2 id="hlosharding-object"><code>HloSharding</code> Object</h2>
<p>First of all, <strong>we need a way to represent sharding specifications</strong> using programming language. XLA designed an object to do such a thing, and this object contains numerous variables and a set of supporting functions to configure itself. Some attributes of <code>HloSharding</code> are listed below.</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// File: tensorflow/compiler/xla/service/hlo_sharding.h</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HloSharding</span> &#123;</span></span><br><span class="line">  <span class="keyword">bool</span> replicated_;</span><br><span class="line">  <span class="keyword">bool</span> maximal_;</span><br><span class="line">  <span class="keyword">bool</span> tuple_;</span><br><span class="line">  <span class="keyword">bool</span> manual_;</span><br><span class="line">  <span class="comment">// This field is only used if replicated_ is false. If maximal_ is true, then</span></span><br><span class="line">  <span class="comment">// the field contains a rank 1 array with a single element, which is the</span></span><br><span class="line">  <span class="comment">// device the HLO is assigned to. If maximal_ is false, the field contains an</span></span><br><span class="line">  <span class="comment">// array with the same rank as the corresponding HLO. The dimension sizes of</span></span><br><span class="line">  <span class="comment">// the array describe the number of ways the HLO is partitioned along each</span></span><br><span class="line">  <span class="comment">// dimension. The values of the array specify which device each tile of</span></span><br><span class="line">  <span class="comment">// the HLO is assigned to. The index of each value determines which tile it</span></span><br><span class="line">  <span class="comment">// takes.</span></span><br><span class="line">  <span class="comment">// For example, &#123;&#123;&#123;2, 3&#125;&#125;, &#123;&#123;5, 7&#125;&#125;&#125; (whose ToString representation is</span></span><br><span class="line">  <span class="comment">// &quot;&#123;devices=[2,1,2]2,3,5,7&#125;&quot;), means that dimension 1 is split two way and</span></span><br><span class="line">  <span class="comment">// dimension 3 is split 2 way. Core 5, whose index is [2,1,1] will take the</span></span><br><span class="line">  <span class="comment">// tile that contains the 2nd half of dimension 1 and the 1st half of</span></span><br><span class="line">  <span class="comment">// dimension 3.</span></span><br><span class="line">  Array&lt;int64&gt; tile_assignment_;</span><br><span class="line">  <span class="comment">// Only non-empty when tuple_ is true. If a tuple is empty then one entry is</span></span><br><span class="line">  <span class="comment">// present for the root. This is a flattened list of all the leaf shardings in</span></span><br><span class="line">  <span class="comment">// a tuple shape, by pre-order walk (ShapeTree iterator order).</span></span><br><span class="line">  std::vector&lt;HloSharding&gt; tuple_elements_;</span><br><span class="line">  <span class="comment">// This flag is to support partial replication and partial sharding. If it is</span></span><br><span class="line">  <span class="comment">// true, tile_assignment_ will have an extra dimension in addition to the data</span></span><br><span class="line">  <span class="comment">// shape rank, and the added last dimension represents the subgroups of</span></span><br><span class="line">  <span class="comment">// replications, i.e., elements in slice [..., :] will be replicated.</span></span><br><span class="line">  <span class="keyword">bool</span> replicate_on_last_tile_dim_;</span><br><span class="line">  <span class="comment">// This field is used to track the source of this sharding, usually derived</span></span><br><span class="line">  <span class="comment">// from instructions. Multiple metadata may be populated if sharding is</span></span><br><span class="line">  <span class="comment">// combined with other shardings. Metadata are to not be populated when</span></span><br><span class="line">  <span class="comment">// tuple_ == true and instead metadata should be set on individual tuple</span></span><br><span class="line">  <span class="comment">// elements.</span></span><br><span class="line">  std::vector&lt;OpMetadata&gt; metadata_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p><code>Array&lt;int64&gt; tile_assignment_</code> here is multi-dimensional with arbitrary shape. <code>&#123;devices=[2,1,2]2,3,5,7&#125;</code> means the shape of <code>tile_assignment_</code> is <code>[2,1,2]</code>, while the values are <code>&#123;2,3,5,7&#125;</code>.</p>
<p><code>std::vector&lt;HloSharding&gt; tuple_elements_</code> probably was designed to specify the sharding specifications of outputs.</p>
<p><em>I am not aware of what the roles of <code>maximal_</code>, <code>tuple_elements_</code> are. Is there any body know that?</em></p>
<p>Note that each single object could be shared by multiple instructions. By doing this, the cost of creating and maintaining several instances with the exact same contents could be eliminated.</p>
<h2 id="extended-hlo-ir-attribute">Extended HLO IR Attribute</h2>
<p>The original implementation of XLA added the attribute <code>std::shared_ptr&lt;const HloSharding&gt; sharding_</code> to the class <code>xla::HloInstruction</code>, which is declared in <code>tensorflow/compiler/xla/service/hlo_instruction.h</code>. A common usage of this HLO Instruction Attribute is to <strong>declare sharded tensors</strong>. Here is a sample HLO IR code with sharding attributes. Note that the Propagation Algorithm may fill in this attribute for those instructions without it.</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">primitive_computation_add.<span class="number">6</span> &#123;</span><br><span class="line">  parameter.<span class="number">7</span> = <span class="built_in">f32</span>[] parameter(<span class="number">0</span>)</span><br><span class="line">  parameter.<span class="number">8</span> = <span class="built_in">f32</span>[] parameter(<span class="number">1</span>)</span><br><span class="line">  ROOT add.<span class="number">9</span> = <span class="built_in">f32</span>[] add(parameter.<span class="number">7</span>, parameter.<span class="number">8</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ENTRY xmap__lambda_.<span class="number">12</span> &#123;</span><br><span class="line">  constant.<span class="number">2</span> = pred[] constant(<span class="literal">false</span>)</span><br><span class="line">  parameter.<span class="number">1</span> = <span class="built_in">f32</span>[<span class="number">8</span>]&#123;<span class="number">0</span>&#125; parameter(<span class="number">0</span>), parameter_replication=&#123;<span class="literal">false</span>&#125;, sharding=&#123;replicated&#125;</span><br><span class="line">  custom-call.<span class="number">3</span> = <span class="built_in">f32</span>[<span class="number">8</span>]&#123;<span class="number">0</span>&#125; custom-call(parameter.<span class="number">1</span>), custom_call_target=<span class="string">&quot;Sharding&quot;</span>, sharding=&#123;devices=[<span class="number">4</span>]<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;</span><br><span class="line">  sine.<span class="number">4</span> = <span class="built_in">f32</span>[<span class="number">8</span>]&#123;<span class="number">0</span>&#125; sine(custom-call.<span class="number">3</span>)</span><br><span class="line">  constant.<span class="number">5</span> = <span class="built_in">f32</span>[] constant(<span class="number">0</span>)</span><br><span class="line">  reduce.<span class="number">10</span> = <span class="built_in">f32</span>[] reduce(sine.<span class="number">4</span>, constant.<span class="number">5</span>), dimensions=&#123;<span class="number">0</span>&#125;, to_apply=primitive_computation_add.<span class="number">6</span></span><br><span class="line">  ROOT tuple.<span class="number">11</span> = (<span class="built_in">f32</span>[]) tuple(reduce.<span class="number">10</span>), sharding=&#123;&#123;replicated&#125;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Note: this HLO IR code is compiled from this JAX Frontend code</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@jtu.with_mesh(<span class="params">[(<span class="params"><span class="string">&#x27;x&#x27;</span>, <span class="number">4</span></span>)]</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    f = pjit(<span class="keyword">lambda</span> x: jnp.sin(x).<span class="built_in">sum</span>(),</span><br><span class="line">             in_axis_resources=(P(<span class="string">&#x27;x&#x27;</span>),),</span><br><span class="line">             out_axis_resources=<span class="literal">None</span>)</span><br><span class="line">    x = jnp.arange(<span class="number">8</span>, dtype=jnp.float32)</span><br><span class="line">    f(x)</span><br></pre></td></tr></table></figure>
<p>This example illustrates a lambda function takes a replicated tensor as the input, and splits this tensor by invoking <code>custom-call</code>, then performs the calculation.</p>
<h2 id="spmd-partitioner">SPMD Partitioner</h2>
<p>You might notice that in the previous example, the instructions invoking operators (e.g. reduce.10) don’t contain sharding attributes. That leads to a critical question, <strong>how a regular operator reacts to sharded tensors</strong>. The solution of XLA is introducing SPMD Partitioner, which is mainly responsible for converting a full-sized operator into a partition-sized operator by adding necessary collective communication primitives to lower-layer IR code, and the partitioner also converts the inputs of operators from global tensor symbols with sharding to local tensor symbols without sharding specifications.</p>
<p>We could find some clues in <code>tensorflow/compiler/xla/service/spmd/spmd_partitioner_test.cc</code>.</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">TEST_F</span>(SpmdPartitioningTest, DotPartialContracting2) &#123;</span><br><span class="line">  absl::string_view hlo_string = <span class="string">R&quot;(</span></span><br><span class="line"><span class="string">HloModule module</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ENTRY entry &#123;</span></span><br><span class="line"><span class="string">  %lhs = f32[24,100] parameter(0),</span></span><br><span class="line"><span class="string">    sharding=&#123;devices=[1,2,2]0,1,2,3 last_tile_dim_replicate&#125;</span></span><br><span class="line"><span class="string">  %rhs = f32[32,100] parameter(1),</span></span><br><span class="line"><span class="string">    sharding=&#123;devices=[1,2,2]0,1,2,3 last_tile_dim_replicate&#125;</span></span><br><span class="line"><span class="string">  ROOT %dot = f32[24,32] dot(%lhs, %rhs),</span></span><br><span class="line"><span class="string">    lhs_batch_dims=&#123;&#125;, rhs_batch_dims=&#123;&#125;,</span></span><br><span class="line"><span class="string">    lhs_contracting_dims=&#123;1&#125;, rhs_contracting_dims=&#123;1&#125;,</span></span><br><span class="line"><span class="string">    sharding=&#123;devices=[2,1,2]0,2,1,3 last_tile_dim_replicate&#125;</span></span><br><span class="line"><span class="string">&#125;)&quot;</span>;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">TF_ASSERT_OK_AND_ASSIGN</span>(<span class="keyword">auto</span> <span class="keyword">module</span>,</span><br><span class="line">                          <span class="built_in">PartitionComputation</span>(hlo_string, <span class="comment">/*num_devices=*/</span><span class="number">4</span>));</span><br><span class="line">  <span class="built_in">VLOG</span>(<span class="number">1</span>) &lt;&lt; <span class="keyword">module</span>-&gt;<span class="built_in">ToString</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> lhs = <span class="built_in">AllOf</span>(op::<span class="built_in">Shape</span>(<span class="string">&quot;f32[24,50]&quot;</span>), op::<span class="built_in">Parameter</span>(<span class="number">0</span>));</span><br><span class="line">  <span class="keyword">auto</span> rhs = <span class="built_in">AllOf</span>(op::<span class="built_in">Shape</span>(<span class="string">&quot;f32[32,50]&quot;</span>), op::<span class="built_in">Parameter</span>(<span class="number">1</span>));</span><br><span class="line">  <span class="keyword">auto</span> dot =</span><br><span class="line">      <span class="built_in">AllOf</span>(op::<span class="built_in">Shape</span>(<span class="string">&quot;f32[12,32]&quot;</span>),</span><br><span class="line">            op::<span class="built_in">Dot</span>(<span class="built_in">AllOf</span>(op::<span class="built_in">Shape</span>(<span class="string">&quot;f32[12,50]&quot;</span>), op::<span class="built_in">DynamicSlice</span>(lhs, _, _)),</span><br><span class="line">                    rhs));</span><br><span class="line">  <span class="keyword">auto</span> root = <span class="keyword">module</span>-&gt;<span class="built_in">entry_computation</span>()-&gt;<span class="built_in">root_instruction</span>();</span><br><span class="line">  <span class="built_in">EXPECT_THAT</span>(root, op::<span class="built_in">AllReduce</span>(dot));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Two inputs, <code>lhs</code> and <code>rhs</code>, are tensors partitioned in the way that the figure describes. Thus, after partitioning the computation, the <code>lhs</code> is unwarpped, and its shape changed from <code>f32[24, 100]</code> to <code>f32[24,50]</code>. And at the end of file, <code>AllReduce</code> was added to collect the partial results.</p>
<figure>
<img data-src="/images/pasted-93.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h2 id="sharding-propagation-algorithm">Sharding Propagation Algorithm</h2>
<p>The system should be able to figure out an optimal sharding specifications for the remaining tensors without user’s annotations. An ideal partitioning plan can reduce the communication amount, reduce memory footprint, and improve the performance.</p>
<figure>
<img data-src="/images/pasted-94.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>Some unit tests written in <code>tensorflow/compiler/xla/service/sharding_propagation_test.cc</code> are intuitive examples.</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">TEST_P</span>(ParameterizedMetadataTest, BroadcastForwardPass) &#123;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">char</span>* <span class="keyword">const</span> hlo_string = <span class="string">R&quot;(</span></span><br><span class="line"><span class="string">HloModule module</span></span><br><span class="line"><span class="string">ENTRY %broadcast &#123;</span></span><br><span class="line"><span class="string">  %param0 = f32[3,2048,2048]&#123;2,1,0&#125; parameter(0),</span></span><br><span class="line"><span class="string">    sharding=&#123;devices=[1,2,2]0,1,2,3 metadata=&#123;op_name=&quot;a&quot;&#125;&#125;</span></span><br><span class="line"><span class="string">  %broadcast = f32[3,2048,2048,3]&#123;3,2,1,0&#125; broadcast(%param0), dimensions=&#123;0,1,2&#125;</span></span><br><span class="line"><span class="string">  ROOT %copy = f32[3,2048,2048,3]&#123;3,2,1,0&#125; copy(%broadcast)</span></span><br><span class="line"><span class="string">&#125;)&quot;</span>;</span><br><span class="line">  <span class="built_in">TF_ASSERT_OK_AND_ASSIGN</span>(<span class="keyword">auto</span> <span class="keyword">module</span>,</span><br><span class="line">                          <span class="built_in">ParseAndReturnVerifiedModule</span>(hlo_string));</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">GetParam</span>().clear_metadata) &#123;</span><br><span class="line">    <span class="built_in">ClearMetadata</span>(<span class="keyword">module</span>.<span class="built_in">get</span>());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">TF_ASSERT_OK_AND_ASSIGN</span>(</span><br><span class="line">      <span class="keyword">bool</span> changed,</span><br><span class="line">      <span class="built_in">ShardingPropagation</span>(<span class="comment">/*is_spmd=*/</span><span class="literal">false</span>, <span class="built_in">GetParam</span>().propagate_metadata)</span><br><span class="line">          .<span class="built_in">Run</span>(<span class="keyword">module</span>.<span class="built_in">get</span>()));</span><br><span class="line">  <span class="built_in">EXPECT_TRUE</span>(changed);</span><br><span class="line">  <span class="keyword">auto</span>* instruction = <span class="built_in">FindInstruction</span>(<span class="keyword">module</span>.<span class="built_in">get</span>(), <span class="string">&quot;broadcast&quot;</span>);</span><br><span class="line">  <span class="built_in">ASSERT_NE</span>(instruction, <span class="literal">nullptr</span>);</span><br><span class="line">  <span class="built_in">EXPECT_THAT</span>(instruction, op::<span class="built_in">Sharding</span>(<span class="string">&quot;&#123;devices=[1,2,2,1]0,1,2,3&#125;&quot;</span>));</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">GetParam</span>().propagate_metadata &amp;&amp; !<span class="built_in">GetParam</span>().clear_metadata) &#123;</span><br><span class="line">    <span class="built_in">EXPECT_THAT</span>(instruction-&gt;<span class="built_in">sharding</span>(),</span><br><span class="line">                <span class="built_in">ShardingMetadata</span>(&#123;<span class="built_in">CreateMetadata</span>(<span class="string">&quot;a&quot;</span>)&#125;));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">EXPECT_THAT</span>(instruction-&gt;<span class="built_in">sharding</span>(), <span class="built_in">ShardingMetadata</span>(&#123;&#125;));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>It clearly shows that the system inferred the sharding specification of <code>broadcast</code> is <code>&#123;devices=[1,2,2,1]0,1,2,3&#125;</code>according to its input with the attribute <code>&#123;devices=[1,2,2]0,1,2,3&#125;</code>. Note that this test is called <code>BroadcastForwardPass</code>, there also exists a test named <code>BroadcastBackwardPass</code>, which is to say the propagation should be on both directions.</p>
<h2 id="reference">Reference</h2>
<ul>
<li><p>GShard: https://arxiv.org/abs/2006.16668</p></li>
<li><p>GSPMD: https://arxiv.org/abs/2105.04663</p></li>
<li><p>Julia DistributedArrays.jl: https://juliaparallel.github.io/DistributedArrays.jl/latest/index.html</p></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>ESXi 折腾记录</title>
    <url>/2019/06/17/ESXi-%E6%8A%98%E8%85%BE%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h1 id="esxi-镜像添加网卡驱动程序">ESXi 镜像添加网卡驱动程序</h1>
<p><a href="https://www.sysadminstories.com/2018/08/adding-realtek-8111-driver-to-vsphere.html">参考文章</a></p>
<h2 id="安装powercli">1. 安装PowerCLI</h2>
<p>下面的Powershell命令可以直接安装最新版PowerCLI</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PS&gt; Install-Module -Name VMware.PowerCLI</span><br></pre></td></tr></table></figure>
<h2 id="下载esxi驱动包">2. 下载ESXi驱动包</h2>
<p><a href="https://vibsdepot.v-front.de/wiki/index.php/Welcome">下载链接</a></p>
<p>在List of EXSi packages中寻找自己网卡的驱动，我的网卡是Realtek 8168系列的，故下载包net55-r8168</p>
<h2 id="下载vmware-vsphere-hypervisor-esxi-offline-bundle">3. 下载VMware vSphere Hypervisor (ESXi) Offline Bundle</h2>
<p><a href="https://my.vmware.com/web/vmware/details?productId=742&amp;downloadGroup=ESXI67U2">官方下载链接</a></p>
<p><a href="http://ddl6.digiboy.ir/vmware/6.7/VMware-ESXi-6.7.0-8169922-depot.zip">分流下载链接</a> <a href="https://www.v2ex.com/t/448441">本链接来自于V2EX</a></p>
<h2 id="导入bundle到软件仓库">4. 导入Bundle到软件仓库</h2>
<p>假设两个Bundles的放置位置分别为</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">D:\net55-r8168-8.045a-napi-offline_bundle.zip</span><br><span class="line">D:\VMware-ESXi-6.7.0-8169922-depot.zip</span><br></pre></td></tr></table></figure>
<p>通过以下命令导入软件仓库</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PS&gt; Add-EsxSoftwareDepot &quot;D:\net55-r8168-8.045a-napi-offline_bundle.zip&quot;, &quot;D:\VMware-ESXi-6.7.0-8169922-depot.zip&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="创建image-profile">5. 创建Image Profile</h2>
<ol type="1">
<li><p>获取软件仓库中可用的Image Profile <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PS&gt; Get-EsxImageProfile</span><br></pre></td></tr></table></figure></p></li>
<li><p>克隆Image Profile <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PS&gt; New-EsxImageProfile -CloneProfile ESXi-6.7.0-8169922-standard -name ESXi-6.7.0-8169922-standard-RTL8111 -Vendor Tonny </span><br></pre></td></tr></table></figure></p></li>
<li><p>允许导入社区维护的Bundle <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PS&gt; Set-EsxImageProfile -ImageProfile ESXi-6.7.0-8169922-standard-RTL8111 -AcceptanceLevel CommunitySupported</span><br></pre></td></tr></table></figure></p></li>
</ol>
<h2 id="向image-profile导入驱动bundle">6. 向Image Profile导入驱动Bundle</h2>
<ol type="1">
<li>查找某一板卡厂商的Bundle</li>
</ol>
<p>假定查找Realtek的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PS&gt; Get-EsxSoftwarePackage | Where &#123;$_.Vendor -eq &quot;Realtek&quot;&#125;</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>导入驱动Bundle</li>
</ol>
<p>假定Bundle名为net55-r8168</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PS&gt; Add-EsxSoftwarePackage -ImageProfile ESXi-6.7.0-8169922-standard-RTL8111 -SoftwarePackage net55-r8168</span><br></pre></td></tr></table></figure>
<h2 id="导出image-iso">7. 导出Image ISO</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PS&gt; Export-EsxImageProfile -ImageProfile ESXi-6.7.0-8169922-standard-RTL8111 -ExportToIso -filepath D:\VMware-ESXi-6.7.0-8169922-RTL8111.iso</span><br></pre></td></tr></table></figure>
<h1 id="esxi-安装程序崩溃处理">ESXi 安装程序崩溃处理</h1>
<p><a href="https://zhidao.baidu.com/question/242122597991245964.html">参考文章</a> 不得不说百度知道在9102年了还有人好好答题还是有点让人感动的</p>
<p>现象：安装EXSi时提示Shutting down firmware services... Using 'simple offset' UEFI RTS mapping policy</p>
<p>解决办法：显然添加<code>ignoreHeadless=TRUE</code>参数也没救回我电脑，根据评论区dalao提示</p>
<blockquote>
<p>在BIOS中将<code>PCI 64bit Resources Handling</code>里的<code>Above 4G Decoding</code>关掉就好了</p>
</blockquote>
<p>实际上我是在安装EXSi 6.7出现这个问题，64bit寻址是近几年才流行的东西<del>(主要被用在挖矿插6张显卡上)</del>，大概2019年发布的EXSi 6.7 Update 2应该解决这个问题了</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>ESXi</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 学习笔记</title>
    <url>/2019/06/08/Docker-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="docker-自启动">Docker 自启动</h2>
<p>Debian系的系统下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> service docker start</span></span><br></pre></td></tr></table></figure>
<hr />
<h2 id="docker-container-自启动">Docker Container 自启动</h2>
<h4 id="container-restart-policy">Container Restart Policy</h4>
<blockquote>
<p>--restart的可选参数： 1. no (默认值) Container退出时不重启 2. on-failure[:max-retries] exit code非0时重启 3. always 4. unless-stopped</p>
</blockquote>
<p>未创建Container时</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> docker run --restart=always</span></span><br></pre></td></tr></table></figure>
<p>已创建Container时</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> docker update --restart=always CONTAINER</span></span><br></pre></td></tr></table></figure>
<hr />
<h2 id="docker-container-自启动脚本">Docker Container 自启动脚本</h2>
<p>在Container下创建/startup.sh (别忘了执行权限)</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">Your commands</span><br><span class="line"></span><br><span class="line">/bin/bash #阻塞，避免脚本执行完后退出</span><br></pre></td></tr></table></figure>
<p>创建Container</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> docker run -td IMAGE /startup.sh</span> </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Easy way to build a virtual cluster with KVM</title>
    <url>/2020/10/25/Easy-way-to-build-a-virtual-cluster-with-KVM/</url>
    <content><![CDATA[<p><em>Updated on 16 May, 2021.</em> The quality of the original version is not satisfying. I've rearranged this article to make it easier to read, and updated some state-of-art approaches widely used today.</p>
<p>This is my first post written in English, and this post is written for my "underboss" and general Linux users who has a little experience on virtual machines. This time, we are going to build our virtual cluster that is similar to old-school supercomputers, which means our configuration will be some kind of outdated and ugly compared to the latest fancy new clusters, but this configuration is much close to mainstream supercomputers in real world.</p>
<h2 id="overview">Overview</h2>
<p>This tutorial mainly focuses on building a simple cluster in a simple way. Here is the list about the software we will install, and the architecture we will construct later. But, we will discuss some state-of-art technologies in the last section <a href="#Advanced%20Topic">Advanced Topic</a> to help you build a much powerful cluster in practice.</p>
<h3 id="software-minimal-requirements">Software (Minimal Requirements)</h3>
<ul>
<li>Host
<ul>
<li>OS: Ubuntu Server LTS (recommended 18.04 or later)</li>
<li>Virtual Machine Hypervisor: KVM + QEMU + <code>virt-manager</code></li>
</ul></li>
<li>Guest
<ul>
<li>OS: Ubuntu Server LTS</li>
<li>Shared Storage: NFS</li>
</ul></li>
</ul>
<h3 id="architecture">Architecture</h3>
<p>In real world, there are many ways to categorize the nodes of a cluster. For example,</p>
<ul>
<li>Compute Node: Run user applications.</li>
<li>Storage Node: Provide shared storage</li>
<li>Master Node: Monitor the cluster and schedule jobs</li>
<li>Login Node: Provide access points for regular users</li>
</ul>
<p>We let the Master Node in our virtual cluster takes the responsibilities of Storage Node and Login Node. It is fine to merge Master Node, Storage Node, and Login Node together if this virtual cluster is not built for production environment.</p>
<figure>
<img data-src="/images/pasted-74.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h2 id="clusters-vs-pc">Clusters vs PC</h2>
<p>To let you have a better understanding of the concept of what we called <em>cluster</em>, I would like to introduce several different characteristics of clusters compared to a regular PC.</p>
<h3 id="shared-storage">Shared Storage</h3>
<p>Most of the clusters I used before share their storage, because it make the environment consistent. For example, when a user login an arbitrary node, the exact same <code>.bashrc</code> will be loaded. I've listed some important directories that are shared among clusters.</p>
<ul>
<li><code>/home</code>: Directory storing user data</li>
<li><code>/opt</code>: Shared software and libraries (e.g. Intel Compiler)</li>
</ul>
<h3 id="ssh-login-without-password">SSH Login without Password</h3>
<p>Some distributed programs may rely on SSH to control remote machines, such as MPI. Thus, setting up password-less SSH login is required.</p>
<h3 id="user-permission">User Permission</h3>
<p>A regular user should not be granted superuser privileges FOREVER if you don't want anybody abuse the permission to crash the system. Therefore, only the administrators can access to the critical system configuration and install software for all users. The regular user should use the preinstalled software or install software in a gentle way. For instance, using Conda to install software to their home directory or compiling the software from source code. As for account management, we will cover this in <a href="#Advanced%20Topic">Advanced Topic</a>.</p>
<h3 id="job-scheduler">Job Scheduler</h3>
<p>Sometimes we may face the problem of lacking computational resources. This usually occurs in supercomputers since there are some user applications requesting a large amount of resources at the same time. Thus, a job scheduler will allow users to submit their applications and queue for the resources. Since it is not a mandatory component of our cluster, this topic will be discussed further in <a href="#Advanced%20Topic">Advanced Topic</a>.</p>
<h2 id="set-up-kvm-hypervisor-on-host">Set up KVM hypervisor on Host</h2>
<p>You probably have heard <code>VMware</code>, <code>Hyper-V</code> or <code>Virtualbox</code>. <code>KVM</code> is similar to them, which is also capable of creating a highly-isolated virtual environment.</p>
<h3 id="make-sure-virtualization-support-is-enabled">Make sure Virtualization support is enabled</h3>
<p>Some manufacturers disabled CPU Virtualization support for security reasons. Please check your BIOS setting and enable CPU Virtualization support. Besides, KVM kernel module is activated on Ubuntu by default. If you are unsure whether everything is correct, this <a href="https://www.linuxtechi.com/install-configure-kvm-ubuntu-18-04-server/">article</a> will guide you to perform some extra examinations.</p>
<h3 id="install-necessary-software">Install necessary software</h3>
<p>The following simple command will install everything we need, including KVM hypervisor. Note that <code>apt</code> is the corresponding packet manager for Ubuntu, just like <code>yum</code> for CentOS.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo apt install virt-manager</span><br></pre></td></tr></table></figure>
<h2 id="launch-gui-vm-manager">Launch GUI VM Manager</h2>
<p>It is quite hard to create virtual machines under command line interface (CLI) because you have to manually specify a bunch of arguments. Luckily, there is a powerful graphical tool to manage virtual machines, and also there is a simple way called X11 forwarding, which could let a graphical application running on the remote server appear on your screen by forwarding and rendering the graphical data on your computer.</p>
<figure>
<img data-src="/images/pasted-73.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h3 id="for-linux-mac-user">For Linux / Mac User</h3>
<p>For Mac User, one additional software <code>XQuartz</code> is required. <a href="https://www.xquartz.org/">Click here to download</a>.</p>
<p>Append the flag <code>-X</code> to <code>ssh</code> command, then the function <code>X11 Forwarding</code> will be enabled.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">local</span>$ ssh -X 10.x.x.x <span class="comment"># Your Host&#x27;s IP</span></span><br><span class="line">vmhost$ sudo virt-manager</span><br></pre></td></tr></table></figure>
<p>Then you will notice <code>virt-manger</code> is already appeared on your screen.</p>
<h3 id="for-windows-user">For Windows User</h3>
<p>One additional software called <code>VcXsrv</code> is required. <a href="(https://sourceforge.net/projects/vcxsrv/)">Click here to download</a>. Open it, follow the path <code>Multiple windows</code> -&gt; <code>Start a program</code> -&gt; <code>Start a program on remote computer</code>, and fill in your information. <code>Remote program</code> could be <code>virt-manager</code>.</p>
<h2 id="create-the-first-virtual-machine">Create the first virtual machine</h2>
<p>So far, what we have done is colored green, and what we need to configure is colored yellow.</p>
<figure>
<img data-src="/images/pasted-75.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>Create a virtual machine by clicking <img data-src="/images/pasted-76.png" alt="upload successful" />, and configure it as what you want. It is recommended that the memory is larger than 1GiB, and the disk is larger than 20GiB. And I prefer to use <a href="https://ubuntu.com/download/server">CD Image ISO File</a> to install the system. Note that currently this VM should have exact one virtual network adapter working under NAT mode.</p>
<blockquote>
<p>Some Optional Configurations</p>
<ul>
<li>CPU and Memory
<ul>
<li><code>Copy host CPU configuration</code>: helps Guest OS to identify CPU instruction set correctly</li>
<li><code>Manually set CPU topology</code>: may improve performance on NUMA architecture.</li>
</ul></li>
<li>Disk
<ul>
<li><code>qcow</code>: will preallocates a lot of space</li>
<li><code>vmdk</code>: allocates the space on demand</li>
<li><code>VirtIO</code>: improves IO performance</li>
</ul></li>
<li>Network
<ul>
<li><code>NAT</code>: connects to the virtual network</li>
<li><code>macvtap/Bridge</code>: connects to the external network
<ul>
<li>A known bug is that</li>
</ul></li>
<li><code>VirtIO</code>: improves IO performance</li>
</ul></li>
<li>Display VNC
<ul>
<li><code>Spice</code> / <code>VNC</code>: may fix the problem if you cannot input anything to virtual machines</li>
</ul></li>
</ul>
</blockquote>
<p>Then install Ubuntu Server LTS in your favorite way, but don't forget to install OpenSSH Server.</p>
<h2 id="configure-nodes-1st-time">Configure nodes (1st time)</h2>
<p>Our approach to create multiple nodes is to clone the existing nodes. Thus, every modification to the configuration of Master Node will be applied to all the nodes we will have in the future.</p>
<h3 id="install-necessary-software-1">Install necessary software</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">node0$ sudo apt install nfs-kernel-server</span><br></pre></td></tr></table></figure>
<h3 id="create-user-accounts-optional">Create User Accounts (Optional)</h3>
<p>For now, this step is optional because we could create accounts after cloning nodes.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">node0$ sudo adduser user1 <span class="comment"># Create a user called user1</span></span><br><span class="line">node0$ sudo usermod -aG sudo user1 <span class="comment"># Promote a user as a superuser</span></span><br></pre></td></tr></table></figure>
<h3 id="create-opt-directory">Create <code>/opt</code> directory</h3>
<p><code>/opt</code> is a conventional directory that stores the shared software and libraries, but Ubuntu won't create it by default.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo mkdir -p /opt</span><br></pre></td></tr></table></figure>
<h3 id="setup-ssh-login-without-password">Setup SSH Login without Password</h3>
<p>For every user account, execute the following command, and don't forget the <code>root</code> account.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">user1@node0$ sudo su - user2 <span class="comment"># Login as user2</span></span><br><span class="line">user2@node0$ ssh-keygen</span><br><span class="line">user2@node0$ cp .ssh/id_rsa.pub .ssh/authorized_keys</span><br><span class="line">user2@node0$ <span class="built_in">exit</span></span><br><span class="line">user1@node0$</span><br></pre></td></tr></table></figure>
<h3 id="setup-sudo-without-password-optional">Setup sudo without Password (Optional)</h3>
<p>Perhaps you are tired with typing the password when acquiring superuser permissions. Setting password-less sudo may degrade the security of the system, but it is really convenient.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">node0$ sudo visudo</span><br></pre></td></tr></table></figure>
<p>And replace this line with the content below.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># %sudo   ALL=(ALL:ALL) ALL</span></span><br><span class="line">%sudo   ALL=(ALL:ALL) NOPASSWD:ALL</span><br></pre></td></tr></table></figure>
<h3 id="clean-up">Clean up</h3>
<p><code>/etc/machine-id</code> might be generated when you install some software or do something else. However, this ID should vary from machine to machine. If two machines share the same ID, they may get the same IP address from the DHCP server. Therefore, this file should keep empty. Additionally, we utilize <code>cloud-init</code> to generate a new SSH ID for the new machine.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">node0$ sudo su</span><br><span class="line">node0<span class="comment"># echo -n &gt; /etc/machine-id</span></span><br><span class="line">node0<span class="comment"># cloud-init clean</span></span><br></pre></td></tr></table></figure>
<p>Then shutdown Master Node.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">node0<span class="comment"># shutdown now</span></span><br></pre></td></tr></table></figure>
<h2 id="clone-nodes-master---compute-1">Clone nodes (Master -&gt; Compute 1)</h2>
<figure>
<img data-src="/images/pasted-78.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>As we mentioned earlier, all the nodes except Master Node is made by cloning. <code>virt-clone</code> is a good utility to clone virtual machines. Here is the usage.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vmhost$ sudo virt-clone -o node0 -n node1 --auto-clone</span><br></pre></td></tr></table></figure>
<p>After that, we can notice <code>node1</code> shown in the window.</p>
<figure>
<img data-src="/images/pasted-77.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h2 id="configure-nodes-2nd-time">Configure nodes (2nd time)</h2>
<h3 id="on-all-nodes">On All Nodes</h3>
<h4 id="check-ip-address">Check IP address</h4>
<p>Check IP addresses of all the existing nodes.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ip a</span><br></pre></td></tr></table></figure>
<p>And write them to the file <code>hosts.txt</code> on Master Node.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">192.168.122.154 node0</span><br><span class="line">192.168.122.186 node1</span><br></pre></td></tr></table></figure>
<p>Note that all nodes will share the same hostname with Master Node temporarily, and you should specify the hostnames in <code>hosts.txt</code> manually.</p>
<h3 id="on-master-node">On Master Node</h3>
<h4 id="add-a-network-adapter">Add a network adapter</h4>
<p>So far, all the virtual machines have connected to the virtual network (192.168.122.x), but this subnet cannot be accessed by external machines in other subnet (e.g. our campus network 10.x.x.x). Thus, we need to add another adapter to expose our Master Node as the login node.</p>
<p>Click <img data-src="/images/pasted-79.png" alt="upload successful" /> to modify the hardware configuration of Master Node. Then click <code>Add Hardware</code>, select <code>Network</code>, then change the network source from <code>NAT</code> to <code>macvtap</code>. Make sure you choose the correct host adapter, which should connect to external network, like campus network.</p>
<figure>
<img data-src="/images/pasted-80.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>However, the stupid Ubuntu will not automatically initialize the new virtual adapter like Windows. Therefore, we have to manually configure this adapter.</p>
<p>First, figure out what is the name of the new adapter.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">node0$ ip a</span><br><span class="line">1: lo: ...</span><br><span class="line">2: ens3: ...</span><br><span class="line">3: ens9: ...</span><br></pre></td></tr></table></figure>
<p>Our new adapter is called <code>ens9</code>. Then modify the file <code>/etc/netplan/xxx.yaml</code> to add the configuration of <code>ens9</code>.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">network:</span></span><br><span class="line">  <span class="attr">ethernets:</span></span><br><span class="line">    <span class="attr">ens3:</span></span><br><span class="line">      <span class="attr">dhcp4:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">ens9:</span></span><br><span class="line">    	<span class="attr">dhcp4:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">version:</span> <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>Finally, reboot to apply the new configuration.</p>
<h4 id="export-nfs-storage">Export NFS Storage</h4>
<p>Modify the file <code>/etc/exports</code> (<code>sudo</code> required), add the following lines.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/home 192.168.122.0/24(rw,sync,no_root_squash,no_subtree_check)</span><br><span class="line">/opt 192.168.122.0/24(rw,sync,no_root_squash,no_subtree_check)</span><br></pre></td></tr></table></figure>
<p>Then restart <code>NFS</code> service.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo service nfs-kernel-server restart</span><br></pre></td></tr></table></figure>
<h3 id="on-compute-node-1">On Compute Node 1</h3>
<h4 id="import-nfs-storage">Import NFS Storage</h4>
<p>Add the following lines at the end of <code>/etc/fstab</code> (<code>sudo</code> required), then reboot.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">192.168.122.154:/home /home nfs auto,nofail,noatime,nolock,intr,tcp,actimeo=1800 0 0</span><br><span class="line">192.168.122.154:/opt  /opt nfs auto,nofail,noatime,nolock,intr,tcp,actimeo=1800 0 0</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note that this configuration is permanent. The temporary approach is listed here.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo mount 192.168.122.10:/home /tmp/home</span><br><span class="line">$ sudo mount 192.168.122.10:/opt /tmp/opt</span><br></pre></td></tr></table></figure>
</blockquote>
<h4 id="clean-up-again">Clean up again</h4>
<p>Refer to <a href="#Clean%20up">Clean up</a> section to clean up Compute Node 1.</p>
<h2 id="clone-nodes-compute-1---compute-n">Clone nodes (Compute 1 -&gt; Compute N)</h2>
<figure>
<img data-src="/images/pasted-81.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>Refer to <a href="#Clone%20nodes%20(Master%20-%3E%20Compute%201)">Clone nodes (Master -&gt; Compute 1)</a> section and make remaining nodes.</p>
<h2 id="set-hostname-and-hosts">Set Hostname and Hosts</h2>
<p>This is the final step of building our virtual cluster. Do you remember the file <code>hosts.txt</code>, which contains all the IP addresses and the new hostnames? Now it is time to utilize that file to set hostnames and <code>/etc/hosts</code> file. Assume the content of <code>hosts.txt</code> is,</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">192.168.122.154 node0</span><br><span class="line">192.168.122.186 node1</span><br><span class="line">192.168.122.31  node2</span><br><span class="line">192.168.122.129 node3</span><br></pre></td></tr></table></figure>
<p>The magic command below will automatically set the correct hostname and <code>hosts</code> file for each node listed in <code>hosts.txt</code>. Note that this command <strong>must be</strong> executed by <code>root</code>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">TMP=$(mktemp) &amp;&amp; cat hosts.txt | awk -v hosts=<span class="string">&quot;<span class="subst">$(base64 -w 0 hosts.txt)</span>&quot;</span> <span class="string">&#x27;&#123;printf &quot;ssh -o StrictHostKeyChecking=no %s \&quot;echo %s | base64 -d &gt;&gt; /etc/hosts\&quot; &amp; \nssh -o StrictHostKeyChecking=no %s \&quot;hostnamectl set-hostname %s\&quot; &amp; \n&quot;, $1, hosts, $1, $2&#125;&#x27;</span> &gt; <span class="variable">$TMP</span> &amp;&amp; bash <span class="variable">$TMP</span> &amp;&amp; rm <span class="variable">$TMP</span> &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;OK&quot;</span></span><br></pre></td></tr></table></figure>
<p>This is the end of the primary part of this tutorial. You have completed all necessary steps to build your toy cluster. Enjoy it!</p>
<h2 id="advanced-topic">Advanced Topic</h2>
<h3 id="os-deployment">OS Deployment</h3>
<ul>
<li>cloud-init</li>
</ul>
<h3 id="terminal">Terminal</h3>
<ul>
<li>Terminator / iTerm</li>
<li>ClusterSSH / csshX</li>
<li>tmux-cssh</li>
<li>ClusterShell</li>
</ul>
<h3 id="job-scheduler-1">Job Scheduler</h3>
<ul>
<li>IBM Platform LSF</li>
<li>Slurm</li>
</ul>
<h3 id="account-management">Account Management</h3>
<ul>
<li>Kerberos + LDAP</li>
</ul>
<h3 id="shared-storage-1">Shared Storage</h3>
<ul>
<li>BeeGFS</li>
<li>Ceph</li>
</ul>
<h3 id="file-system">File System</h3>
<ul>
<li>Ext4</li>
<li>XFS</li>
<li>Btrfs</li>
<li>ZFS</li>
</ul>
<h3 id="environment-management">Environment Management</h3>
<ul>
<li>Environment Modules</li>
<li>Spack</li>
<li>Conda</li>
</ul>
<p>(To be continued)</p>
<h2 id="acknowledgment">Acknowledgment</h2>
<ul>
<li>Tsinghua student supercomputing team / TUNA</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Easy way to debug TensorFlow XLA Compiler using VSCode</title>
    <url>/2021/08/04/Easy-way-to-debug-TensorFlow-XLA-Compiler-using-VSCode/</url>
    <content><![CDATA[<p>It would be easier to read the source code if we are aware of the runtime information, including call stacks and variable values. This tutorial introduces how to utilize our powerful VSCode to trace XLA Compiler.</p>
<figure>
<img data-src="/images/pasted-82.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h2 id="preparing-environment">Preparing Environment</h2>
<p>Of course we need to download the source code of TensorFlow, and install all the dependencies. I suggest to use Conda to manage the environment, and use build-in GCC on Ubuntu 18.04 (or above, maybe) to build the code. Note that building from source requires about 50GiB of free space.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Fetch Source Code</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/tensorflow/tensorflow.git</span><br><span class="line"><span class="built_in">cd</span> tensorflow</span><br><span class="line"></span><br><span class="line"><span class="comment"># Install dependencies</span></span><br><span class="line">conda create -n tf_dev python numpy wheel -y</span><br><span class="line">conda activate tf_dev</span><br><span class="line">pip install keras_preprocessing</span><br><span class="line">conda install -c conda-forge bazel -y</span><br></pre></td></tr></table></figure>
<h2 id="compile-the-source-code">Compile the source code</h2>
<p>First of all, configure the project and build it.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./configure</span><br><span class="line">bazel build --config=dbg //tensorflow/tools/pip_package:build_pip_package</span><br></pre></td></tr></table></figure>
<p>During the configuration process, it is recommended to choose <strong>ALL</strong> the default options if it is not a must to debug on GPU, since enabling GPU support needs additional configuration (Please refer to <a href="https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md">this article</a>) and much more time to compile.</p>
<p>As for the bazel build flag,</p>
<ul>
<li><code>--config=dbg</code> adds debugging symbols. Required.</li>
<li><code>--config=monolithic</code> should generate the binary code as a single dynamic library. But this option seems to be buggy. Not recommended.</li>
</ul>
<p>Compiling TensorFlow is quite time-consuming, and it took about 20min using 48 CPU threads on my server. Time for coffee now.</p>
<h2 id="pick-a-unit-test-to-compile">Pick a unit test to compile</h2>
<p>In fact, we don't have to write something in Python frontend to trigger breakpoints inside XLA compiler, as there are already tons of unit tests that covers most of codes and demonstrates the capability of the compiler.</p>
<p>Let pick a simple test first to validate the code is compiled correctly.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bazel <span class="built_in">test</span> --config=dbg //tensorflow/compiler/xla/tests:tuple_test_cpu</span><br></pre></td></tr></table></figure>
<p>From the compiling log, we could find the executable file locates at <code>bazel-bin/tensorflow/compiler/xla/tests/tuple_test_cpu</code>. Execute it! If everything works well, the program will print out the message below.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[----------] Global <span class="built_in">test</span> environment tear-down</span><br><span class="line">[==========] 25 tests from 2 <span class="built_in">test</span> suites ran. (3618 ms total)</span><br><span class="line">[  PASSED  ] 25 tests.</span><br></pre></td></tr></table></figure>
<p>Then pick a test you interest, and repeat the steps above.</p>
<h2 id="fix-broken-dependency-optional">Fix broken dependency (Optional)</h2>
<p>Take <code>spmd_partitioner_test</code> as an example. This unit test can be compiled without any error message, but when you directly run the executable, you will see this message.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[ RUN      ] SpmdPartitioningTest.BroadcastAsReplicate3</span><br><span class="line">2021-08-04 10:44:13.324501: I tensorflow/compiler/xla/service/platform_util.cc:72] platform Host present but no XLA compiler available: could not find registered compiler for platform Host -- check target linkage (hint: try adding tensorflow/compiler/jit:xla_cpu_jit as a dependency)</span><br><span class="line">[       OK ] SpmdPartitioningTest.BroadcastAsReplicate3 (6 ms)</span><br></pre></td></tr></table></figure>
<p>This is because this executable is not linked to a valid backend, which means this executable doesn't contain the code of JIT Execution Environment. The solution is modifying the <code>BUILD</code> file manually to fix the dependency as the message suggests.</p>
<p>Open the <code>BUILD</code> file in the directory where the unit test locates. In this example, the test <code>tensorflow/compiler/xla/service/spmd/spmd_partitioner_test.cc</code> corresponds to <code>tensorflow/compiler/xla/service/spmd/BUILD</code>. And add this dependency <code>//tensorflow/compiler/jit:xla_cpu_jit</code>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf_cc_test(</span><br><span class="line">    name = <span class="string">&quot;spmd_partitioner_test&quot;</span>,</span><br><span class="line">    srcs = [<span class="string">&quot;spmd_partitioner_test.cc&quot;</span>],</span><br><span class="line">    deps = [</span><br><span class="line">        <span class="string">&quot;:spmd_partitioner&quot;</span>,</span><br><span class="line">        <span class="string">&quot;//tensorflow/compiler/xla:util&quot;</span>,</span><br><span class="line">        <span class="string">&quot;//tensorflow/compiler/xla:xla_data_proto_cc&quot;</span>,</span><br><span class="line">        <span class="string">&quot;//tensorflow/compiler/xla/service:hlo&quot;</span>,</span><br><span class="line">        <span class="string">&quot;//tensorflow/compiler/xla/service:hlo_casting_utils&quot;</span>,</span><br><span class="line">        <span class="string">&quot;//tensorflow/compiler/xla/service:hlo_matchers&quot;</span>,</span><br><span class="line">        <span class="string">&quot;//tensorflow/compiler/xla/service:hlo_parser&quot;</span>,</span><br><span class="line">        <span class="string">&quot;//tensorflow/compiler/xla/service:hlo_pass_pipeline&quot;</span>,</span><br><span class="line">        <span class="string">&quot;//tensorflow/compiler/xla/service:hlo_verifier&quot;</span>,</span><br><span class="line">        <span class="string">&quot;//tensorflow/compiler/xla/tests:hlo_test_base&quot;</span>,</span><br><span class="line">        <span class="string">&quot;//tensorflow/compiler/xla/tests:xla_internal_test_main&quot;</span>,</span><br><span class="line">        <span class="string">&quot;//tensorflow/compiler/jit:xla_cpu_jit&quot;</span>,</span><br><span class="line">        <span class="string">&quot;//tensorflow/core:test&quot;</span>,</span><br><span class="line">    ],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="configuring-vscode">Configuring VSCode</h2>
<p>Since the unit test was built as an executable with debugging symbols, there is nothing special about the configuration of VSCode. Install <code>C/C++</code> Extension, and write the following lines to <code>.vscode/launch.json</code>.</p>
<blockquote>
<p>You could open that json file by clicking <code>ctrl/command</code>+<code>shift</code>+<code>p</code>, typing <code>launch.json</code>, and selecting <code>Add Configuration</code> -&gt; <code>C/C++: (gdb) Launch</code></p>
</blockquote>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;(gdb) Launch&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;cppdbg&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;request&quot;</span>: <span class="string">&quot;launch&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;program&quot;</span>: <span class="string">&quot;$&#123;workspaceFolder&#125;/bazel-bin/tensorflow/compiler/xla/service/spmd/spmd_partitioner_test&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;args&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;stopAtEntry&quot;</span>: <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">&quot;cwd&quot;</span>: <span class="string">&quot;$&#123;workspaceFolder&#125;&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;environment&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;externalConsole&quot;</span>: <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">&quot;MIMode&quot;</span>: <span class="string">&quot;gdb&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;setupCommands&quot;</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">&quot;description&quot;</span>: <span class="string">&quot;Enable pretty-printing for gdb&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;text&quot;</span>: <span class="string">&quot;-enable-pretty-printing&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;ignoreFailures&quot;</span>: <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Everything is all set! Press <code>F5</code> to start debugging.</p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://www.tensorflow.org/install/source#ubuntu">https://www.tensorflow.org/install/source#ubuntu</a></li>
<li><a href="https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md">https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Everything you need to know about Splitting NCCL Communicators</title>
    <url>/2021/12/15/Everything-you-need-to-know-about-Splitting-NCCL-Communicators/</url>
    <content><![CDATA[<p>MPI allows to create a new communicator by splitting an existing one into a sub-communicator, which can make our program dynamically select a subset of computing nodes to involve in the collective communication operations, such as all-reduce and all-gather operations. NCCL also has a similar feature, but it is not well-documented yet.</p>
<h2 id="tldr">TL;DR</h2>
<p>Since NCCL relies on MPI to run on multiple nodes, the following example code is based on MPI Programming Model. Assume there are 4 CUDA GPUs and 4 corresponding MPI ranks. This code performs all-reduce operation within the first two and the last two ranks simultaneously.</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;nccl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mpi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdint.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thrust/device_ptr.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thrust/fill.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">MPI_Init</span>(<span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">  <span class="keyword">int</span> world_size, world_rank;</span><br><span class="line">  <span class="built_in">MPI_Comm_size</span>(MPI_COMM_WORLD, &amp;world_size);</span><br><span class="line">  <span class="built_in">MPI_Comm_rank</span>(MPI_COMM_WORLD, &amp;world_rank);</span><br><span class="line">  <span class="built_in">assert</span>(world_size == <span class="number">4</span>);</span><br><span class="line">  <span class="built_in">cudaSetDevice</span>(world_rank); <span class="comment">// GPU N binds to MPI rank N</span></span><br><span class="line"></span><br><span class="line">  ncclUniqueId nccl_id, nccl_ids[<span class="number">4</span>];</span><br><span class="line">  <span class="keyword">size_t</span> id_size = <span class="built_in"><span class="keyword">sizeof</span></span>(ncclUniqueId);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Generate Unique ID */</span></span><br><span class="line">  <span class="comment">// nccl_id is a simple struct with the size of exact 128 bytes</span></span><br><span class="line">  <span class="comment">// so it can be transferred over MPI</span></span><br><span class="line">  <span class="built_in">ncclGetUniqueId</span>(&amp;nccl_id);</span><br><span class="line">  <span class="built_in">MPI_Allgather</span>(&amp;nccl_id, id_size, MPI_UINT8_T,</span><br><span class="line">                &amp;nccl_ids[<span class="number">0</span>], id_size, MPI_UINT8_T, MPI_COMM_WORLD);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Create a sub-communicator */</span></span><br><span class="line">  ncclComm_t nccl_comm;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (world_rank &lt;= <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="built_in">ncclCommInitRank</span>(&amp;nccl_comm, <span class="number">2</span>, nccl_ids[<span class="number">0</span>], world_rank);</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (world_rank &gt;= <span class="number">2</span>) &#123;</span><br><span class="line">    <span class="built_in">ncclCommInitRank</span>(&amp;nccl_comm, <span class="number">2</span>, nccl_ids[<span class="number">2</span>], world_rank - <span class="number">2</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Test */</span></span><br><span class="line">  <span class="keyword">constexpr</span> <span class="keyword">size_t</span> N = (<span class="keyword">size_t</span>)<span class="number">1e3</span>;</span><br><span class="line">  <span class="keyword">constexpr</span> <span class="keyword">size_t</span> arr_size = <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">int64_t</span>) * N;</span><br><span class="line">  <span class="keyword">void</span> *arr, *arr_host;</span><br><span class="line">  <span class="built_in">cudaMalloc</span>(&amp;arr, arr_size);</span><br><span class="line">  <span class="built_in">cudaMallocHost</span>(&amp;arr_host, arr_size);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* Init the array on local GPU */</span></span><br><span class="line">  <span class="function">thrust::device_ptr&lt;<span class="keyword">int64_t</span>&gt; <span class="title">arr_ptr</span><span class="params">((<span class="keyword">int64_t</span>*)arr)</span></span>;</span><br><span class="line">  thrust::<span class="built_in">fill</span>(arr_ptr, arr_ptr + N, world_rank);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">ncclAllReduce</span>(arr, arr, N, ncclInt64, ncclSum, nccl_comm, <span class="literal">NULL</span>);</span><br><span class="line">  <span class="built_in">cudaMemcpy</span>(arr_host, arr, arr_size, cudaMemcpyDeviceToHost);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;[rank%d] result: %ld\n&quot;</span>, world_rank, ((<span class="keyword">int64_t</span>*)arr_host)[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">MPI_Finalize</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>This code can be compiled and run on my machine with these commands,</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nvcc -ccbin mpic++ test.cu -o <span class="built_in">test</span> -L/usr/<span class="built_in">local</span>/cuda/lib -lnccl</span><br><span class="line">mpirun -n 4 ./<span class="built_in">test</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: Using <code>nvcc</code> to compile MPI code is not a common practice. It is recommended to compile it with <code>mpic++</code> from a CUDA-Aware MPI variant.</p>
</blockquote>
<p>The output of this program should be,</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[rank0] result: 1 <span class="comment"># 0 + 1 = 1</span></span><br><span class="line">[rank1] result: 1</span><br><span class="line">[rank2] result: 5 <span class="comment"># 2 + 3 = 5</span></span><br><span class="line">[rank3] result: 5</span><br></pre></td></tr></table></figure>
<p><strong>The key is <code>ncclCommInitRank</code>. Suppose only a subset of ranks initializes the communicator with the same unique ID belonging to one of them. In that case, this communicator will ignore other ranks that are not in this subset.</strong></p>
<h2 id="usage-of-ncclcomminitrank">Usage of ncclCommInitRank</h2>
<blockquote>
<p>Official API explanation:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">ncclResult_t <span class="title">ncclCommInitRank</span><span class="params">(ncclComm_t *comm, <span class="keyword">int</span> nranks, ncclUniqueId commId, <span class="keyword">int</span> rank)</span></span></span><br></pre></td></tr></table></figure>
<p>Creates a new communicator (multi thread/process version). rank must be between <code>0</code> and <code>nranks-1</code> and unique within a communicator clique. Each rank is associated to a CUDA device, which has to be set before calling <code>ncclCommInitRank</code>. <code>ncclCommInitRank</code> implicitly synchronizes with other ranks, so it must be called by different threads/processes or use <code>ncclGroupStart</code>/<code>ncclGroupEnd</code>.</p>
</blockquote>
<p>In addition to the official instructions, we should also know,</p>
<ul>
<li>Each unique ID should only be used once.</li>
<li><code>ncclGetUniqueId</code> can be invoked multiple times, and it will return a different unique ID each time. Meanwhile, the unique ID generated before is still working.</li>
<li>It is safe to communicate within disjoint subsets of nodes simultaneously.</li>
<li>Using NCCL to perform inter-GPU communication concurrently with CUDA-aware MPI may create deadlocks.</li>
</ul>
<h2 id="performance">Performance</h2>
<p>Moreover, I also evaluate the influence on performance bring by sub-grouping.</p>
<p>The testbed is,</p>
<ul>
<li>AWS <code>g4dn.metal</code> instance with 8x NVIDIA Tesla T4 GPUs.</li>
<li>Shipped with AWS Deep Learning AMI
<ul>
<li>OS: Ubuntu 18.04 (Kernel Version: Linux 5.4)</li>
<li>CUDA Toolkit: 11.0 (Driver Version: 450.119.03 )</li>
</ul></li>
</ul>
<p>First of all, I would like to emphasize the GPU topology of this bare-metal machine.</p>
<blockquote>
<p>Note: We should extract the topology information from physical machines instead of virtual machines since the hypervisor may fuzz the result due to security reasons.</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># nvidia-smi topo -m</span></span><br><span class="line">        GPU0    GPU1    GPU2    GPU3    GPU4    GPU5    GPU6    GPU7    CPU Affinity    NUMA Affinity</span><br><span class="line">GPU0     X      PHB     NODE    NODE    SYS     SYS     SYS     SYS     0-23,48-71      0</span><br><span class="line">GPU1    PHB      X      NODE    NODE    SYS     SYS     SYS     SYS     0-23,48-71      0</span><br><span class="line">GPU2    NODE    NODE     X      PHB     SYS     SYS     SYS     SYS     0-23,48-71      0</span><br><span class="line">GPU3    NODE    NODE    PHB      X      SYS     SYS     SYS     SYS     0-23,48-71      0</span><br><span class="line">GPU4    SYS     SYS     SYS     SYS      X      PHB     NODE    NODE    24-47,72-95     1</span><br><span class="line">GPU5    SYS     SYS     SYS     SYS     PHB      X      NODE    NODE    24-47,72-95     1</span><br><span class="line">GPU6    SYS     SYS     SYS     SYS     NODE    NODE     X      PHB     24-47,72-95     1</span><br><span class="line">GPU7    SYS     SYS     SYS     SYS     NODE    NODE    PHB      X      24-47,72-95     1</span><br></pre></td></tr></table></figure>
<p>It looks like a balanced tree topology. We could expect two neighbor GPUs will have higher communication efficiency.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">UPI                   </span><br><span class="line"> |--CPU0              </span><br><span class="line"> |   |--PCIe Switch   </span><br><span class="line"> |   |   |--GPU0      </span><br><span class="line"> |   |   |--GPU1      </span><br><span class="line"> |   |--PCIe Switch   </span><br><span class="line"> |       |--GPU2      </span><br><span class="line"> |       |--GPU3      </span><br><span class="line"> |--CPU1              </span><br><span class="line">     |--PCIe Switch   </span><br><span class="line">     |   |--GPU4      </span><br><span class="line">     |   |--GPU5      </span><br><span class="line">     |--PCIe Switch   </span><br><span class="line">         |--GPU6      </span><br><span class="line">         |--GPU7      </span><br></pre></td></tr></table></figure>
<p>The result below is measured on the root rank, and each experiment is repeated 5 times. Meanwhile, the environment <code>CUDA_VISIBLE_DEVICES</code> was set to reorder GPUs binded to MPI ranks. CPU binding remains unset.</p>
<p>And the meaning of the notations on communicators is,</p>
<ul>
<li><code>0/1</code>: Only one communicator performing all-reduce on physical GPU 0/1.</li>
<li><code>0/1 + 2/3</code>: Two communicators are working at the same time, and each of them perform all-reduce on two GPUs independently.</li>
<li><code>0-7</code>: Equivalent to <code>0/1/2/.../6/7</code>.</li>
</ul>
<figure>
<img data-src="/images/pasted-95.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>From the result above, we can conclude that,</p>
<ul>
<li>GPUs are working at PCIe Gen3 x8 mode as the PCIe Switch splits one PCIe x16 slot into two x8 slots.
<ul>
<li>Double checked by <code>nvidia-smi --query-gpu=pcie.link.gen.current --format=csv</code> and <code>sudo lspci -vvv</code></li>
</ul></li>
<li>The GPU Topology will significantly affect the performance of all-reduce.
<ul>
<li>The topology that NVIDIA DGX adopt should obviously accelerate collective communication operations.</li>
</ul></li>
<li>The interference between two concurrent communicators is not quite noticeable.</li>
<li>UPI bus is not a bottleneck when two PCIe Gen3 x16 devices (PCIe Switches) transmit a large data chunk over UPI bus.</li>
</ul>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/mpi.html#inter-gpu-communication-with-cuda-aware-mpi">NCCL and MPI — NCCL 2.11.4 documentation (nvidia.com)</a></li>
<li><a href="https://developer.nvidia.com/blog/fast-multi-gpu-collectives-nccl/">Fast Multi-GPU collectives with NCCL</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>GPU Hackathon 2019 日记</title>
    <url>/2019/08/12/GPU-Hackathon-2019-%E6%97%A5%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="gpu-hackathon-介绍">1. GPU Hackathon 介绍</h2>
<p>据NVIDIA的员工说，GPU Hackathon 最早是美国橡树岭国家实验室发起的，因为在近些年，GPU的架构非常适合执行并行计算，GPGPU的概念流行后，显卡的GPU可以支持大规模的并行计算，并行计算的速度远超CPU，所以当时的橡树岭在他们的超算平台上配置了不少的GPU。但是如果想用GPU加速计算的话，就需要修改自己的程序，使得程序能够运行在GPU上，然而在当时编写GPU加速代码的门槛比较高，很少的程序能够充分利用GPU的性能，所以橡树岭希望举办一些活动推广GPU计算的技术。后来NVIDIA作为一个GPU厂商，自然也希望更多的用户学会使用GPU，这样他们就能卖出更多的显卡。</p>
<p>这个活动的流程是这样的，每一支队伍拿出自己原先运行在CPU上的程序，然后在为期5天的活动中，NVIDIA会为每一支队伍安排两名导师，在导师的指导下我们修改自己的代码。此外，每一天每个组都要做一个简单的报告，介绍自己的进展，瓶颈，和下一步的工作。最后，会有一场大型的报告，各组总结自己的工作，并汇报所取得的加速效果。</p>
<h2 id="活动前的准备">2. 活动前的准备</h2>
<p>GPU Hackathon建议我们提前两周，团队就要开始进行一些初步的工作。然而，我因为假期参加了NUS Summer Workshop，活动开始前两天我才回到了学校。</p>
<p>我们组实际上被划分为两个小组，每个小组会负责一份代码的优化，另一个组的成员全部是我们学校力学与航空航天系的一位教授的课题组的研究生和研究助理，而我们组都是对并行计算感兴趣的本科生，我们要优化的代码也是他们课题组提供的。</p>
<p>活动开始前几天的晚上，我去到他们的课题组，大家简单的介绍了一下自己，接着他们打包了一份原始代码让我先看看。他们的代码都是用Fortran写的，我一开始觉得我学过不少现代的高级编程语言，看懂这古老的高级编程语言应该不是什么困难的事，然而后来活动开始后，事情越来越不妙了。</p>
<h2 id="困难和坑">3. 困难和坑</h2>
<p>踩坑可以说是第一天就开始踩，不过对于这点我还是有所心理准备的，只不过我没有预计到之后我天天踩而已。</p>
<h3 id="day-1-2">Day 1-2</h3>
<p>第一天我们小组还好，还有一个经验丰富的学长坐镇，踩坑可以一起踩，摔得没有那么惨。我们遇到的第一个问题就是VPN登录不了。一般来说，超算的全部节点，包括登录节点全部隐藏在内网里，需要用一个VPN隧道访问内网，其实这就是VPN最原始的工作。NVIDIA的测试集群也是如此，需要借助一个叫NVIDIA Next Generation VPN Gateway的东西才能连接到测试集群。然而一开始我们去下载客户端Cisco Anyconnect Secure Mobility Client的时候，官网先让你注册，注册后告诉你你没资格下载。接着我们试着从第三方网站下载客户端，不是版本太老就是版本太新。最后发现NVIDIA有提供客户端下载，安装后发现连接不上深圳上海北京香港的Gateway，直到连接美国的Gateway才连接上并下载配置文件，借助配置文件才能连接其他国家的Gateway。其实最迷惑人的是，NVIDIA的工程师再次期间也不知道怎么办。</p>
<p>解决VPN的问题花掉了上午大部分时间，接着试着编译他们课题组给的Fortran代码。首先使用Linux Environment Modules这种古老的东西配置环境。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">module load PrgEnv/PGI+OpenMPI/2018-03-19</span><br><span class="line">module load cuda</span><br><span class="line">module load pgi</span><br><span class="line">module load openmpi</span><br></pre></td></tr></table></figure>
<p>CUDA是NVIDIA GPU的支持库，PGI是个编译器，OpenMPI是CPU进程间通信使用的库，Hackathon主要推广的技术是OpenACC，这个库由CUDA和PGI支持。</p>
<p>本想一句make编译一遍过，又不是什么大工程像什么CESM这种编译起来一堆坑的，结果这份代码却依赖一个极其古老的库，FFTW2，1999年last updated，连SSE这种古老的SIMD指令都没用上的东西。与此同时在NVIDIA的测试集群只有FFTW3的库。更加坑的事情是，FFTW3的接口完全不兼容FFTW2的，这就意味着要是修改原始代码以适配FFTW3，那工作量够我们喝一壶的。学长直接按照README编译FFTW2，想编译出静态链接库，结果因为时代变迁，当时写的编译脚本已经不能在现在的系统下运行了。我一开始试着去解包CentOS的FFTW2的yum二进制包，得到了动态链接库和头文件，编译是能编译了，但是运行程序的时候动态链接库不在指定路径里，并且我们的权限不能将动态链接库复制到指定路径下。不得已，只能借助Arch Linux编译安装的脚本去编译FFTW2，才得到了静态链接库。</p>
<h3 id="day-2-3">Day 2-3</h3>
<p>从第二天起，那位经验丰富的学长就跑路去准备雅思了。成功编译后，工程师发现，使用命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -np 40 ./main</span><br></pre></td></tr></table></figure>
<p>可以用40个进程运行，然而在使用20个进程运行程序的时候，MPI就会引发错误。工程师让我去排查问题的原因。起初我想用GDB之类的debugger，结果我发现GDB只能trace一个进程，而且往往不是trace的进程出错。于是我想用古老的print打印日志法调试，然而40个进程同时将log连同错误信息异步打印到屏幕上，根本不知道错误信息是哪个进程引发的，好死不死因为MPI出错导致MPI_Barrier也不工作了。然后我想着用stderr重定向错误信息到文件，在C语言里用freopen轻松实现，结果Fortran里没有这种函数。最后只能一句句的修改代码，让程序运行到某个位置终止程序，从而判断哪一行代码引发MPI错误。最后发现是block分割时相关代码，将进程数除8,也就意味着进程数需要是8的整数倍。滑稽的是，相关代码附近的注释写着，慎重处理8这个数，没有文档谁知道这个事。</p>
<h3 id="day-3-4">Day 3-4</h3>
<p>解决了MPI问题，random seed的相关代码引发了Runtime error，我看了一眼代码的上下文，又看了一遍上下文，还是没看懂这代码在干什么，于是我先问候了代码的作者的家人，再去问候“代码的作者”，然而“代码的作者”说这部分代码应该是十年前教授在美国的学生写的，他只是直接拿来用，但是他强调在Intel编译器下代码没有问题。一顿搜索猛如虎后发现Intel编译器的random seed的array size是2，同时PGI编译器的random seed的size是37。但是在我接触过的语言里，random seed就是个数，而不是数组，难怪我看不懂这段代码。</p>
<h3 id="day-4-5">Day 4-5</h3>
<p>代码能在CPU上运行了，与此同时其他组已经开始取得数十倍甚至百倍的加速效果了，哪怕这段代码跑出来的结果未必正确，先做个性能分析再直接加上OpenACC导语先跑起来再说。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -np 40 nvprof --cpu-profiling on --cpu-profiling-mode top-down --annotate-mpi openmpi  -o output.%h.%p.%q&#123;OMPI_COMM_WORLD_RANK&#125; ./main</span><br><span class="line"><span class="comment"># command to get the profiling results</span></span><br></pre></td></tr></table></figure>
<p>使用上面这段命令既可启动NVPROF，配合NVIDIA Visual Profiler就可以做性能分析，加上NVTX的话就可以增加tag，对自定义的代码片段进行性能分析。</p>
<p>但是，运行nvprof的时候又引发了工程师都不知道怎么发生的错误，结果去掉<code>--annotate-mpi openmpi</code>这个开关就可以正常运行了，反正也不知道为什么就好了。</p>
<p>加上OpenACC导语后又引发了CUDA Kernel的错误，一番排查后发现Fortran的数组支持负数的下标，然而OpenACC隐性生成copyin代码的时候对数组大小识别错误，调整了导语后可以在GPU上运行。</p>
<p>然而不知道为什么，用GPU加速的程序比原来慢了很多，打开Profiler一看，显示只有一个GPU一个SMX的一个CUDA核心在运行串行的程序，换句话说就是一核有难，20479核围观。</p>
<p>在工程师的建议下，在活动结束之前，程序能够跑满一块GPU了，但是因为运算结果保存在GPU上，CPU需要取得这些数据时，CUDA为了维护Unified Memory的一致性开销巨大，在Profiler中大块大块的时间片都是Memory Page Fault。</p>
<p>最终我们运行在GPU上的程序的计算速度和原始版本相近，并行计算节约下来的时间全部被数据离散传输消耗。</p>
<h2 id="总结">4. 总结</h2>
<p>总的来说，还是很感谢深圳超算中心和NVIDIA提供的这次宝贵的踩坑经验，所谓的程序员的经验其实绝大部分就是踩坑和从坑里跳出来的经验，对于很多人来说，他们连踩坑的机会都没有，毕竟这种核武器级的设施也不是随随便便就能接触到的。同时也要致敬那些用超算科研的科学家，因为在超算上还能看到大量上个世纪的计算机痕迹，实话说这玩意是真的很难用好，为了取得更高的计算效率需要付出大量的努力，然后代码变得难以维护和移植，而且科研是漫长的过程，维护上古代码也不是什么轻松的事情。</p>
<p>加上导语后却引发了CUDA Kernel的错误，一番排查后发现Fortran的数组支持负数的下标，然而OpenACC隐性生成copyin代码的时候对数组大小识别错误，调整了导语后可以在GPU上运行。</p>
]]></content>
      <categories>
        <category>吹水日记</category>
      </categories>
      <tags>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title>Google 可搜索资源</title>
    <url>/2020/01/20/Google-%E5%8F%AF%E6%90%9C%E7%B4%A2%E8%B5%84%E6%BA%90/</url>
    <content><![CDATA[<h2 id="gpu-cuda-相关">GPU &amp; CUDA 相关</h2>
<h3 id="search-keywords">Search Keywords</h3>
<ul>
<li><code>site: on-demand-gtc.gputechconf.com filetype:pdf</code></li>
</ul>
<h3 id="openacc">OpenACC</h3>
<ul>
<li><a href="https://www.openacc.org/sites/default/files/inline-files/OpenACC_Programming_Guide_0.pdf">OpenACC Programming and Best Practices Guide</a></li>
<li><a href="https://docs.nvidia.com/hpc-sdk/compilers/openacc-gs/index.html">OpenACC Getting Started Guide</a></li>
<li><a href="https://www.nvidia.com/docs/IO/117377/directives-tips-for-c.pdf">12 Tips for Maximum Performance with PGI Directives in C</a></li>
</ul>
<h3 id="cuda-new-features">CUDA New features</h3>
<ul>
<li><a href="http://on-demand.gputechconf.com/gtc/2018/presentation/s8278-cuda-new-features-and-beyond.pdf">CUDA New features</a></li>
</ul>
<h3 id="cuda-unified-memory">CUDA Unified Memory</h3>
<ul>
<li><a href="http://on-demand.gputechconf.com/gtc/2018/presentation/s8430-everything-you-need-to-know-about-unified-memory.pdf">Unified Memory</a></li>
</ul>
<h3 id="cuda-multi-gpu">CUDA Multi GPU</h3>
<ul>
<li><a href="http://on-demand.gputechconf.com/gtc/2014/presentations/S4236-multi-gpu-programming-mpi.pdf">MULTI GPU PROGRAMMING WITH MPI</a>
<ul>
<li>Debug <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpiexec -x -np 2 xterm -e cuda-gdb ./myapp &lt;args&gt;</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><a href="http://on-demand.gputechconf.com/gtc-eu/2017/presentation/23031-jiri-kraus-multi-gpu-programming-models.pdf">MULTI-GPU PROGRAMMING MODELS</a>
<ul>
<li>GPU/CPU AFFINITY <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nvidia-smi topo –m</span><br></pre></td></tr></table></figure></li>
</ul></li>
</ul>
<h3 id="cuda-compute-capability">CUDA Compute Capability</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/CUDA">CUDA - Wiki</a></li>
</ul>
<h3 id="cuda-pro-tip">CUDA Pro Tip</h3>
<ul>
<li><a href="https://devblogs.nvidia.com/cuda-pro-tip-control-gpu-visibility-cuda_visible_devices/">CUDA_VISIBLE_DEVICES</a></li>
</ul>
<h3 id="cuda-aware-mpi">CUDA-aware MPI</h3>
<ul>
<li><a href="https://developer.nvidia.com/mpi-solutions-gpus">MPI Solutions for GPUs</a></li>
<li><a href="https://anhnguyen.me/2013/12/how-to-mix-mpi-and-cuda-in-a-single-program/">How to mix MPI and CUDA in a single program</a></li>
<li><a href="https://www.olcf.ornl.gov/wp-content/uploads/2018/12/summit_workshop_CUDA-Aware-MPI.pdf">GPUDIRECT, CUDAAWARE MPI, &amp; CUDA IPC</a></li>
<li><a href="http://fisica.cab.cnea.gov.ar/gpgpu/images/charlas/multi_gpu_programming_with_mpi.pdf">MULTI GPU PROGRAMMING (WITH MPI)</a></li>
</ul>
<h3 id="cuda-nvtx">CUDA NVTX</h3>
<ul>
<li><a href="https://devblogs.nvidia.com/cuda-pro-tip-generate-custom-application-profile-timelines-nvtx/">CUDA Pro Tip: Generate Custom Application Profile Timelines with NVTX</a></li>
<li><a href="https://stackoverflow.com/questions/56605670/finding-the-nvidia-toolkit-extensions-library-with-cmake">Finding the nVIDIA Toolkit Extensions library with CMake</a></li>
</ul>
<h2 id="cpu">CPU</h2>
<h3 id="simd">SIMD</h3>
<ul>
<li><a href="http://www.jos.org.cn/html/2015/6/4811.htm">SIMD自动向量化编译优化概述</a></li>
</ul>
<h2 id="神威">神威</h2>
<h3 id="search-keyword">Search Keyword</h3>
<ul>
<li><code>site: bbs.nsccwx.cn filetype:pdf</code></li>
</ul>
<h3 id="tutorial-optimization">Tutorial &amp; Optimization</h3>
<ul>
<li><a href="http://bbs.nsccwx.cn/assets/uploads/files/1528120200586-cpc%E5%9F%B9%E8%AE%AD_%E7%A5%9E%E5%A8%81%E5%A4%AA%E6%B9%96%E4%B9%8B%E5%85%89%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B%E4%B8%8E%E4%B8%8A%E6%9C%BA%E5%AE%9E%E8%B7%B5.pdf">神威太湖之光并行编程与上机实践</a></li>
<li><a href="http://bbs.nsccwx.cn/assets/uploads/files/1529047771770-%E7%A5%9E%E5%A8%81%E5%A4%AA%E6%B9%96%E4%B9%8B%E5%85%89%E9%AB%98%E7%BA%A7%E8%BF%9B%E9%98%B6.pdf">神威太湖之光高级进阶</a></li>
<li><a href="http://bbs.nsccwx.cn/assets/uploads/files/1528178274621-%E5%A4%AA%E6%B9%96%E4%B9%8B%E5%85%89%E4%B8%8A%E7%9A%84%E5%B9%B6%E8%A1%8C%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1-%E8%96%9B%E5%B7%8Dv2.0.pdf">太湖之光上的并行算法设计</a></li>
<li><a href="http://bbs.nsccwx.cn/assets/uploads/files/1519436304069-%E7%A5%9E%E5%A8%81%E5%A4%AA%E6%B9%96%E4%B9%8B%E5%85%89%E5%B9%B6%E8%A1%8C%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E4%BC%98%E5%8C%96.pdf">神威太湖之光并行程序设计与优化</a></li>
</ul>
<h3 id="compiler">Compiler</h3>
<ul>
<li><a href="http://bbs.nsccwx.cn/assets/uploads/files/1519435987239-%E7%A5%9E%E5%A8%81%E5%A4%AA%E6%B9%96%E4%B9%8B%E5%85%89%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E6%89%8B%E5%86%8C.pdf">神威太湖之光编译系统用户手册</a></li>
</ul>
<h3 id="profile">Profile</h3>
<ul>
<li><a href="http://bbs.nsccwx.cn/assets/uploads/files/1529544400336-decode-%E7%94%B3%E5%A8%8126010%E5%A4%84%E7%90%86%E5%99%A8%E6%80%A7%E8%83%BD%E5%B7%A5%E5%85%B7%E7%AE%80%E6%98%93%E6%89%8B%E5%86%8C-v3.6.pdf">申威26010处理器性能工具简易手册</a></li>
</ul>
<h3 id="library">Library</h3>
<ul>
<li><a href="https://dxhisboy.github.io/shenwei-doc/">神威编译手册速查工具</a></li>
</ul>
<h3 id="paper">Paper</h3>
<ul>
<li><a href="https://dl.acm.org/doi/pdf/10.1145/3295500.3356165?download=true">OpenKMC: a KMC Design for Hundred-Billion-Atom Simulation Using Millions of Cores on Sunway Taihulight</a></li>
</ul>
]]></content>
      <categories>
        <category>学习资料</category>
      </categories>
  </entry>
  <entry>
    <title>HP DL360e G8 服务器静音化</title>
    <url>/2019/10/18/HP-DL360e-G8-%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%9D%99%E9%9F%B3%E5%8C%96/</url>
    <content><![CDATA[<p>HP DL360e G8是一个买回来就嗡嗡嗡的服务器，我一开始以为服务器已经把噪音自动控制到最优，后来在网上冲浪的时候发现我错了。</p>
<p>无意间在Reddit上看到<a href="https://www.reddit.com/r/homelab/comments/8q4mg2/is_30_fan_speed_normal_at_idle_in_a_dl360e_gen8/">这么篇讨论</a></p>
<blockquote>
<p>It's a bit complicated with the e-Series because of the shitty RAID controller, but I'll try to guide you to low rpm: (~21-23%)</p>
</blockquote>
<blockquote>
<ol type="1">
<li>Check that none of the typical fan ramp up stuff applies (use original HP drives, no PCI-e cards)</li>
<li>Make sure you set your BIOS to use the RAID controller (even if you don't use the drives as a raid)</li>
<li>Go into the smart storage thing when booting and setup your drives. If you don't want to use RAID just create RAID0 configs for each single drive.</li>
<li>Boot into the Service Pack, since the SPP has the necessary drivers the fans should spin down after a while to about 21-23% Alternative to 4: I also got them to spin down by installing the HP provided ESXi image which has the necessary drivers preinstalled. The fans spin down after about 1-2 minutes.</li>
</ol>
</blockquote>
<blockquote>
<p>The reason for its weird behavior is the B120i RAID controller. It NEEDS to see it working via their proprietary drivers (hpvsa) to spin down the fans to their minimum. I couldn't get them farther below 21-23% which was still too loud for office use IMO and too restricted for me (couldn't get the fans to spin down running proxmox).</p>
</blockquote>
<blockquote>
<p>That all said, I'd recommend to ditch the server and sell it if you need a quiet server. They completed dropped the ball on the *e Gen8 servers. Just look into the official forums how they basically ignored their customers for years, promised firmware updates to fix the noise issues and then never delivered.</p>
</blockquote>
<p>简而言之就是服务器的RAID卡，和PCI-E插槽上的东西会控制服务器风扇的转速。不信的话你可以先在BIOS设置里把SATA控制器从AHCI改成RAID以激活RAID卡，并启动HPE提供的SPP光盘上的系统，就可以观察到风扇转速从降到21%~23%。</p>
<p>这么操作后，我的服务器风扇转速从33%降到了左半侧18<sub>23%，右半侧27%。我一开始以为右半侧插的那张声卡不碍事，把声卡拔掉以后右半侧风扇转速也降到了18</sub>23%。</p>
<p>这意味着降低噪音需要激活RAID卡并且正确安装<code>hpvsa</code>RAID卡驱动，才能让服务器安静下来。md真是个智障的设计。</p>
<h2 id="我的硬盘呢">我的硬盘呢？</h2>
<p>自从RAID卡被激活以后，硬盘和主板之间的通信就被RAID卡接管了，不配置RAID阵列的话就看不到硬盘了。</p>
<p>上网冲浪了一段时间又发现了一个YouTube上的视频：<a href="https://www.youtube.com/watch?v=JuaezJd4C3I">How to turn HP Smart array raid controller to HBA - Mode</a>。简单来说就是用HPE提供的SPP里隐藏的Console修改RAID卡参数，来激活<code>HPA模式</code>，这样就可以配置硬盘直通了。</p>
<p>首先我们需要弄到SPP，HPE只将SPP提供给保修期内的服务器的其指定的维护人员。还好民间人才多，似乎有中东国家的人吧SPP的镜像分享出来了。</p>
<p>SPP可以顺便把我服务器上各部分的固件更新了。我一开始下载了<a href="http://www.kaixinit.com/server/gen8/1750.html">SPP 2019版</a>, 启动以后发现这个版本的SPP主要面向Gen9+，对于Gen8只提供基本的ILO固件更新。于是用回了最后一版面向Gen8的<a href="http://www.kaixinit.com/server/gen8/2002.html">SPP 2017版</a>。</p>
<p>更新完固件以后按照视频的步骤操作，发现总是失败。用修改RAID卡的命令查询RAID卡的信息，发现这破B120i压根就不支持<code>HPA模式</code>。</p>
<p>网上也有人说每一个磁盘初始化成一个RAID0阵列就好了。没办法只得照做。</p>
<h2 id="我装了个假系统">我装了个假系统？</h2>
<p>之前Reddit上的讨论提到了可以安装HPE定制的ESXI系统，自带了相应的RAID卡固件。我一开始用的是最新版的ESXI 6.7，尽管官网上说仅支持Gen9+的服务器，但有热心网友说Gen8用了也没啥问题。装完以后发现风扇又嗡嗡嗡的响，转速回到了33%的水平。进系统一看这个版本的系统连<code>hpvsa</code>的驱动包都没有。换回了ESXI 6.5 For Gen8，风扇才安静了下来。</p>
<h2 id="我硬盘的内容没了">我硬盘的内容没了？</h2>
<p>我有一块4TB硬盘用作FreeNAS系统的存储池。重装了FreeNAS以后发现找不到存储池了，然后用dmesg一看内核日志，有检测到硬盘分区表存在致命错误的报告。我将硬盘分配到Ubuntu系统下，试图用Ubuntu的gdisk工具去修复分区表。gdisk工具检测到分区表里第二分区的大小超出了硬盘的容量。</p>
<p>然后我又看到<a href="https://superuser.com/questions/560682/how-to-fix-a-corruptedtoo-big-gpt">一篇文章</a>，说因为硬盘被划为RAID0阵列，硬盘的一部分区域划为<code>Host Protected Area</code>，理论上HPA操作系统不可见，但是可以检测到是否存在HPA了，不出意外，确实检测到硬盘上存在HPA区域。比较好的解决办法就是将硬盘拔下来插到普通电脑上，把数据导出来，在服务器上格式化后再把数据导回来。</p>
<p>我设想应该可以调整ZFS分区大小，把HPA区域空出来，这样就没啥问题了吧。但问题来了，HPA区域在硬盘上的哪里？分析一下，硬盘头部的GPT分区表还在，尾部的备份GPT分区表也在，那HPA到底在哪里？</p>
]]></content>
      <categories>
        <category>吹水日记</category>
      </categories>
      <tags>
        <tag>Server</tag>
      </tags>
  </entry>
  <entry>
    <title>HPC常用编译选项和性能分析及调试方法</title>
    <url>/2020/11/07/HPC%E5%B8%B8%E7%94%A8%E7%BC%96%E8%AF%91%E9%80%89%E9%A1%B9%E5%92%8C%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%8F%8A%E8%B0%83%E8%AF%95%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="常用编译选项">常用编译选项</h1>
<h2 id="icc编译器">ICC编译器</h2>
<h3 id="环境准备">环境准备</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> /opt/intel/bin/compilervars.sh intel64</span><br><span class="line"><span class="built_in">source</span> /opt/intel/bin/iccvars.sh intel64</span><br><span class="line"><span class="built_in">source</span> /opt/intel/vtune_profiler/env/vars.sh</span><br></pre></td></tr></table></figure>
<h3 id="icc编译链接-openmp-openmpi">ICC编译链接: OpenMP + OpenMPI</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpicxx -std=c++11 -g -fopenmp -O3 -xhost -qopt-report=5 -qopt-report-phase=vec -cxx=icc</span><br></pre></td></tr></table></figure>
<h2 id="pgi-nvcc编译器">PGI + NVCC编译器</h2>
<h3 id="环境准备-1">环境准备</h3>
<p>向<code>~/.modulerc</code>添加以下代码给Environment Modules导入文件夹<code>/opt/pgi/modulefiles</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">module use /opt/pgi/modulefiles</span><br></pre></td></tr></table></figure>
<p>启动Environment Modules</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile.d/modules.sh</span><br></pre></td></tr></table></figure>
<p>然后启动PGI环境</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">module load pgi-nollvm</span><br><span class="line">module load pgi/19.10</span><br><span class="line">module load openmpi</span><br></pre></td></tr></table></figure>
<p>添加NVIDIA工具链路径</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/cuda-11.1/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
<h3 id="pgi编译openacc-openmp-openmpi">PGI编译：OpenACC + OpenMP + OpenMPI</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpicxx -std=c++11 -I/usr/<span class="built_in">local</span>/cuda-11.1/include -g -O3 -mp=numa -acc -Minfo=accel -ta=tesla:cc60 -fast</span><br></pre></td></tr></table></figure>
<h3 id="nvcc编译-cuda-openmpi">NVCC编译: CUDA + OpenMPI</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nvcc -lineinfo -g -O3 -std=c++11 -gencode arch=compute_60,code=sm_60 -ccbin=mpicxx</span><br></pre></td></tr></table></figure>
<h3 id="pgi链接">PGI链接</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpicxx -std=c++11 -I/usr/<span class="built_in">local</span>/cuda-11.1/include -g -O3 -mp=numa -acc -Minfo=accel -ta=tesla:cc60 -fast -lnvToolsExt -lcudart -L/usr/<span class="built_in">local</span>/cuda-11.1/lib64</span><br></pre></td></tr></table></figure>
<h1 id="性能分析方法">性能分析方法</h1>
<h2 id="intel-vtune性能分析">Intel Vtune性能分析</h2>
<h3 id="环境准备-2">环境准备</h3>
<p>同<code>ICC</code>环境准备</p>
<h3 id="gui启动分析">GUI启动分析</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vtune-gui &amp;</span><br></pre></td></tr></table></figure>
<h3 id="cli启动分析">CLI启动分析</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/opt/intel/vtune_profiler_2020.1.0.607630/bin64/vtune -collect hpc-performance -finalization-mode=full -app-working-dir /home/tonny -- /home/tonny/myscript</span><br></pre></td></tr></table></figure>
<p><code>myscript</code>是一个包含了启动环境变量，用<code>mpirun</code>启动目标程序的脚本</p>
<h2 id="nvidia-profiler性能分析">NVIDIA Profiler性能分析</h2>
<h3 id="环境准备-3">环境准备</h3>
<p>添加NVIDIA工具链路径</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/cuda-11.1/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
<p>推荐使用Java 8，NVVP不兼容高版本Java</p>
<h3 id="cli启动分析-1">CLI启动分析</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -np 4 nvprof --cpu-profiling on --cpu-profiling-mode top-down --annotate-mpi openmpi  -o output.%h.%p.%q&#123;OMPI_COMM_WORLD_RANK&#125;.nvvp ./myprogram</span><br></pre></td></tr></table></figure>
<h1 id="调试方法">调试方法</h1>
<h2 id="多进程多窗口gdb调试">多进程多窗口GDB调试</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -np 4 xterm gdb ./myprogram</span><br><span class="line">mpirun -np 4 xterm cuda-gdb ./myprogram</span><br></pre></td></tr></table></figure>
<h2 id="多进程单窗口gdb调试">多进程单窗口GDB调试</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -np 1 gdb ./myprogram : -np 3 ./myprogram</span><br><span class="line">mpirun -np 1 cuda-gdb ./myprogram : -np 3 ./myprogram</span><br></pre></td></tr></table></figure>
<h2 id="pgi-gui调试">PGI GUI调试</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pgdbg ./myprogram</span><br></pre></td></tr></table></figure>
<h1 id="调试技巧">调试技巧</h1>
<h2 id="cuda-gdb查看显存上数组">CUDA-GDB查看显存上数组</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span> ((@global double*)arr)[0]@100</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>Hexo Next主题添加Utterances评论系统</title>
    <url>/2020/05/20/Hexo-Next%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0Utterances%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>当前网上有很多给Hexo NexT主题添加Utterances评论系统的教程，但是这些实现并没有充分利用Hexo的特性，所以我参考了其他评论模块的代码，将Utterances模块插入到文章中。</p>
<h2 id="过程">过程</h2>
<h3 id="创建utterances.swig">创建<code>utterances.swig</code></h3>
<p>在<code>layout/_third-party/comments</code>里创建<code>utterances.swig</code>，内容如下</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&#123;%- if page.comments %&#125;</span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="javascript"></span></span><br><span class="line"><span class="javascript">NexT.utils.loadComments(<span class="built_in">document</span>.querySelector(<span class="string">&#x27;#utterances-container&#x27;</span>), <span class="function">() =&gt;</span> &#123;</span></span><br><span class="line"><span class="javascript">    <span class="comment">// if (typeof parcelRequire === &#x27;function&#x27;) &#123; return; &#125;</span></span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> js = <span class="built_in">document</span>.createElement(<span class="string">&#x27;script&#x27;</span>);</span></span><br><span class="line"><span class="javascript">    js.type = <span class="string">&#x27;text/javascript&#x27;</span>;</span></span><br><span class="line"><span class="javascript">    js.src = <span class="string">&#x27;https://utteranc.es/client.js&#x27;</span>;</span></span><br><span class="line"><span class="javascript">    js.async = <span class="literal">true</span>;</span></span><br><span class="line"><span class="javascript">    js.crossorigin = <span class="string">&#x27;anonymous&#x27;</span>;</span></span><br><span class="line"><span class="javascript">    js.setAttribute(<span class="string">&#x27;repo&#x27;</span>, <span class="string">&#x27;&#123;&#123; theme.utterances.repo &#125;&#125;&#x27;</span>);</span></span><br><span class="line"><span class="javascript">    js.setAttribute(<span class="string">&#x27;issue-term&#x27;</span>, <span class="string">&#x27;&#123;&#123; theme.utterances.issue_term &#125;&#125;&#x27;</span>);</span></span><br><span class="line"><span class="javascript">    js.setAttribute(<span class="string">&#x27;theme&#x27;</span>, <span class="string">&#x27;&#123;&#123; theme.utterances.theme &#125;&#125;&#x27;</span>);</span></span><br><span class="line"><span class="javascript">    <span class="built_in">document</span>.getElementById(<span class="string">&#x27;utterances-container&#x27;</span>).appendChild(js);</span></span><br><span class="line"><span class="javascript">&#125;);</span></span><br><span class="line"><span class="javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">&#123;%- endif %&#125;</span><br></pre></td></tr></table></figure>
<h3 id="创建utterances.js">创建<code>utterances.js</code></h3>
<p>在<code>scripts/filters/comment</code>下创建<code>utterances.js</code>，内容如下</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* global hexo */</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">&#x27;use strict&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> path = <span class="built_in">require</span>(<span class="string">&#x27;path&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Add comment</span></span><br><span class="line">hexo.extend.filter.register(<span class="string">&#x27;theme_inject&#x27;</span>, <span class="function"><span class="params">injects</span> =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">let</span> theme = hexo.theme.config;</span><br><span class="line">  <span class="keyword">if</span> (!theme.utterances.enable) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">  injects.comment.raw(<span class="string">&#x27;utterances&#x27;</span>, <span class="string">&#x27;&lt;div class=&quot;comments&quot; id=&quot;utterances-container&quot;&gt;&lt;/div&gt;&#x27;</span>, &#123;&#125;, &#123;<span class="attr">cache</span>: <span class="literal">true</span>&#125;);</span><br><span class="line"></span><br><span class="line">  injects.bodyEnd.file(<span class="string">&#x27;utterances&#x27;</span>, path.join(hexo.theme_dir, <span class="string">&#x27;layout/_third-party/comments/utterances.swig&#x27;</span>));</span><br><span class="line"></span><br><span class="line">&#125;);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="修改主题配置文件">修改主题配置文件</h3>
<p>在主题配置文件中添加</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">utterances:</span> </span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">&quot;你的repo地址&quot;</span></span><br><span class="line">  <span class="attr">issue_term:</span> <span class="string">&quot;pathname&quot;</span></span><br><span class="line">  <span class="attr">theme:</span> <span class="string">&quot;github-light&quot;</span></span><br></pre></td></tr></table></figure>
<p>关于配置选项的更多信息可参考<a href="https://utteranc.es/">官方网站</a>.</p>
<h2 id="分析">分析</h2>
<p>在<code>swig</code>文件中调用了<code>NexT</code>提供的函数来插入评论模块，查看这个函数的源码的话可以发现这个函数其实是个观察者，用来Lazyload评论模块的。</p>
<p>而<code>js</code>文件是一个以相对正式的方法在<code>document</code>的评论里精准插入一个用来attach新元素的div标签，相当于指定了新添加的Utterances显示的位置。</p>
<h2 id="已知问题">已知问题</h2>
<p>似乎有部分地区的网络不能加载这个评论模块，至少我的移动宽带是不能直接加载这个模块的，大概这就是NexT没集成这个模块的原因吧。</p>
]]></content>
  </entry>
  <entry>
    <title>Hexo 第一次魔改全记录</title>
    <url>/2020/01/12/Hexo-%E7%AC%AC%E4%B8%80%E6%AC%A1%E9%AD%94%E6%94%B9%E5%85%A8%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h2 id="hexo-pug-主题修改-非典型教程">Hexo Pug 主题修改 非典型教程</h2>
<p>为了庆祝2020年的到来和大二上学期的结束，<del>（其实是越来越觉得博客太丑了）</del>，我决定对半岁大的博客<del>痛下杀手</del>全面改造。</p>
<p>这一次改造的目标是： - 提高可读性 - 美化界面 - 推广博客<del>，以假装是dalao</del></p>
<h2 id="选择合适的主题">1. 选择合适的主题</h2>
<figure>
<img data-src="https://github.com/blackshow/hexo-theme-freemind.386/raw/master/free386-screenshot.png" alt="freemind" /><figcaption>freemind</figcaption>
</figure>
<p>这是我之前用的主题<code>freemind</code>，并且在原来的主题上进行魔改，<del>使得博客看起来更丑的同时降低了可读性</del></p>
<p>顺着终端风的思路，我找到了一个和终端有那么一丝丝关系的主题<code>terminal</code></p>
<figure>
<img data-src="https://github.com/lazysheep666/terminal_theme/raw/master/Preview.png" alt="terminal" /><figcaption>terminal</figcaption>
</figure>
<p>选择这个主题的理由很简单，可读性极佳，审美在线，把杂七杂八的东西扔进终端里，让页面的其他部分变得非常简洁</p>
<h2 id="魔改主题">2. 魔改主题</h2>
<p>部署这个主题没几秒，就发现了这个主题虽然好，但是我不太满意的地方也有不少</p>
<h3 id="配置文件解析部分">配置文件解析部分</h3>
<p>原来配置文件的格式是这样的</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">Sheep:</span></span><br><span class="line">  <span class="attr">education:</span> </span><br><span class="line">    <span class="attr">typ:</span> <span class="string">string</span></span><br><span class="line">    <span class="attr">val:</span> <span class="string">BUPT</span></span><br><span class="line">  <span class="attr">github:</span></span><br><span class="line">    <span class="attr">typ:</span> <span class="string">link</span></span><br><span class="line">    <span class="attr">val:</span> <span class="string">github.com/lazysheep666</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">https://github.com/lazysheep666</span></span><br></pre></td></tr></table></figure>
<p>这段配置会在终端上生成这样的代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; Sheep.education</span><br><span class="line">BUPT</span><br><span class="line">&gt; Sheep.github</span><br><span class="line">github.com/lazysheep666</span><br></pre></td></tr></table></figure>
<p>乍一看没啥毛病，但是这样输出内容的形式其实是比较固定的，输入一行前缀固定，输出只有一行，输出复杂内容就不太行了，而且编写配置文件也比较麻烦</p>
<p>于是我干脆就重写配置文件解析部分，现在配置文件看起来像这样</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">about:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">pwd:</span></span><br><span class="line">    <span class="attr">cmd:</span> <span class="string">whoami</span></span><br><span class="line">    <span class="attr">outputs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">text:</span> <span class="string">NekoDaemon</span></span><br><span class="line">        <span class="attr">ending:</span> <span class="string">&quot;@&quot;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">type:</span> <span class="string">url</span></span><br><span class="line">        <span class="attr">url:</span> <span class="string">https://github.com/Tonny-Gu</span></span><br><span class="line">        <span class="attr">text:</span> <span class="string">GitHub</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">pwd:</span></span><br><span class="line">    <span class="attr">cmd:</span> <span class="string">whereis</span> <span class="string">me</span></span><br><span class="line">    <span class="attr">outputs:</span></span><br><span class="line">      <span class="string">...</span></span><br></pre></td></tr></table></figure>
<p>其中，配置的格式如下 - pwd 终端显示的工作目录 - cmd 终端执行的命令 - outputs 命令执行后输出的结果 参数类型是yaml的array - text 终端输出的文字 - type 输出的格式 - (无) 普通文本格式 - url 超链接，打开新选项卡 - url_intra 超链接，不打开新选项卡 - ending 结尾的文字 - (无) 换行 - (str) 输出str里的内容</p>
<p>最终效果如下 <img data-src="/images/pasted-21.png" alt="upload successful" /></p>
<p>其中解析的代码写在<code>terminal-util.pug</code>文件里</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mixin _terminal_render_outputs(outputs)</span><br><span class="line">  ...</span><br><span class="line">  each output in outputs</span><br><span class="line">    case output.type</span><br><span class="line">      when &quot;url&quot;</span><br><span class="line">        a(href= output.url class=&quot;code-pl-output-url&quot; target=&quot;_blank&quot;)</span><br><span class="line">          span(class=&quot;code-pl-output&quot;)= output.text</span><br><span class="line">      ...</span><br><span class="line">    if output.ending</span><br><span class="line">      span(class=&quot;code-pl-output&quot;)= output.ending</span><br><span class="line">      - hasNewLine = false</span><br><span class="line">    else</span><br><span class="line">      br</span><br><span class="line">      ...</span><br><span class="line"></span><br><span class="line">mixin terminal_exec(pwd, cmd, outputs)</span><br><span class="line">  if pwd</span><br><span class="line">    - pwd = &quot;/&quot;+pwd</span><br><span class="line">  | #&#123;config.author&#125;:~#&#123;pwd&#125;$</span><br><span class="line">  |</span><br><span class="line">  span(class=&quot;code-pl-input&quot;)= cmd</span><br><span class="line">  br</span><br><span class="line">  if outputs</span><br><span class="line">    +_terminal_render_outputs(outputs)</span><br><span class="line"></span><br><span class="line">mixin terminal_print_cmd_in_yaml(yaml_array)</span><br><span class="line">  if yaml_array</span><br><span class="line">    each yaml in yaml_array</span><br><span class="line">      +terminal_exec(yaml.pwd, yaml.cmd, yaml.outputs)</span><br><span class="line">      br</span><br></pre></td></tr></table></figure>
<p>这里面有三个相关函数 - _terminal_render_outputs 解析并渲染命令输出结果部分 - terminal_exec 渲染模拟执行命令的效果 - 函数自身渲染输入部分 - 调用了_terminal_render_outputs渲染输出部分 - 参数格式和yaml中的格式相同 - terminal_print_cmd_in_yaml 解析yaml设置中的数据 - 调用了terminal_exec渲染单条命令 - 典型用法: (来源: <code>terminal.pug</code>) <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if is_current(&quot;/about&quot;)</span><br><span class="line">  +terminal_print_cmd_in_yaml(theme.terminal.about)</span><br></pre></td></tr></table></figure></p>
<h3 id="恢复categories页">恢复Categories页</h3>
<figure>
<img data-src="/images/pasted-22.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p><code>Terminal</code>主题最新的commit是修了一个越界的bug，解决方法是干掉categories页</p>
<p>这个解决方法和其代码风格一样粗犷放肆，贴一段给你们感受一下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- var fileName = page.title || &#x27;home&#x27;</span><br><span class="line">- var objNames = []</span><br><span class="line">each obj, objName in theme.terminal</span><br><span class="line">  - objNames.push(objName)</span><br><span class="line">- var flag = 0</span><br><span class="line">if page.title === &#x27;about&#x27;</span><br><span class="line">  - flag = 1</span><br><span class="line">else if page.title === &#x27;tags&#x27;</span><br><span class="line">  - flag = 2</span><br><span class="line">else if is_post()</span><br><span class="line">  - flag = 3</span><br><span class="line">- var objName = objNames[flag]</span><br><span class="line">#terminal-pl</span><br><span class="line">  #top-bar</span><br><span class="line">    ...</span><br><span class="line">  #code-pl</span><br><span class="line">    ...</span><br><span class="line">    if flag === 2</span><br><span class="line">      include ./terminal/terminal-tags.pug</span><br><span class="line">    else if flag === 3</span><br><span class="line">      include ./terminal/terminal-categories.pug</span><br><span class="line">    else if flag === 4</span><br><span class="line">      include ./terminal/terminal-post.pug</span><br></pre></td></tr></table></figure>
<p>于是我干脆就把这段重写了，毕竟乔老人家说过不仅要追求外在美，内在……至少不能丑</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">include ./terminal/terminal-util.pug</span><br><span class="line"></span><br><span class="line">#terminal-pl</span><br><span class="line">  #top-bar</span><br><span class="line">    ...</span><br><span class="line">  #code-pl</span><br><span class="line">    if is_home()</span><br><span class="line">      +terminal_print_cmd_in_yaml(theme.terminal.home)</span><br><span class="line">      include ./terminal/terminal-home.pug</span><br><span class="line">    if is_post()</span><br><span class="line">      +terminal_print_cmd_in_yaml(theme.terminal.post)</span><br><span class="line">      include ./terminal/terminal-post.pug</span><br><span class="line">    if is_current(&quot;/categories&quot;)</span><br><span class="line">      +terminal_print_cmd_in_yaml(theme.terminal.categories)</span><br><span class="line">      include ./terminal/terminal-categories.pug</span><br><span class="line">      +terminal_print_archives()</span><br><span class="line">    if is_current(&quot;/tags&quot;)</span><br><span class="line">      +terminal_print_cmd_in_yaml(theme.terminal.tags)</span><br><span class="line">      include ./terminal/terminal-tags.pug</span><br><span class="line">      +terminal_print_archives()</span><br><span class="line">    if is_current(&quot;/about&quot;)</span><br><span class="line">      +terminal_print_cmd_in_yaml(theme.terminal.about)</span><br></pre></td></tr></table></figure>
<p>值得注意的是这里用了一些Hexo的<a href="https://hexo.io/zh-cn/docs/helpers">内置函数</a> &gt; - is_home 检查当前页面是否为首页 - is_post 检查当前页面是否为文章 - is_current 检查<code>path</code>是否符合目前页面的网址</p>
<p>其实Hexo也提供了<code>is_category</code>和<code>is_tag</code>函数，但是我测试后发现这两个函数并不能使用</p>
<p>代码改完以后自然而然的，Categories页就回归了，毕竟原来的代码没删掉</p>
<h3 id="归档">归档</h3>
<p>虽然Hexo原生支持归档页，但是<code>Terminal</code>主题并没有相关代码，我觉得单独给归档页写代码，写样式，占用导航栏一格空间又不是很值得</p>
<p>当我看到Tags页和Categories页的Terminal空空如也的时候就决定，把归档扔在这两页的Terminal里</p>
<p>还是在<code>terminal-util.pug</code>文件里写下生成归档信息的代码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mixin terminal_print_archives()</span><br><span class="line">  - var posts_by_year = []</span><br><span class="line">  each article in site.posts.data</span><br><span class="line">    - var year_non_exist = true</span><br><span class="line">    each archive in posts_by_year</span><br><span class="line">      if archive.year == date(article.date, &quot;YYYY&quot;)</span><br><span class="line">        - year_non_exist = false</span><br><span class="line">        - archive.posts.push(article)</span><br><span class="line">    if year_non_exist</span><br><span class="line">      - posts_by_year.push(&#123;year:date(article.date, &quot;YYYY&quot;), posts:[article]&#125;)</span><br><span class="line">  </span><br><span class="line">  each archive in posts_by_year</span><br><span class="line">    - archive.posts.sort(function(a, b) &#123;return date(b.date, &quot;MMDD&quot;)-date(a.date, &quot;MMDD&quot;)&#125;)</span><br><span class="line">  - posts_by_year.sort(function(a, b) &#123;return b.year-a.year&#125;)</span><br><span class="line"></span><br><span class="line">  each archive in posts_by_year</span><br><span class="line">    +terminal_exec(&quot;blog/archives&quot;, &quot;tar -xf &quot;+archive.year+&quot;.tar &amp;&amp; ls posts&quot;, false)</span><br><span class="line">    +terminal_print_titles(archive.posts)</span><br><span class="line">    br</span><br></pre></td></tr></table></figure>
<p>简单来说就是 - 先根据文章创建年份将文章扔进不同数组里 - 对数组进行排序 - 先给月日进行排序，再对年份进行排序 - 值得注意的是，这里用了date函数生成指定格式的时间信息，用sort函数进行排序，sort函数需要提供一个比较函数 - 输出结果</p>
<p>最终的效果如下 <img data-src="/images/pasted-23.png" alt="upload successful" /></p>
<h3 id="显示相同tag的文章">显示相同tag的文章</h3>
<p>这部分的代码写在<code>terminal-post/pug</code>文件里，代码比较简单，和归档的代码比较相似 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">+terminal_exec(&quot;blog&quot;, &quot;grep -lr $TAGS post&quot;, false)</span><br><span class="line"></span><br><span class="line">- var articles = []</span><br><span class="line">if page.tags.data</span><br><span class="line">  each article in site.posts.data</span><br><span class="line">    if article.tags.data</span><br><span class="line">      - var isRelated = false</span><br><span class="line">      each tag in article.tags.data</span><br><span class="line">        each val in page.tags.data </span><br><span class="line">          if val.name == tag.name</span><br><span class="line">            - isRelated = true</span><br><span class="line">      if isRelated</span><br><span class="line">        - articles.push(article)</span><br><span class="line"></span><br><span class="line">+terminal_print_titles(articles)</span><br></pre></td></tr></table></figure></p>
<p>最终的效果如下，我还顺便改掉了原先的信息显示方式，压缩了一下空间</p>
<figure>
<img data-src="/images/pasted-28.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h3 id="评论">评论</h3>
<p>一开始我是移植了disqus评论系统，从<code>maupassant-hexo</code>这个主题里找到了<a href="https://github.com/tufu9441/maupassant-hexo/blob/master/layout/_partial/comments.pug">相关的代码</a>，然后截取了<del>我看得懂的</del>一段代码</p>
<p>修改后的代码在<code>disqus.pug</code>文件里</p>
<p>配置<code>_config.yml</code>，写上shortname，即可使用disqus，例如 <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">disqus:</span> <span class="string">NekoDaemon</span></span><br></pre></td></tr></table></figure></p>
<p>考虑到国内很多人无法加载disqus，那就很有必要把无法加载的提示做得好看一点</p>
<p>原来的代码如下 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if theme.disqus</span><br><span class="line">  #disqus_thread</span><br><span class="line">    .btn_click_load</span><br><span class="line">      button.disqus_click_btn 阅读评论（请确保 Disqus 可以正常加载）</span><br></pre></td></tr></table></figure></p>
<p>被改成了这样 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if theme.disqus</span><br><span class="line">  #disqus_thread</span><br><span class="line">    .btn_click_load</span><br><span class="line">      div.disqus_click_btn </span><br><span class="line">        a.article-comment 阅读评论（请确保 Disqus 可以正常加载）</span><br></pre></td></tr></table></figure></p>
<p>并在<code>post.styl</code>文件中添加<del>复制</del><code>article-comment</code>按钮样式 <figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.article-more</span></span><br><span class="line">  <span class="keyword">@extend</span> <span class="variable">$btn</span></span><br><span class="line">  <span class="attribute">float</span>: right</span><br><span class="line"><span class="selector-class">.article-comment</span></span><br><span class="line">  <span class="keyword">@extend</span> <span class="variable">$btn</span></span><br></pre></td></tr></table></figure></p>
<p>又考虑到，什么都没考虑，就是看到了<a href="https://harrychen.xyz/2019/02/09/enable-comments/">巨佬的这篇文章</a>，就决定换<a href="https://utteranc.es/">utterances</a>评论系统了</p>
<p>简单来说这个系统是借助了GitHub的帐号系统，并把评论存在我的repo的issues里，具体的配置过程非常简单，参考官网即可，另外还需要在主题里嵌入一个js，嵌入的代码如下，我把这段代码保存在<code>utterances.pug</code>里 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if theme.utterances</span><br><span class="line">  script(type=&#x27;text/javascript&#x27;</span><br><span class="line">    src= &quot;https://utteranc.es/client.js&quot;</span><br><span class="line">    repo= theme.utterances</span><br><span class="line">    issue-term= &quot;pathname&quot;</span><br><span class="line">    theme= &quot;github-light&quot;</span><br><span class="line">    crossorigin= &quot;anonymous&quot;</span><br><span class="line">    async= true)</span><br></pre></td></tr></table></figure></p>
<p>并找到文章的模板<code>post.pug</code>，然后include这个pug文件，顺便给评论套一个和文章正文一模一样的样式 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">extends includes/layout.pug</span><br><span class="line"></span><br><span class="line">block content</span><br><span class="line">  article#post</span><br><span class="line">    a.article-title= page.title || &#x27;No Title&#x27;</span><br><span class="line">    time.article-date #[i(class=&quot;fa fa-calendar&quot; aria-hidden=&quot;true&quot;)] !&#123;date(page.date, config.date_format)&#125;</span><br><span class="line">    != page.content</span><br><span class="line">  if theme.disqus</span><br><span class="line">    article#post</span><br><span class="line">      include includes/disqus.pug</span><br><span class="line">  if theme.utterances</span><br><span class="line">    article#post</span><br><span class="line">      include includes/utterances.pug</span><br><span class="line">  include includes/pagination.pug</span><br></pre></td></tr></table></figure></p>
<p>最终的效果如下（现在已关闭disqus评论功能）</p>
<figure>
<img data-src="/images/pasted-25.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>断网的效果</p>
<figure>
<img data-src="/images/pasted-26.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h3 id="友情链接">友情链接</h3>
<p>造博客的乐趣之一不就是加友链吗，现在的人们加什么微信，加个友链不是充满逼格吗（雾）</p>
<p>友链被我放在了Terminal里，代码比较简单，在<code>terminal-links.pug</code>里，在合适的地方include即可使用 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">include terminal-util.pug</span><br><span class="line"></span><br><span class="line">- var outputs = []</span><br><span class="line">each url, name in theme.terminal.Links</span><br><span class="line">  - outputs.push(&#123;type:&quot;url&quot;, url:url, text:name&#125;)</span><br><span class="line">+terminal_exec(&quot;blog&quot;, &quot;curl dalao.orz&quot;, outputs)</span><br><span class="line">br</span><br></pre></td></tr></table></figure></p>
<p>其中配置文件的格式如下 <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">terminal:</span></span><br><span class="line">  <span class="attr">Links:</span></span><br><span class="line">    <span class="attr">spinmry:</span> <span class="string">https://blog.spinmry.moe</span></span><br><span class="line">    <span class="attr">laekov:</span> <span class="string">https://laekov.com.cn</span></span><br></pre></td></tr></table></figure></p>
<p>特别感谢以上两位dalao，他们分别是线上碰到的第一个主动加我友链的，和线下碰到的第一个主动加友链的人，最终效果如下</p>
<figure>
<img data-src="/images/pasted-29.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h3 id="版权声明">版权声明</h3>
<p>其实折腾版权声明对我来说最大的作用就是限制抄袭课程作业的人的行为。在查重的时候被老师误杀，与老师argue的时候，我可以声称我允许对方使用我的代码，但必须署名，抄袭的同学没有保留署名所以是他的错</p>
<p>但是原先的主题并没有这方面考虑，所以在<code>footer.pug</code>文件把原先的内容 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">p.design-info</span><br><span class="line">  | power by #[a(href=&quot;https://hexo.io&quot; target=&quot;_blank&quot;) Hexo] | theme #[a(href=&quot;https://github.com/lazysheep666/terminal_theme&quot; target=&quot;_blank&quot;) Teminal]</span><br><span class="line">p.copyright= `Copyright © $&#123;config.author&#125; Blog $&#123;new Date().getFullYear()&#125;` </span><br></pre></td></tr></table></figure> 换成 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">p.design-info</span><br><span class="line">  | Powered by #[a(href=&quot;https://hexo.io&quot; target=&quot;_blank&quot;) Hexo] | Theme #[a(href=&quot;https://github.com/lazysheep666/terminal_theme&quot; target=&quot;_blank&quot;) Teminal] (#[a(href=&quot;https://github.com/Tonny-Gu/terminal_theme&quot; target=&quot;_blank&quot;) NekoDaemon Remix])</span><br><span class="line">p.design-info</span><br><span class="line">  a(href=theme.license.url target=&quot;_blank&quot;)= theme.license.name</span><br><span class="line">  | </span><br><span class="line">  | Licensed | Copyright © #&#123;new Date().getFullYear()&#125; #&#123;config.author&#125;</span><br></pre></td></tr></table></figure></p>
<p>并且在<code>_config.yml</code>里加上 <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">license:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">CC-BY-SA</span> <span class="number">4.0</span></span><br><span class="line">  <span class="attr">url:</span> <span class="string">https://creativecommons.org/licenses/by-sa/4.0/</span></span><br></pre></td></tr></table></figure></p>
<p>顺便把原作者不太地道的英语表达换掉了，值得一提的是我把copyright样式换成了design-info样式是因为在移动端上后者渲染的字体大小更加合适，并且对电脑端毫无影响，最后看起来是这个样子的</p>
<figure>
<img data-src="/images/pasted-27.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h3 id="本地化加速">本地化加速</h3>
<p>先前用的font-awesome脚本加载起来奇慢无比，导致在一开始，图标都加载不出来，在W3CSchool的推荐下换成了境内CDN加速过的源，只需要对<code>_config.yml</code>稍作修改 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">css:</span><br><span class="line">  # font-awsome: https://netdna.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css</span><br><span class="line">  font-awsome: https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css</span><br></pre></td></tr></table></figure></p>
<h2 id="hexo侧优化">3. Hexo侧优化</h2>
<h3 id="摘要生成">摘要生成</h3>
<p>之前在主页上，每篇文章都会显示全文，要划拉半天才见到下一个标题和下一页的按钮，所以只需要安装一个插件即可自动生成文章的摘要（其实就是类似<code>| head -n 10</code>一下）</p>
<p>安装一个组件即可解决问题，主题会优先使用摘要，而不是全文 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-excerpt --save</span><br></pre></td></tr></table></figure></p>
<h3 id="seo优化">SEO优化</h3>
<p>针对Hexo的SEO优化的文章有很多，<a href="https://www.jianshu.com/p/86557c34b671">比如这篇</a></p>
<p>简单来说就是 - 添加robots.txt - 生成sitemap - 添加网站到Google Search Console</p>
<h3 id="修复奇妙的bug">修复奇妙的bug</h3>
<p>当遇到莫名其妙的错误的时候，据说重装一下node modules就有可能会有奇效，反正我重装了一次确实解决了几个莫名其妙的bug，难关Google一下npm会自动补全reinstall，啧啧</p>
<h2 id="one-more-word">One more word</h2>
<p>放假前三天的空余时间都拿来魔改博客了，觉得至少需要自己魔改主题，自己的博客才拿得出手，毕竟听说真正的dalao都是，最多从jQuery开始徒手撸框架的</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Pug</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo 第二次魔改记录</title>
    <url>/2020/05/20/Hexo-%E7%AC%AC%E4%BA%8C%E6%AC%A1%E9%AD%94%E6%94%B9%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<p>为了迎接即将来临的本博客成功活过一周内的大喜日子，我决定全面魔改博客以表示庆祝。这一次魔改博客主要的目标是提升浏览体验，切入点是链路质量和美化博客。</p>
<h2 id="接入cdn">接入CDN</h2>
<p>博客当前扔在<del>白嫖来的</del>腾讯云香港VPS上，<del>不过这个博客都是用Docker打包好的，随时可以跑路</del>。腾讯云香港的链路质量一言难尽，好的时候是真的好，烂的时候是真的烂，基本上和4G上网和4G回落2G上网的体验差不多。香港CN2应该早就被广大劳动人民玩坏了。另外比较坑的一点是有传言腾讯云会干扰SSL，本站<del>顺手</del>使用极为先进的HTTPS沦为极为卡顿的原因之一。所以找了一阵子免备案免信用卡按量计费的CDN，CloudFlare就不说了还不如不用，CloudCone的表现和不挂CDN差不多（主观感受），现在用的UDomain的China Routing CDN，在CN2卡得不能自理的时候，还可以提供不错的体验。</p>
<h2 id="主题美化">主题美化</h2>
<p>之前用的主题是<code>Terminal</code>魔改版，说实话我挺喜欢这个主题的风格的，美中不足的就是缺功能，没有目录等常见功能。所以最后选择了完成度很高的<del>烂大街的</del><code>NexT.Gemini</code>，为了避免博客主题Hash碰撞，<del>不被一眼就看出来是什么大路货主题</del>，决定魔改这个主题，并且继承<code>Terminal</code>的设计风格，<del>复制粘贴CSS</del>。另外还参考了这学期写作业用的<code>Typora</code>主题<code>typora-markdown-resume</code>。</p>
<p>下面是一部分对该主题的调整内容 - 强制文章标题使用<code>h1</code>标签 - 添加<code>utterances</code>评论模块 - 调整版权声明的颜色 - 调整正文的字间距，粗细，大小，字体，颜色 - 调整导航菜单的边距 - 调整导航菜单字体粗细，大小，颜色 - 调整导航栏的背景颜色 - 调整标题字体的粗细 - 修改<code>h2</code>标签的风格 - 使用圆角矩形，添加阴影 - 调整正文页的最大宽度，页边距 - 调整圆角矩形间距 - 调整页面和正文的背景颜色</p>
<p>最后，看起来很像<code>Terminal</code>主题和<code>typora-markdown-resume</code>主题的<code>NexT.Gemini Remix</code>主题就这么诞生了。</p>
<h2 id="总结">总结</h2>
<p>这波操作给博客带来了一堆功能更新和界面优化（特别是移动端），包括但不限于</p>
<ul>
<li>加载进度条</li>
<li>阅读进度条</li>
<li>文章目录</li>
<li>访问量统计</li>
<li>版权声明</li>
<li>图片缩放</li>
</ul>
<p>以及速度优化</p>
<ul>
<li>CDN</li>
<li>Lazyload</li>
<li>PJAX局部刷新</li>
<li>HTTP2 + HSTS</li>
</ul>
<figure>
<img data-src="/images/pasted-37.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<figure>
<img data-src="/images/pasted-38.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>把CDN配置为全球网络优化Google PageSpeed的分数会更高一些（当前是只针对中国链路优化）</p>
<hr />
<p>2020.5.22更新。CDN回源策略从HTTPS回源改成了HTTP回源，降低后端响应时间（虽然还是很长，毕竟CDN的回源时间还在）。</p>
<figure>
<img data-src="/images/pasted-45.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
]]></content>
  </entry>
  <entry>
    <title>How to make an unattended Ubuntu Server Installation ISO with cloud-init</title>
    <url>/2021/04/27/How-to-make-an-unattended-Ubuntu-Server-Installation-ISO-with-cloud-init/</url>
    <content><![CDATA[<p><em>Updated on 16 Jan, 2022</em>. I worte <a href="/2022/01/16/Unattended-Ubuntu-20-04-Server-Offline-Installation/">a post for Ubuntu 20.04 Server</a>.</p>
<p>It will be convenient if the installation is fully automated when configuring multiple nodes at the same time. However, I believe Ubuntu doesn't care about unattended installation via the CD image. Its developers seem to be unwilling to write a detailed tutorial about that, even some changes they made make trouble unintentionally. Note that installing via PXE Network Boot is a good alternative.</p>
<h2 id="before-getting-hands-dirty">Before getting hands dirty</h2>
<p>An unnoticeable fact is that Ubuntu Server replaced its installer silently, which means some tutorials are actually not applicable for specific versions of Ubuntu. According to my observation, we have two installers so far,</p>
<ul>
<li>Before Ubuntu 18.04.3: <code>Debian-Installer</code>, a non-live installer</li>
<li>Ubuntu 18.04.4~18.04.5: <del>Old version of <code>subiquity</code>, a live installer, <strong>without unattended installation support</strong></del>
<ul>
<li>There are two varients, (thanks for jack's comment)
<ul>
<li>one is called <code>non-live</code> version with <code>Debian-Installer</code></li>
<li>another is called <code>live</code> version with old version of <code>subiquity</code>, which doesn't have unattended installation support</li>
</ul></li>
</ul></li>
<li>Ubuntu 20.04: <code>subiquity</code>, a live installer, with unattended installation support</li>
</ul>
<p>Consider that Ubuntu 18.04 has excellent compatibility, this tutorial aims at <strong>making Ubuntu 18.04.5 Installation ISO</strong>. As for Ubuntu 20.04 users, please refer to this tutorial <a href="https://gist.github.com/s3rj1k/55b10cd20f31542046018fcce32f103e">https://gist.github.com/s3rj1k/55b10cd20f31542046018fcce32f103e</a> or <a href="/2022/01/16/Unattended-Ubuntu-20-04-Server-Offline-Installation/">my newer blog post</a> for your information, and you can still read this tutorial because some approaches mentioned in this article also work.</p>
<h2 id="download-iso-and-tools">Download ISO and Tools</h2>
<p><del>Since Ubuntu 18.04.4~18.04.5 doesn't support unattended installation, we have to use Ubuntu 18.04.3 as the original version. Note that this version is deprecated. Thus it can only be downloaded from <code>old-releases</code> site.</del> Make sure what you download is a <code>non-live</code> version, such as,</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http://old-releases.ubuntu.com/releases/18.04.3/ubuntu-18.04.3-server-amd64.iso</span><br></pre></td></tr></table></figure>
<p>There is an excellent tool called <code>cubic</code>, which helps us decompress and repack the ISO file and <code>rootfs</code> image. Also, it will automatically set up the virtual environment (<code>chroot</code>), where modifying the root filesystem is quite easy, just like operating a regular Ubuntu.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-add-repository ppa:cubic-wizard/release</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install cubic</span><br></pre></td></tr></table></figure>
<p>Run <code>cubic</code> command in the terminal to launch this program.</p>
<h2 id="modify-root-filesystem">Modify Root Filesystem</h2>
<p>Generally speaking, all the files existing in the virtual environment will be directly copied to the machine where this system is installed, except several files generated during installation. Thus, you can preinstall some software in this step.</p>
<figure>
<img data-src="/images/pasted-69.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h3 id="install-and-upgrade-software">Install and Upgrade Software</h3>
<p>Consider that Ubuntu 18.04.3 is a bit outdated, so some build-in software should be upgraded.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apt update &amp;&amp; apt upgrade -y</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note:</p>
<ul>
<li>The Linux Kernel has been installed in this stage, and it will be installed by <code>Debian-installer</code> during installation. Therefore, you still need to perform <code>apt upgrade</code> after installation.</li>
<li>You can change an APT repository in the virtual environment, but the file <code>/etc/apt/source.list</code> will be replaced by <code>Debian-installer</code> or <code>cloud-init</code> eventually.</li>
<li>SSH server could be installed in advance to save some time in installing OS, and <code>cloud-init</code> will regenerate SSH-key during the first boot.</li>
</ul>
</blockquote>
<h3 id="write-post-installation-script">Write Post-Installation Script</h3>
<p><code>cloud-init</code> is widely used in the cloud industry to initialize the system during the first boot. In fact, we could utilize it to do post-installation configuration. It is recommended to refer to these examples to customize your script: <a href="https://cloudinit.readthedocs.io/en/latest/topics/examples.html">https://cloudinit.readthedocs.io/en/latest/topics/examples.html</a>.</p>
<p>I attach my script located at <code>/etc/cloud/cloud.cfg.d/20-asc-init.cfg</code> here for your reference.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#cloud-config</span></span><br><span class="line"></span><br><span class="line"><span class="attr">network:</span></span><br><span class="line">  <span class="attr">config:</span> <span class="string">disabled</span></span><br><span class="line"><span class="attr">bootcmd:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">/usr/bin/asc_init_net</span></span><br><span class="line"><span class="attr">ntp:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">apt:</span></span><br><span class="line">  <span class="attr">primary:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">arches:</span> [<span class="string">default</span>]</span><br><span class="line">      <span class="attr">uri:</span> <span class="string">http://mirrors.sustech.edu.cn/ubuntu/</span></span><br><span class="line"></span><br><span class="line"><span class="attr">package_update:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">package_upgrade:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">power_state:</span></span><br><span class="line">  <span class="attr">mode:</span> <span class="string">reboot</span></span><br></pre></td></tr></table></figure>
<h3 id="optional-configure-dhcp-for-all-network-interfaces-after-installation">Optional: Configure DHCP for all network interfaces after installation</h3>
<p><code>Debian-installer</code> has a known bug: <code>netcfg/choose_interface=auto</code> fails to pick the functional network interface from many ones. Meanwhile, <code>cloud-init</code> also only configure one interface since most of the cloud instances only have one. If your machine happens to have one interface, you can skip this part. Otherwise, you need a workaround.</p>
<p>I wrote a script <code>/usr/bin/asc_init_net</code> to automatically generate configuration file for <code>Netplan</code> during post-installation. All interfaces will contact the DHCP server to get available IP addresses simultaneously. Of course, this script should be executed by <code>cloud-init</code> as <code>bootcmd</code>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">find /sys/class/net -<span class="built_in">type</span> l -not -lname <span class="string">&#x27;*virtual*&#x27;</span> -<span class="built_in">printf</span> <span class="string">&#x27;%f\n&#x27;</span> | python3 -c <span class="string">&quot;</span></span><br><span class="line"><span class="string">import sys</span></span><br><span class="line"><span class="string">import yaml</span></span><br><span class="line"><span class="string">c = &#123;</span></span><br><span class="line"><span class="string">    &#x27;network&#x27;: &#123;</span></span><br><span class="line"><span class="string">        &#x27;version&#x27;: 2,</span></span><br><span class="line"><span class="string">        &#x27;ethernets&#x27;: &#123;&#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">for i in sys.stdin.readlines():</span></span><br><span class="line"><span class="string">    c[&#x27;network&#x27;][&#x27;ethernets&#x27;][i.strip()] = &#123;&#x27;dhcp4&#x27;: True, &#x27;optional&#x27;: True&#125;</span></span><br><span class="line"><span class="string">print(yaml.dump(c))</span></span><br><span class="line"><span class="string">&quot;</span> &gt; /etc/netplan/20-asc-init.yaml &amp;&amp; netplan apply</span><br></pre></td></tr></table></figure>
<p>Don't forget to set the correct permission.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod +x /usr/bin/asc_init_net</span><br></pre></td></tr></table></figure>
<h3 id="clean-up">Clean up</h3>
<p><code>/etc/machine-id</code> might be generated when you install some software or do something else. However, this ID should vary from machine to machine. If two machines share the same ID, they may get the same IP address from the DHCP server. Therefore, this file should keep empty.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> -n &gt; /etc/machine-id</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: This file could be regenerated by running <code>systemd-machine-id-setup</code> or rebooting the computer.</p>
</blockquote>
<p>Moreover, <code>cloud-init</code> will be executed on the next boot only if it is clean, then it will write something to disk to prevent itself from running again. To make sure it will work as expected, we can clean it manually.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cloud-init clean</span><br></pre></td></tr></table></figure>
<h2 id="write-preseed-file">Write Preseed File</h2>
<p>Preseed files store all the answers to the questions that the installer asks. Move to the directory <code>custom-disk</code>, which is created by <code>cubic</code> and contains the supporting files of the CD, including bootloaders and some configuration. Create a file <code>custom-disk/preseed/auto-inst.seed</code>, and write the following content to that file.</p>
<figure>
<img data-src="/images/pasted-68.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">### Automatic Installation</span></span><br><span class="line">d-i auto-install/<span class="built_in">enable</span> boolean <span class="literal">true</span></span><br><span class="line">d-i debconf/priority select critical</span><br><span class="line"></span><br><span class="line"><span class="comment">### Localization</span></span><br><span class="line">d-i debian-installer/locale string en_US.UTF-8</span><br><span class="line">d-i localechooser/supported-locales multiselect en_US.UTF-8</span><br><span class="line">d-i console-setup/ask_detect boolean <span class="literal">false</span></span><br><span class="line">d-i keyboard-configuration/xkb-keymap select us</span><br><span class="line"></span><br><span class="line"><span class="comment">### Network config</span></span><br><span class="line">d-i netcfg/<span class="built_in">enable</span> boolean <span class="literal">false</span></span><br><span class="line"><span class="comment">#d-i netcfg/choose_interface select auto</span></span><br><span class="line"><span class="comment">#d-i netcfg/get_hostname string node0</span></span><br><span class="line"><span class="comment">#d-i netcfg/get_domain string unassigned-domain</span></span><br><span class="line"><span class="comment">#d-i netcfg/hostname string node0</span></span><br><span class="line">d-i hw-detect/load_firmware boolean <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Mirror settings</span></span><br><span class="line">d-i apt-setup/use_mirror boolean <span class="literal">false</span></span><br><span class="line"><span class="comment">#d-i mirror/http/mirror select CC.archive.ubuntu.com</span></span><br><span class="line"><span class="comment">#d-i mirror/country string manual</span></span><br><span class="line"><span class="comment">#d-i mirror/http/hostname string mirrors.sustech.edu.cn</span></span><br><span class="line"><span class="comment">#d-i mirror/http/directory string /ubuntu</span></span><br><span class="line"><span class="comment">#d-i mirror/http/proxy string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Account setup</span></span><br><span class="line"><span class="comment"># This is just for testing!!!</span></span><br><span class="line">d-i passwd/make-user boolean <span class="literal">false</span></span><br><span class="line">d-i passwd/user-fullname string Ubuntu User</span><br><span class="line">d-i passwd/username string ubuntu</span><br><span class="line">d-i passwd/user-password password ubuntu</span><br><span class="line">d-i passwd/user-password-again password ubuntu</span><br><span class="line"><span class="comment">#d-i passwd/user-password-crypted password [crypt(3) hash]</span></span><br><span class="line">d-i user-setup/allow-password-weak boolean <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set to true if you want to encrypt the first user&#x27;s home directory.</span></span><br><span class="line">d-i user-setup/encrypt-home boolean <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Clock and time zone setup</span></span><br><span class="line">d-i clock-setup/utc boolean <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># You may set this to any valid setting for $TZ; see the contents of</span></span><br><span class="line"><span class="comment"># /usr/share/zoneinfo/ for valid values.</span></span><br><span class="line">d-i time/zone string Asia/Shanghai</span><br><span class="line"></span><br><span class="line"><span class="comment"># Controls whether to use NTP to set the clock during the install</span></span><br><span class="line">d-i clock-setup/ntp boolean <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Partitioning</span></span><br><span class="line"><span class="comment"># !!!DANGER don&#x27;t use this without knowing what you are doing!!!</span></span><br><span class="line"><span class="comment"># comment out this block it you want the installer to ask about the </span></span><br><span class="line"><span class="comment"># partitioning, which is much safer!</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The following will partition disk /dev/sda with an EFI partition, a root partition</span></span><br><span class="line"><span class="comment"># and a swap file. AND WONT ASK TO CONFIRM ANYTHING i.e. it will overwrite existing partitions</span></span><br><span class="line">d-i preseed/early_command string umount /media || <span class="literal">true</span></span><br><span class="line">d-i partman/unmount_active boolean <span class="literal">true</span></span><br><span class="line">d-i partman-auto/disk string /dev/sda</span><br><span class="line">d-i partman-auto/method string regular</span><br><span class="line">d-i partman-auto/choose_recipe select atomic</span><br><span class="line">d-i partman-partitioning/confirm_write_new_label boolean <span class="literal">true</span></span><br><span class="line">d-i partman/choose_partition select finish</span><br><span class="line">d-i partman/confirm boolean <span class="literal">true</span></span><br><span class="line">d-i partman/confirm_nooverwrite boolean <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The kernel image (meta) package to be installed;</span></span><br><span class="line">d-i base-installer/kernel/image string linux-generic</span><br><span class="line"><span class="comment">#d-i base-installer/kernel/altmeta string hwe-18.04</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Package selection</span></span><br><span class="line"><span class="comment"># Install the Ubuntu Server seed.</span></span><br><span class="line"><span class="comment">#tasksel tasksel/force-tasks string server</span></span><br><span class="line"><span class="comment">#tasksel tasksel/first multiselect openssh-server</span></span><br><span class="line">d-i tasksel/first multiselect none</span><br><span class="line">d-i pkgsel/language-packs multiselect en, zh</span><br><span class="line">d-i pkgsel/update-policy select none</span><br><span class="line"></span><br><span class="line"><span class="comment"># Verbose output and no boot splash screen.</span></span><br><span class="line">d-i debian-installer/quiet  boolean <span class="literal">false</span></span><br><span class="line">d-i debian-installer/splash boolean <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">d-i cdrom-detect/eject boolean <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Avoid that last message about the install being complete.</span></span><br><span class="line"><span class="comment"># This will just finish and reboot</span></span><br><span class="line">d-i finish-install/reboot_in_progress note</span><br><span class="line"><span class="comment">#d-i debian-installer/exit/poweroff boolean true</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: The network is disabled during the installation due the problem we talked about earlier. As a result, <code>debian-install</code> will</p>
<ul>
<li>Fail to use self-defined APT repository</li>
<li>Skip setting the host name</li>
<li>Skip configuring <code>netplan</code></li>
</ul>
<p>But, all the problems above can be fixed by <code>cloud-init</code>.</p>
</blockquote>
<h2 id="add-boot-arguments">Add Boot Arguments</h2>
<p>Automatic installation requires us to pass extra arguments to the kernel. Luckily, <code>cubic</code> will help us to edit the configuration of bootloaders.</p>
<blockquote>
<p>Note: There are two bootloaders in the CD image. <code>grub</code> is used to support the <code>EFI</code> firmware, and <code>isolinux</code> is used to support the traditional BIOS.</p>
</blockquote>
<p>Write the content below to the corresponding file.</p>
<h3 id="bootgrubgrub.cfg"><code>boot/grub/grub.cfg</code></h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> loadfont /boot/grub/font.pf2 ; <span class="keyword">then</span></span><br><span class="line">	<span class="built_in">set</span> gfxmode=auto</span><br><span class="line">	insmod efi_gop</span><br><span class="line">	insmod efi_uga</span><br><span class="line">	insmod gfxterm</span><br><span class="line">	terminal_output gfxterm</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> menu_color_normal=white/black</span><br><span class="line"><span class="built_in">set</span> menu_color_highlight=black/light-gray</span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> timeout=3</span><br><span class="line">menuentry <span class="string">&quot;Auto Install Ubuntu Server&quot;</span> &#123;</span><br><span class="line">	<span class="built_in">set</span> gfxpayload=keep</span><br><span class="line">	linux /install/vmlinuz boot=casper file=/cdrom/preseed/auto-inst.seed auto=<span class="literal">true</span> priority=critical locale=en_US quiet ---</span><br><span class="line">	initrd  /install/initrd.gz</span><br><span class="line">&#125;</span><br><span class="line">menuentry <span class="string">&quot;Rescue a broken system&quot;</span> &#123;</span><br><span class="line">	<span class="built_in">set</span> gfxpayload=keep</span><br><span class="line">	linux /install/vmlinuz boot=casper rescue/<span class="built_in">enable</span>=<span class="literal">true</span> ---</span><br><span class="line">	initrd /install/initrd.gz</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="isolinuxtxt.cfg"><code>isolinux/txt.cfg</code></h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">default autoinstall</span><br><span class="line">label  auto-install</span><br><span class="line">  menu label ^Auto Install Ubuntu Server</span><br><span class="line">  kernel /install/vmlinuz</span><br><span class="line">  append boot=casper file=/cdrom/preseed/auto-inst.seed vga=788 initrd=/install/initrd.gz auto=<span class="literal">true</span> priority=critical locale=en_US quiet ---</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: <code>isolinux</code> has a build-in option <code>Rescue a broken system</code>.</p>
</blockquote>
<p>By now, everything is ready to go. Let us enjoy the automatic installation.</p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://www.pugetsystems.com/labs/hpc/Note-Auto-Install-Ubuntu-with-Custom-Preseed-ISO-1654/">https://www.pugetsystems.com/labs/hpc/Note-Auto-Install-Ubuntu-with-Custom-Preseed-ISO-1654/</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>How to resize the root LVM partition of Ubuntu</title>
    <url>/2022/02/26/How-to-resize-the-root-LVM-partition-of-Ubuntu/</url>
    <content><![CDATA[<p>When we resize the virtual hard disk of a virtual machine or restore a disk image to a larger disk, the free space of the partition detected by Ubuntu will not increase because the partition table is unchanged. In the past, we could easily resize the ext4 root partition with the help of <code>resize2fs</code>. However, things get complex when Ubuntu utilizes LVM partition as their default root partition.</p>
<h2 id="quick-intro-to-lvm">Quick Intro to LVM</h2>
<p>Logical Volume Manager (LVM) is similar to Dynamic Disks under Windows, which can take several GPT / MBR partitions on different hard disks as a storage pool (LVM call it Volume Groups, VG), and allocate spaces from this pool, then Linux will recognize each space (LVM call it Logical Volume, LV) as an useable partition.</p>
<figure>
<img data-src="/images/pasted-99.png" alt="Lvm Layout" /><figcaption>Lvm Layout</figcaption>
</figure>
<p>Thus, we should modify not only <strong>the GPT / MBR partition table</strong>, but also <strong>the LVM configuration</strong>.</p>
<h2 id="update-gpt-mbr-partition-table">Update GPT / MBR partition table</h2>
<p><strong>I suggest all the operations should be done under live CD environment to avoid the occurrence of unpredictable problems.</strong> I didn't test online resizing on the root partition so far.</p>
<ol type="1">
<li>The following instructions in this section assume <strong>the last partition on your disk is the LVM Physical Volume</strong>. You could verify this with the command <code>lsblk --fs</code>. <code>nvme0n1p3</code> is the last GPT partition on the disk <code>nvme0n1</code>, and it is easy to identify this partition is a LVM PV, and <code>ubuntu--vg-ubuntu--lv</code> is the corresponding LV.</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ lsblk --fs</span><br><span class="line">NAME                      FSTYPE      FSVER        </span><br><span class="line">loop3</span><br><span class="line">└─loop3p1                 LVM2_member LVM2 001 </span><br><span class="line">  └─test--vg-test--lv     ext4        1.0      </span><br><span class="line">nvme0n1</span><br><span class="line">├─nvme0n1p1               vfat        FAT32    </span><br><span class="line">├─nvme0n1p2               ext4        1.0      </span><br><span class="line">└─nvme0n1p3               LVM2_member LVM2 001 </span><br><span class="line">  └─ubuntu--vg-ubuntu--lv ext4        1.0      </span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note that <code>ubuntu--vg-ubuntu--lv</code> is the root partition of the system here.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ df -Th</span><br><span class="line">Filesystem                        Type   Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/mapper/ubuntu--vg-ubuntu--lv ext4    78G  7.7G   67G  11% /</span><br><span class="line">/dev/nvme0n1p2                    ext4   974M   87M  820M  10% /boot</span><br><span class="line">/dev/nvme0n1p1                    vfat   511M  3.6M  508M   1% /boot/efi</span><br><span class="line">/dev/mapper/test--vg-test--lv     ext4   464M   24K  429M   1% /home/tonny/mnt</span><br></pre></td></tr></table></figure>
<p>Also you could check the LVM Volume Group status by <code>vgs</code>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ sudo vgs</span><br><span class="line">  VG        <span class="comment">#PV #LV #SN Attr   VSize   VFree</span></span><br><span class="line">  test-vg     1   1   0 wz--n- 496.00m    0</span><br><span class="line">  ubuntu-vg   1   1   0 wz--n- &lt;78.50g    0</span><br></pre></td></tr></table></figure>
</blockquote>
<ol start="2" type="1">
<li>Update the GPT / MBR partition table using <code>fdisk</code>. I will use an emulated disk <code>/dev/loop3</code> to demonstrate the whole process. Don't worry, you won't loss your data under normal circumstances. These commands will only modify the partition table, but make sure <strong>DO NOT remove the LVM's signature</strong>, otherwise the system may no longer recognize your LVM PV.</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ sudo fdisk /dev/loop3 <span class="comment"># replace with your hard disk, such as /dev/nvme0n1p3</span></span><br><span class="line"></span><br><span class="line">Welcome to fdisk (util-linux 2.36.1).</span><br><span class="line">Changes will remain <span class="keyword">in</span> memory only, until you decide to write them.</span><br><span class="line">Be careful before using the write <span class="built_in">command</span>.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): p</span><br><span class="line">Disk /dev/loop3: 1 GiB, 1073741824 bytes, 2097152 sectors</span><br><span class="line">Units: sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disklabel <span class="built_in">type</span>: gpt</span><br><span class="line">Disk identifier: C5F55056-8C56-5448-81E4-567F59AD93ED</span><br><span class="line"></span><br><span class="line">Device       Start     End Sectors  Size Type</span><br><span class="line">/dev/loop3p1  2048 1026047 1024000  500M Linux filesystem</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): d</span><br><span class="line">Selected partition 1</span><br><span class="line">Partition 1 has been deleted.</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): n</span><br><span class="line">Partition number (1-128, default 1):</span><br><span class="line">First sector (2048-2097118, default 2048):</span><br><span class="line">Last sector, +/-sectors or +/-size&#123;K,M,G,T,P&#125; (2048-2097118, default 2097118):</span><br><span class="line"></span><br><span class="line">Created a new partition 1 of <span class="built_in">type</span> <span class="string">&#x27;Linux filesystem&#x27;</span> and of size 1023 MiB.</span><br><span class="line">Partition <span class="comment">#1 contains a LVM2_member signature.</span></span><br><span class="line"></span><br><span class="line">Do you want to remove the signature? [Y]es/[N]o: N</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): p</span><br><span class="line"></span><br><span class="line">Disk /dev/loop3: 1 GiB, 1073741824 bytes, 2097152 sectors</span><br><span class="line">Units: sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disklabel <span class="built_in">type</span>: gpt</span><br><span class="line">Disk identifier: C5F55056-8C56-5448-81E4-567F59AD93ED</span><br><span class="line"></span><br><span class="line">Device       Start     End Sectors  Size Type</span><br><span class="line">/dev/loop3p1  2048 2097118 2095071 1023M Linux filesystem</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): w</span><br><span class="line">The partition table has been altered.</span><br><span class="line">Calling ioctl() to re-read partition table.</span><br><span class="line">Syncing disks.</span><br></pre></td></tr></table></figure>
<h2 id="update-lvm-configuration">Update LVM Configuration</h2>
<ol type="1">
<li>Notify LVM there is an update on the partition table.</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ sudo partprobe <span class="comment"># ask kernel to read the new partition table</span></span><br><span class="line">tonny@vm:~$ sudo pvresize /dev/loop3p1 <span class="comment"># replace with your partition</span></span><br><span class="line">  Physical volume <span class="string">&quot;/dev/loop3p1&quot;</span> changed</span><br><span class="line">  1 physical volume(s) resized or updated / 0 physical volume(s) not resized</span><br></pre></td></tr></table></figure>
<blockquote>
<p>At this moment, the LVM Volume Group status has changed to,</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ sudo vgs</span><br><span class="line">  VG        <span class="comment">#PV #LV #SN Attr   VSize    VFree</span></span><br><span class="line">  test-vg     1   1   0 wz--n- 1020.00m 524.00m</span><br><span class="line">  ubuntu-vg   1   1   0 wz--n-  &lt;78.50g      0</span><br></pre></td></tr></table></figure>
<p>Observe that <code>VFree</code> of <code>test-vg</code> has increased by 524.00 MB.</p>
</blockquote>
<ol start="2" type="1">
<li>Resize LVM Logical Volume. The following command will allocate all the free space of VG to the LV.</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ sudo lvextend -l +100%FREE /dev/mapper/test--vg-test--lv</span><br><span class="line">  Size of logical volume test-vg/test-lv changed from 496.00 MiB (124 extents) to 1020.00 MiB (255 extents).</span><br><span class="line">  Logical volume test-vg/test-lv successfully resized.</span><br></pre></td></tr></table></figure>
<blockquote>
<p>The free space of VG is used up now.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ sudo vgs</span><br><span class="line">  VG        <span class="comment">#PV #LV #SN Attr   VSize    VFree</span></span><br><span class="line">  test-vg     1   1   0 wz--n- 1020.00m    0</span><br><span class="line">  ubuntu-vg   1   1   0 wz--n-  &lt;78.50g    0</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="resize-ext4-file-system">Resize ext4 File System</h2>
<p>Up to now, although LVM LV is resized, the ext4 file system is not aware of the extra available space. Simply run <code>resize2fs</code> to let it know.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ sudo resize2fs /dev/mapper/test--vg-test--lv</span><br><span class="line">resize2fs 1.46.3 (27-Jul-2021)</span><br><span class="line">Filesystem at /dev/mapper/test--vg-test--lv is mounted on /home/tonny/mnt; on-line resizing required</span><br><span class="line">old_desc_blocks = 1, new_desc_blocks = 1</span><br><span class="line">The filesystem on /dev/mapper/test--vg-test--lv is now 261120 (4k) blocks long.</span><br></pre></td></tr></table></figure>
<blockquote>
<p>We can see the available space of <code>test--vg-test--lv</code> has been enlarged.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tonny@vm:~$ df -h</span><br><span class="line">Filesystem                         Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/mapper/test--vg-test--lv      973M  1.3M  917M   1% /home/tonny/mnt</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="references">References</h2>
<ul>
<li><a href="https://www.linuxtechi.com/extend-lvm-partitions/">https://www.linuxtechi.com/extend-lvm-partitions/</a></li>
<li><a href="https://www.thegeekdiary.com/centos-rhel-how-to-extend-physical-volume-in-lvm-by-extending-the-disk-partition-used/">https://www.thegeekdiary.com/centos-rhel-how-to-extend-physical-volume-in-lvm-by-extending-the-disk-partition-used/</a></li>
<li><a href="https://i0.wp.com/manjaro.site/wp-content/uploads/2017/08/lvm-layout.png">https://i0.wp.com/manjaro.site/wp-content/uploads/2017/08/lvm-layout.png</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Jetson Nano PWM配置</title>
    <url>/2019/08/22/Jetson-Nano-PWM%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>Updated on 7 Feb, 2021. For English User, there is an English version of this post. Link: <a href="https://www.seeedstudio.com/blog/2020/05/27/configure-pwm-output-on-jetson-nano-m/">https://www.seeedstudio.com/blog/2020/05/27/configure-pwm-output-on-jetson-nano-m/</a>. By the way, I sincerely hope the translator will be capable of understanding the meaning of <strong>reference</strong> thoroughly next time.</p>
<hr />
<p>最近要用PWM信号控制激光雷达的转速，一开始以为用Jetson Nano的PWM控制非常简单，结果看到了下面这段话</p>
<blockquote>
<p>See <code>samples/simple_pwm.py</code> for details on how to use PWM channels.</p>
</blockquote>
<blockquote>
<p>The Jetson.GPIO library supports PWM only on pins with attached hardware PWM controllers. Unlike the RPi.GPIO library, the Jetson.GPIO library does not implement Software emulated PWM. Jetson Nano supports 2 PWM channels, and Jetson AGX Xavier supports 3 PWM channels. Jetson TX1 and TX2 do not support any PWM channels.</p>
</blockquote>
<blockquote>
<p>The system pinmux must be configured to connect the hardware PWM controlller(s) to the relevant pins. If the pinmux is not configured, PWM signals will not reach the pins! The Jetson.GPIO library does not dynamically modify the pinmux configuration to achieve this. Read the L4T documentation for details on how to configure the pinmux.</p>
</blockquote>
<blockquote>
<p><a href="https://github.com/NVIDIA/jetson-gpio/blob/master/README.md">原文链接</a></p>
</blockquote>
<p>大概意思就是说，要用硬件PWM就得改Pinmux，要用软PWM，抱歉，我们没写这个代码</p>
<h2 id="官方参考代码">官方参考代码</h2>
<p>官方给出了PWM的Python参考代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> RPi.GPIO <span class="keyword">as</span> GPIO</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">output_pins = &#123;</span><br><span class="line">    <span class="string">&#x27;JETSON_XAVIER&#x27;</span>: <span class="number">18</span>,</span><br><span class="line">    <span class="string">&#x27;JETSON_NANO&#x27;</span>: <span class="number">33</span>,</span><br><span class="line">&#125;</span><br><span class="line">output_pin = output_pins.get(GPIO.model, <span class="literal">None</span>)</span><br><span class="line"><span class="keyword">if</span> output_pin <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">raise</span> Exception(<span class="string">&#x27;PWM not supported on this board&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment"># Pin Setup:</span></span><br><span class="line">    <span class="comment"># Board pin-numbering scheme</span></span><br><span class="line">    GPIO.setmode(GPIO.BOARD)</span><br><span class="line">    <span class="comment"># set pin as an output pin with optional initial state of HIGH</span></span><br><span class="line">    GPIO.setup(output_pin, GPIO.OUT, initial=GPIO.HIGH)</span><br><span class="line">    p = GPIO.PWM(output_pin, <span class="number">50</span>)</span><br><span class="line">    p.start(<span class="number">25</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;PWM running. Press CTRL+C to exit.&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        p.stop()</span><br><span class="line">        GPIO.cleanup()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p><code>GPIO.PWM</code>的50是指代PWM频率，传闻上限是50kHZ <code>p.start</code>的25当然是指占空比了，范围是0-100</p>
<h2 id="导出dt文件">导出DT文件</h2>
<figure>
<img data-src="/images/pasted-0.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p><a href="https://github.com/NVIDIA/jetson-gpio/blob/master/README.md">原图链接</a></p>
<p>官方样例钦定了33作为PWM Pin，Jetson Nano的33 Pin实际上是<code>GPIO_PE6</code>，也就是说我们需要把<code>GPIO_PE6</code>配置为PWM</p>
<p>打开<code>Jetson Nano Module Pinmux Config Template</code> <a href="https://developer.nvidia.com/embedded/dlc/jetson-nano-pinmux-table">下载链接</a>，很轻松的就找到了<code>GPIO_PE6</code></p>
<figure>
<img data-src="/images/pasted-1.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>可见PE6可以配置为<code>PM3_PWM2</code></p>
<figure>
<img data-src="/images/pasted-3.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>然后这个Excel表格会提醒你改成输出模式（做表格的人真他娘的nb）</p>
<figure>
<img data-src="/images/pasted-4.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>最后就可以Generate DT File了</p>
<figure>
<img data-src="/images/pasted-5.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>期间，脚本会询问board name，输入<code>jetson-nano-sd</code>即可</p>
<p>最后将该Excel表格另存为<code>CSV UTF-8 (comma-delimited) (*.csv)</code>格式，文件名为<code>jetson-nano-sd.csv</code></p>
<p>我们就得到了三个文件，把这个文件复制到电脑的Linux系统上</p>
<figure>
<img data-src="/images/pasted-14.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h2 id="疯狂下载">疯狂下载</h2>
<p>参考文章: - <a href="https://developer.nvidia.com/embedded/dlc/Jetson-Nano-40-Pin-Expansion-Header-1.2">NVIDIA Jetson Nano Pinmux官方文档</a></p>
<ul>
<li><p><a href="https://docs.nvidia.com/jetson/archives/l4t-archived/l4t-281/index.html#page/Tegra%20Linux%20Driver%20Package%20Development%20Guide/l4t_pinmux.html">NVIDIA Jetson TX2 Pinmux官方文档</a></p></li>
<li><p><a href="https://devtalk.nvidia.com/default/topic/1055398/jetson-nano/how-to-use-the-jetson-nanos-pinmux-spreadsheet-/">NVIDIA Jetson Nano 官方答疑</a></p></li>
<li><p><a href="https://developer.ridgerun.com/wiki/index.php?title=Jetson_Nano/Development/Building_the_Kernel_from_Source">Jetson Nano 内核构建教程</a></p></li>
</ul>
<p>首先在SDK Manager下载Jetson Nano的全家桶，过程略</p>
<figure>
<img data-src="/images/pasted-8.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>一切妥当后，在<code>~/nvidia/nvidia_sdk/JetPack_4.2.1_Linux_GA_P3448/Linux_for_Tegra</code>这个路径下应该能看到<code>source_sync.sh</code></p>
<figure>
<img data-src="/images/pasted-9.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>在终端下执行以下命令就可以把内核代码扒拉下来了 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt install build-essential bc bzip2 xz-utils git-core vim-common</span><br><span class="line">./source_sync.sh</span><br></pre></td></tr></table></figure> 在脚本运行过程中，输入的tag为<code>tegra-l4t-r32.2.0</code>，这个tag要和其他东西的版本保持一致</p>
<p>然后我们就可以下载工具链了 <a href="https://developer.nvidia.com/embedded/downloads">下载工具链</a></p>
<p>建议勾选Filter</p>
<figure>
<img data-src="/images/pasted-10.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>然后下载GCC Tool Chain for 64-bit BSP</p>
<figure>
<img data-src="/images/pasted-11.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>随便解压一下工具包，并记住路径</p>
<p>比如我的路径就是<code>/home/tonny/bin/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu</code></p>
<h2 id="编译uboot">编译Uboot</h2>
<p>在Linux系统上下载脚本<code>tegra-pinmux-scripts</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">https://github.com/NVIDIA/tegra-pinmux-scripts</span><br></pre></td></tr></table></figure>
<p>在<code>tegra-pinmux-scripts</code>目录下创建csv文件夹，把之前得到的csv文件复制到里面去 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd tegra-pinmux-scripts</span><br><span class="line">mkdir csv</span><br><span class="line">cp &lt;path-to-csv&gt;/jetson-nano-sd.csv csv/p3450-porg.csv </span><br></pre></td></tr></table></figure></p>
<p>然后执行以下命令 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./csv-to-board.py p3450-porg</span><br><span class="line">./board-to-uboot.py p3450-porg &gt; pinmux-config-p3450-porg.h</span><br></pre></td></tr></table></figure></p>
<p>用得到的<code>pinmux-config-p3450-porg.h</code>覆盖uboot目录<code>/home/tonny/nvidia/nvidia_sdk/JetPack_4.2.1_Linux_GA_P3448/Linux_for_Tegra/sources/u-boot/board/nvidia/p3450-porg</code>原来的文件</p>
<p>再设置环境变量，导入工具链的相关信息 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> CROSS_COMPILE=/home/tonny/bin/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu/bin/aarch64-linux-gnu-</span><br></pre></td></tr></table></figure></p>
<p>安装dtc <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apt-get install device-tree-compiler</span><br></pre></td></tr></table></figure></p>
<p>退回到uboot源码根目录<code>/home/tonny/nvidia/nvidia_sdk/JetPack_4.2.1_Linux_GA_P3448/Linux_for_Tegra/sources/u-boot</code>，编译uboot</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">make distclean</span><br><span class="line">make p3450-porg_defconfig</span><br><span class="line">make</span><br></pre></td></tr></table></figure>
<p>最后将刚编译好的uboot导入L4T tree <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp u-boot.bin ../../bootloader/t210ref/p3450-porg/ </span><br></pre></td></tr></table></figure></p>
<h2 id="更新cboot">更新CBoot</h2>
<p>首先我们要检查自己的Jetson Nano的设备树版本</p>
<p>在nano上运行 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /proc/device-tree/nvidia,dtsfilename</span><br></pre></td></tr></table></figure></p>
<p>比如我的nano是<code>tegra210-p3448-0000-p3449-0000-b00.dts</code>，说明我们之后要修改b00版的文件，有的人可能拿到了a02版的nano，他们要改a02版的文件</p>
<figure>
<img data-src="/images/pasted-15.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>如果L4T版本为32.1，需要去参考<a href="https://developer.nvidia.com/embedded/dlc/Jetson-Nano-40-Pin-Expansion-Header-1.2">NVIDIA Jetson Nano Pinmux官方文档</a>更新部分源码</p>
<p>回到Linux主机上，用之前Excel表格生成的dtsi文件覆盖源码里的文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> Linux_for_Tegra/sources/hardware/nvidia/platform/t210/porg/kernel-dts/porg-platforms/ </span><br><span class="line"></span><br><span class="line">cp &lt;path-to-new-dt-files&gt;/tegra210-jetson-nano-sd-pinmux.dtsi tegra210-porg-pinmux-p3448-0000-&lt;nano-dt-version&gt;.dtsi </span><br><span class="line"></span><br><span class="line">cp &lt;path-to-new-dt-files&gt;/tegra210-jetson-nano-sd-gpio-default.dtsi tegra210-porg-gpio-p3448-0000-&lt;nano-dt-version&gt;.dtsi </span><br></pre></td></tr></table></figure>
<p>进入<code>Linux_for_Tegra/sources/kernel/kernel-4.9/</code>文件夹构建device tree image</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> Linux_for_Tegra/sources/kernel/kernel-4.9/</span><br><span class="line">make ARCH=arm64 tegra_defconfig </span><br><span class="line">make ARCH=arm64 dtbs </span><br></pre></td></tr></table></figure>
<p>最后将刚编译好的device tree image导入L4T tree</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp arch/arm64/boot/dts/tegra210-p3448-0000-p3449-0000-&lt;nano-dt-version&gt;.dtb ../../../kernel/dtb/</span><br></pre></td></tr></table></figure>
<h2 id="刷机">刷机</h2>
<p>在<code>Linux_for_Tegra</code>文件夹下执行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo ./create-jetson-nano-sd-card-image.sh -o sd-blob.img -s &lt;sd_card_size&gt; -r &lt;nano-dt-revision&gt;</span><br></pre></td></tr></table></figure>
<p>注意，sd_card_size为sd卡大小，而nano-dt-revision与nano-dt-version的对应关系如下</p>
<table>
<thead>
<tr class="header">
<th>DT-Ver</th>
<th>DT-Rev</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>a01</td>
<td>100</td>
</tr>
<tr class="even">
<td>a02</td>
<td>200</td>
</tr>
<tr class="odd">
<td>b00</td>
<td>300</td>
</tr>
</tbody>
</table>
<p>这里我的sd卡为32g，dt-ver为b00，那么我实际执行了</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo ./create-jetson-nano-sd-card-image.sh -o sd-blob.img -s 32G -r 300</span><br></pre></td></tr></table></figure>
<p>下一步，进入目录<code>Linux_for_Tegra/bootloader/signed</code>，将对应版本的<code>tegra210-p3448-0000-p3449-0000-&lt;nano-dt-version&gt;.dtb.encrypt</code>复制到nano上</p>
<p>然后在nano上执行 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo dd <span class="keyword">if</span>=tegra210-p3448-0000-p3449-0000-&lt;nano-dt-version&gt;.dtb.encrypt of=/dev/disk/by-partlabel/DTB</span><br></pre></td></tr></table></figure></p>
<p>当然个人建议先备份一下，万一失败了还能抢救一下 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo dd <span class="keyword">if</span>=/dev/disk/by-partlabel/DTB of=backup.dtb.encrypt</span><br></pre></td></tr></table></figure></p>
<h2 id="附录">附录</h2>
<p>进入Force Recovery Mode的方法： <a href="https://developer.nvidia.com/embedded/dlc/jetson-nano-dev-kit-user-guide">nano-dev-kit-user-guide</a></p>
<blockquote>
<ol type="1">
<li>Jumper the Force Recovery pins (3 and 4) on J40 button header</li>
<li>Jumper the J48 Power Select Header pins and connect a power supply to J25 power jack. The developer kit automatically powers on in Force Recovery mode.</li>
<li>Now that the developer kit is running, remove the Force Recovery pins’ jumper.</li>
</ol>
</blockquote>
<figure>
<img data-src="/images/pasted-16.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>其实短接Recovery pins就可以了，不一定要用DC接口，只要能保证供得上电就行，比如在40pin引脚的5v上加个电源</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Jetson</tag>
      </tags>
  </entry>
  <entry>
    <title>Jetson Nano的USB共享网络</title>
    <url>/2020/11/07/Jetson-Nano%E7%9A%84USB%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h2 id="通过usb连接jetson-nano">通过USB连接Jetson Nano</h2>
<p>在完成初始化，设置好用户的账号密码后，Jetson Nano官方的L4T系统默认开启了RNDIS将自己虚拟为一张网卡。当用电脑连接到Nano的USB供电接口时，电脑会将Nano识别为一张网卡，并且可以获取到IP地址（NVIDIA贴心的帮你配好了DHCP和SSH）。此时用SSH连接到<code>192.168.50.1</code>就可以连接上Jetson Nano了。</p>
<p>如果没有完成初始化，碰巧手边没有显示器，可以参考<a href="https://desertbot.io/blog/jetson-nano-headless-wifi-setup">这篇文章</a>完成headless下的初始化设置，通过Jetson Nano假扮成的USB Modem完成初始化。</p>
<h2 id="关闭或启动jetson-nano">关闭或启动Jetson Nano</h2>
<p>对于绝大多数人来说是没有这个需要的，但是碰巧我用电脑给Nano供电，碰巧用Chrome OS系统，没有禁用网卡的选项，也不能改路由表，不关掉这个网络就没法上网。还好NVIDIA有脚本。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 禁用USB共享网络</span></span><br><span class="line">sudo /opt/nvidia/l4t-usb-device-mode/nv-l4t-usb-device-mode-stop.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用USB共享网络</span></span><br><span class="line">sudo /opt/nvidia/l4t-usb-device-mode/nv-l4t-usb-device-mode.sh</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>MATLAB 一些向量化思路和例子</title>
    <url>/2020/05/21/MATLAB-%E4%B8%80%E4%BA%9B%E5%90%91%E9%87%8F%E5%8C%96%E6%80%9D%E8%B7%AF%E5%92%8C%E4%BE%8B%E5%AD%90/</url>
    <content><![CDATA[<p>Digital Image Processing的处理经常需要密集的计算，效率低的代码处理一张500x500的图片都可以计算30秒。<del>为了方便调参</del>，<del>同时身为超算比赛参赛者，职业病犯了</del>，写一个速度快的代码是很有必要的。本文的code和benchmark来自我写的DIP实验报告。</p>
<h2 id="convolution-correlation">Convolution / Correlation</h2>
<p>卷积 (Convolution)是DIP和CNN常用的一种操作，而Correlation是一种和卷积差不多的操作，把卷积核转置两下做卷积就是Correlation。Correlation在DIP可以用来做模糊和边缘检测。下面我给大家表演徒手写向量化Correlation。</p>
<h3 id="常规思路">常规思路</h3>
<figure>
<img data-src="/images/pasted-39.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>假设<code>padImgArr</code>输入的图片，<code>mask</code>就是类似卷积核的一个东西（<code>mask</code>转置两下做Correlation就是Convolution）。正常思路当然是两层for循环，遍历图片的每一个像素，然后取像素临近的点，和<code>mask</code>来一发点乘。菜一点的人会再来两层for循环，去逐个计算像素值乘<code>mask</code>值的结果，稍微觉得有点不对劲的人，很容易想到对<code>padImgArr</code>切片做点乘再求和，这种想法的代码实现如下。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">outImgArr</span> = <span class="title">correlation2</span><span class="params">(padImgArr, mask)</span></span></span><br><span class="line">    imgSize = <span class="built_in">size</span>( padImgArr );</span><br><span class="line">    outImgArr = <span class="built_in">zeros</span>( imgSize );</span><br><span class="line">    H = imgSize(<span class="number">1</span>); W = imgSize(<span class="number">2</span>);</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">2</span>:H<span class="number">-1</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">2</span>:W<span class="number">-1</span></span><br><span class="line">            outImgArr(<span class="built_in">i</span>, <span class="built_in">j</span>) = sum( padImgArr( <span class="built_in">i</span><span class="number">-1</span>:<span class="built_in">i</span>+<span class="number">1</span>, <span class="built_in">j</span><span class="number">-1</span>:<span class="built_in">j</span>+<span class="number">1</span> ).*mask, <span class="string">&quot;all&quot;</span> );</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h3 id="优化方法">优化方法</h3>
<p>如果你是一个对解释型语言的循环有PTSD的人，很快你会开始考虑如何减少循环次数。</p>
<figure>
<img data-src="/images/pasted-40.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>换一个思路，对<code>mask</code>的元素做一次遍历，而不是遍历每个像素，如果是3x3的<code>mask</code>，512x512的<code>padImgArr</code>，那么循环次数就从512x512=262144次降低到3*3=9次。很容易<del>（并不是）</del>就可以发现，在整个计算过程中，<code>mask</code>左上角的橙色元素只会和图片坐上角橙色框的像素相乘，其数组乘积是最终结果的一部分。完善这个思路<del>（完整思路看图片意会去）</del>，可以写出下面的代码。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">outImgArr</span> = <span class="title">correlation</span><span class="params">(padImgArr, mask)</span></span></span><br><span class="line">    imgSize = <span class="built_in">size</span>( padImgArr );</span><br><span class="line">    outImgArr = <span class="built_in">zeros</span>( imgSize );</span><br><span class="line">    H = imgSize(<span class="number">1</span>); W = imgSize(<span class="number">2</span>);</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">-1</span>:<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">-1</span>:<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> mask(<span class="built_in">i</span>+<span class="number">2</span>, <span class="built_in">j</span>+<span class="number">2</span>)</span><br><span class="line">                outImgArr(<span class="number">2</span>:H<span class="number">-1</span>, <span class="number">2</span>:W<span class="number">-1</span>) =  outImgArr(<span class="number">2</span>:H<span class="number">-1</span>, <span class="number">2</span>:W<span class="number">-1</span>) + padImgArr( (<span class="number">2</span>+<span class="built_in">i</span>):(H<span class="number">-1</span>+<span class="built_in">i</span>), (<span class="number">2</span>+<span class="built_in">j</span>):(H<span class="number">-1</span>+<span class="built_in">j</span>) )*mask(<span class="built_in">i</span>+<span class="number">2</span>, <span class="built_in">j</span>+<span class="number">2</span>);</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p><code>if mask(i+2, j+2)</code>这一句是判断<code>mask</code>的元素是否为0，为0就跳过计算，反正0乘什么东西都是0，这对稀疏的<code>mask</code>有一定的加速作用。</p>
<p>最终优化的结果如下</p>
<figure>
<img data-src="/images/pasted-43.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>这个优化产生了10倍左右的加速，除了因为避免解释型语言的循环开销，还有可能是因为每一次向量计算的计算规模增大，SIMD非对齐内存访问的次数减少。</p>
<h2 id="max-pooling-max-filter">Max-pooling / Max Filter</h2>
<p>CNN的最大池化 (Max-pooling)和DIP的Max Filter在工作方式上差不多，只不过前者是用来缩小计算规模，后者经常拿来消除图片的某种噪声。最大池化通常配置是跨步为2，池化核为2x2，而Max Filter用CNN的黑话来说就是通常配置为跨步为1，池化核为3x3，5x5等。接下来以DIP的Max Filter为例，向量化MATLAB的代码。</p>
<h3 id="常规思路-1">常规思路</h3>
<figure>
<img data-src="/images/pasted-41.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>常规思路就是常规思路，每个像素点遍历一下，该干什么就干什么，就像上面的常规思路一样搞，代码简单朴素又原始。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">outImgArr</span> = <span class="title">reduceSAP2</span><span class="params">(inImgArr, nSize)</span></span></span><br><span class="line">    edgeW = <span class="built_in">floor</span>( nSize/<span class="number">2</span> );</span><br><span class="line">    padImgArr = padImg( inImgArr, [edgeW edgeW], <span class="number">0</span>, <span class="string">&quot;center&quot;</span>);</span><br><span class="line">    outImgArr = <span class="built_in">zeros</span>(<span class="built_in">size</span>(padImgArr));</span><br><span class="line">    inImgSize = <span class="built_in">size</span>( inImgArr );</span><br><span class="line">    inH = inImgSize(<span class="number">1</span>); inW = inImgSize(<span class="number">2</span>);</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = edgeW+<span class="number">1</span>:inH+edgeW</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">j</span> = edgeW+<span class="number">1</span>:inW+edgeW</span><br><span class="line">            outImgArr(<span class="built_in">i</span>, <span class="built_in">j</span>) = <span class="built_in">max</span>( padImgArr(<span class="built_in">i</span>-edgeW:<span class="built_in">i</span>+edgeW, <span class="built_in">j</span>-edgeW:<span class="built_in">j</span>+edgeW), [], <span class="string">&#x27;all&#x27;</span>);</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    outImgArr = uint8( outImgArr(edgeW+<span class="number">1</span>:inH+edgeW, edgeW+<span class="number">1</span>:inW+edgeW) );</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>这里的<code>padImg</code>函数是我写的用来给图像pad一圈0的。如果是在3x3范围内取最大值，那么<code>nSize</code>就为3，<code>edgeW</code>就为1，意味着pad了一圈0。如果<code>edgeW</code>为2，就pad两圈0。</p>
<h3 id="优化方法-1">优化方法</h3>
<p>如果你是PTSD和OCD患者，就往下看吧。</p>
<figure>
<img data-src="/images/pasted-42.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>一个简单的想法是把计算每一个像素需要用到的那几个数据全部给拎出来存着，很快<del>（并没有）</del>就联想起了之前的优化思路，对原始图片疯狂移位。这个时候建立一个三维数组，对原始图片疯狂移位，让临近的像素蹭到中心像素位置上，然后把临近的像素值保存到不同通道上（借用一下CNN的概念，看图片很容易理解），相当于保存了一堆错位的图片，最后把这一堆叠在一起的图片啪叽一下拍成一张图片就好了。顺着这个感觉可以写出来以下的实现。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">outImgArr</span> = <span class="title">reduceSAP</span><span class="params">(inImgArr, nSize)</span></span></span><br><span class="line">    inImgSize = <span class="built_in">size</span>( inImgArr );</span><br><span class="line">    inH = inImgSize(<span class="number">1</span>); inW = inImgSize(<span class="number">2</span>);</span><br><span class="line">    </span><br><span class="line">    edgeW = <span class="built_in">floor</span>( nSize/<span class="number">2</span> );</span><br><span class="line">    padImgSize = inImgSize + <span class="number">2</span>*edgeW;</span><br><span class="line">    stackImgArr = <span class="built_in">repmat</span>(<span class="number">0</span>, [padImgSize nSize^<span class="number">2</span>]);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = -edgeW:edgeW</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">j</span> = -edgeW:edgeW</span><br><span class="line">            stackImgArr(edgeW+<span class="number">1</span>+<span class="built_in">i</span>:inH+edgeW+<span class="built_in">i</span>, edgeW+<span class="number">1</span>+<span class="built_in">j</span>:inW+edgeW+<span class="built_in">j</span>, nSize*(<span class="built_in">i</span>+edgeW)+(<span class="built_in">j</span>+edgeW)+<span class="number">1</span>) = inImgArr;            </span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    </span><br><span class="line">    stackImgArr = stackImgArr(edgeW+<span class="number">1</span>:inH+edgeW, edgeW+<span class="number">1</span>:inW+edgeW, :);</span><br><span class="line">    outImgArr = uint8( <span class="built_in">max</span>(stackImgArr, [], <span class="number">3</span>) );</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>注意这里的<code>max</code>函数指定了参数3，意思是把第三维上所有的数据规约，变成单个值，这样就可以让三维数组降维成二维数组。</p>
<p>优化的效果也很还行，也就那么100倍的性能提升。</p>
<figure>
<img data-src="/images/pasted-44.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h2 id="牢骚">牢骚</h2>
<p>一开始让我写MATLAB，我是拒绝的。你看MATLAB的代码又臭又丑（<del>看到了其他电子系同学的代码后</del>）。后来发现随便一个MATLAB的向量操作，就有多线程优化，AVX优化，执行效率还高，同时Python的多线程性能还是那么感人，C语言起手先来句<code>#pragma omp parallel for</code>，接上一个for循环，再来两句代码，才等效一句MATLAB代码，而且说不定还引入了两个bug...MATLAB真香。</p>
]]></content>
  </entry>
  <entry>
    <title>Markdown 学习笔记</title>
    <url>/2019/06/07/Markdown-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>兼 Markdown / Latex 渲染测试</p>
<h2 id="标题">标题</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># H1</span><br><span class="line">## H2</span><br><span class="line">### H3</span><br><span class="line">#### H4</span><br><span class="line">##### H5</span><br><span class="line">###### H6</span><br><span class="line"></span><br><span class="line">H1</span><br><span class="line">====</span><br><span class="line"></span><br><span class="line">H2</span><br><span class="line">----</span><br></pre></td></tr></table></figure>
<h1 id="h1">H1</h1>
<h2 id="h2">H2</h2>
<h3 id="h3">H3</h3>
<h4 id="h4">H4</h4>
<h5 id="h5">H5</h5>
<h6 id="h6">H6</h6>
<h1 id="h1-1">H1</h1>
<h2 id="h2-1">H2</h2>
<hr />
<h2 id="分割线">分割线</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--- (短横线)</span><br><span class="line">___ (下划线)</span><br></pre></td></tr></table></figure>
<hr />
<h2 id="超链接">超链接</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Example](http://example.org/)</span><br><span class="line">[icon.png](./images/icon.png)</span><br><span class="line">[Google](http://www.google.com/ &quot;Put your mouse on this link&quot;)</span><br><span class="line">&lt;http://baidu.com/&gt;</span><br><span class="line">&lt;admin@163.com&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><a href="http://example.org/">Example</a> <a href="./images/icon.png">icon.png</a> <a href="http://www.google.com/" title="Put your mouse on this link">Google</a> <a href="http://baidu.com/" class="uri">http://baidu.com/</a> <a href="mailto:admin@163.com" class="email">admin@163.com</a></p>
<hr />
<h2 id="图片">图片</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">![HTML5](http://html5test.com/images/html5.png &quot;Put your mouse on this icon&quot;)</span><br></pre></td></tr></table></figure>
<figure>
<img data-src="http://html5test.com/images/html5.png" title="Put your mouse on this icon" alt="HTML5" /><figcaption>HTML5</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">![HTML5](http://html5test.com/images/html5.png)</span><br></pre></td></tr></table></figure>
<figure>
<img data-src="http://html5test.com/images/html5.png" alt="HTML5" /><figcaption>HTML5</figcaption>
</figure>
<hr />
<h2 id="强调">强调</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*Text1*</span><br><span class="line">_Text2_</span><br><span class="line">**Text3**</span><br><span class="line">__Text4__</span><br></pre></td></tr></table></figure>
<p><em>Text1</em> <em>Text2</em> <strong>Text3</strong> <strong>Text4</strong></p>
<hr />
<h2 id="列表">列表</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. Level 1</span><br><span class="line">  1. Lv 1.1</span><br><span class="line">  2. Lv 1.2</span><br><span class="line">* Level 2</span><br><span class="line">3. Level 3</span><br><span class="line">  * Lv 3.1</span><br><span class="line">  + Lv 3.2</span><br><span class="line">  - Lv 3.3</span><br></pre></td></tr></table></figure>
<ol type="1">
<li>Level 1</li>
<li>Lv 1.1</li>
<li>Lv 1.2</li>
</ol>
<ul>
<li>Level 2</li>
</ul>
<ol start="3" type="1">
<li>Level 3</li>
</ol>
<ul>
<li>Lv 3.1</li>
<li>Lv 3.2</li>
<li>Lv 3.3</li>
</ul>
<hr />
<h2 id="删除线">删除线</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">~~我杀我自己~~</span><br></pre></td></tr></table></figure>
<p><del>我杀我自己</del></p>
<hr />
<h2 id="引用">引用</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; 一级引用</span><br><span class="line">&gt;&gt; 二级引用</span><br></pre></td></tr></table></figure>
<blockquote>
<p>一级引用 &gt; 二级引用</p>
</blockquote>
<hr />
<h2 id="代码区块">代码区块</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">```</span><br><span class="line">$echo &quot;Hello world!&quot;</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">```java</span><br><span class="line">System.out.println(&quot;Hello world&quot;);</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">This is `Plain text` and `Java`</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$echo &quot;Hello world!&quot;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">System.out.println(<span class="string">&quot;Hello world&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>This is <code>Plain text</code> and <code>Java</code></p>
<p>注: 主要支持的语言有（我关心的） - asp - brainfuck - c - cmake - cpp - cs - csharp - css - csv - bash - go - haml - http - java - javascript - json - make - markdown - matlab - nginx - objectivec - pascal - PHP - Perl - python - rust - shell, sh, zsh, bash - sql - svg - swift - rb, jruby, ruby - vim, viml - vhdl - vue - xml - yaml</p>
<hr />
<h2 id="转义">转义</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\\ \` \* \_ \&#123; \&#125; \[ \] \( \) \# \+ \- \. \! &amp;lt; &amp;gt;</span><br></pre></td></tr></table></figure>
<p>\ ` * _ { } [ ] ( ) # + - . ! &lt; &gt;</p>
<hr />
<h2 id="表格">表格</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">RowA | Row B</span><br><span class="line">--- | ---</span><br><span class="line">A1 | B1</span><br><span class="line">A2 | B2</span><br><span class="line">A3 | B3</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr class="header">
<th>RowA</th>
<th>Row B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A1</td>
<td>B1</td>
</tr>
<tr class="even">
<td>A2</td>
<td>B2</td>
</tr>
<tr class="odd">
<td>A3</td>
<td>B3</td>
</tr>
</tbody>
</table>
<h2 id="latex">Latex</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">`$\pi$`</span><br><span class="line"></span><br><span class="line">`$\int_a^b f(x) dx$`</span><br><span class="line"></span><br><span class="line">\\(lim_&#123;x\rightarrow \infty&#125;\frac&#123;1&#125;&#123;\sin x&#125;\\)</span><br><span class="line"></span><br><span class="line">\\(lim_&#123;n\rightarrow \infty&#125;(1+2^n+3^n)^\frac&#123;1&#125;&#123;x+\sin n&#125;\\)</span><br></pre></td></tr></table></figure>
<p><code>$\pi$</code></p>
<p><code>$\int_a^b f(x) dx$</code></p>
<p>\(lim_{x}\)</p>
<p>\(lim_{n}(1+2<sup>n+3</sup>n)^\)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$$</span><br><span class="line">P(A_i \mid B) = \frac&#123;P(B\mid A)P(A_i)&#125;&#123;\sum_&#123;j=1&#125;^&#123;n&#125;P(A_j)P(B \mid A_j)&#125;</span><br><span class="line">$$</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
P(A_i \mid B) = \frac{P(B\mid A)P(A_i)}{\sum_{j=1}^{n}P(A_j)P(B \mid A_j)}
\]</span></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>NUS SoC Summer Workshop 日记</title>
    <url>/2019/08/18/NUS-SoC-Summer-Workshop-%E6%97%A5%E8%AE%B0/</url>
    <content><![CDATA[<p>总体来说，如果希望体验一下不同的教学方式，Make Good Product Great Again (以下简称为Product)这个Topic是可以参加体验的。但是如果希望像传统课程一样，想确保自己能学到计算机知识，就不是特别推荐这门课了。</p>
<p>先从教学方式说起。Product的上课方式并不是我们这种短期交流学生“独享”的。其实NUS Soc在Summer Special Term里的给自己的学生开的部分课程也采用了这种教学方式，即教授给定一个方向，让学生想做什么东西就做什么东西，教授给予指导意见让学生对自己作品进行修改，而不是照本宣科。最后给分的方式取决于某种标准，如东西的创新性或者实用性。简单的堆砌技术并不能保证能让你拿高分。</p>
<p>在Product这Topic中，教授让我们制作一个具有优秀User Experience (简称UX)的手机App，或者说是产品。起初介绍了UX的一些知识，评论了一些产品UX方面的优缺点，然后就放手让我们自由发挥了。我们需要做的是，确定自己要做什么App，先做个Prototype，接着做个Pre，教授和学生给出建议，然后修改Prototype，再做Pre，如此循环几次。然后再用编程做出自己的App，最后Final Showcase上展示。</p>
<p>教授建议我们使用Adobe Xd或是PowerPoint进行Prototype的设计，以及使用Node.JS编写后端。以上内容全部自学，当然要如果使用别的工具来展示自己的创意都是可以的。</p>
<p>其实问题就来了，前几次Prototype的迭代花掉了不少的时间，然后所有的用到的技术都要自学，所以显而易见，App是做不完的。最终Showcase上很多人是直接展示自己的Prototype（也就相当于能操作的PPT），或者展示完成度很低的App。</p>
<p>对于我来说，最困难的一点反而不涉及计算机知识那部分（因为我们组放弃了编程），而是在于，我们要做个什么App的问题上。最初的问题表现在，缺idea，这个情况其实很常见，毕竟好的idea大多数已经有现成的产品了。接着我们确定了idea，找到了日常生活中的一个痛点，但是在痛点的解决方案上我们组里面产生了严重的分歧。由于组内大多数人缺乏产品的设计经验，同时对自己能力的把握不足，以及思考方式不够成熟，考虑事情不充分，最初的几个产品方案有新手常见的几个毛病：在假想的应用场景下去想象用户可能碰到的问题，然后胡乱的给产品添加功能，导致主要功能跑偏; 想做一个包罗一切的大平台却又只能拿出嘴上可行的实现方案; 不能明确自己要解决什么问题; 要解决的问题实际上不存在等等毛病。（以上毛病在我过去参加创新大赛的时候多少都存在。）所以我消耗了大量的时间精力去劝说和阻止他们继续跳坑，也导致了整个组前期根本不在状态上。</p>
<p>或许这种踩坑经验才是老师希望我们获得的东西，毕竟这种经验没踩过都不知道，光靠课本和别人口述也没啥用，因为我们的其他组员也是知道要避免什么，但越想避免什么，什么就发生了。</p>
<p>所以总的来说，这是一门想传授给你课本不能传授，只能在实践中学到的知识的一门课程。当然我还期待着能学学前后端，想看看是不是有如相声般精彩又蕴含着维基百科级的信息量的Lecture，并以此衡量我们系饱受批评的教学质量是否有如传闻中那么不堪。很遗憾，这个愿望只能留给下一次的交流活动了。</p>
<p>另外NUS的建筑物真的是比我们像得罪了设计师一样的建筑美观太多。</p>
]]></content>
      <categories>
        <category>吹水日记</category>
      </categories>
      <tags>
        <tag>NUS</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenWRT路由器加速Switch联机的方案</title>
    <url>/2021/03/02/OpenWRT%E8%B7%AF%E7%94%B1%E5%99%A8%E5%8A%A0%E9%80%9FSwitch%E8%81%94%E6%9C%BA%E7%9A%84%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<p>Switch的NAT Type是一个很迷惑的东西，因为似乎没有人能够解释清楚NAT Type的每个类别对应什么意思，又会有什么影响，但是这玩意似乎又能决定一些游戏能否成功联机，比如喷喷。网络上什么说法都有，不过经过我一段时间的摸索，终于理解一丝丝Switch联机的秘密，并找到了不依靠商用加速器提升NAT Type的方法。</p>
<h2 id="声明">声明</h2>
<p>这篇文章适合对计算机网络有一定了解的（至少得知道NAT，TCP，UDP这些词），乐于请教搜索引擎，也有兴趣和能力部署爬墙工具的玩家，因为大家都知道的原因，本文将不会包含手把手部署爬墙工具的内容。实施这个方案也需要时间，耐心和勇气，有可能在部署过程中就把家里网弄塌了，而且大概还是要花点钱，折腾完了发现还是商用加速器香。</p>
<h2 id="nat-type">NAT Type</h2>
<p>一般来说，NAT Type可以分为很多种，最经典的分类是RFC 3489里的，其中最受限的是对称形（Symmetric），最开放的是完全锥形（Full Cone）（注：无NAT的公网也可以被认为是完全锥形网络），简单来说就是联机双方网络受限程度越重，双方能够直接通信的可能性越小，也就是UDP打洞的成功率越低，因此NAT类型会对某些游戏的联机产生影响。<del>这里还是得喷任天堂，明明只要像CF一样弄个公共服务器辅助双方的通信就没这么多破事了，就算双方都是对称形都没关系。</del></p>
<p>根据我的观察和网上的资料，Switch的NAT Type A差不多等同于RFC 3489中定义的<strong>完全锥形（Full Cone）</strong>。不过很遗憾，出于安全考虑，<del>以及封杀P2P的需要</del>，大部分国内网络别说各种受限的锥形了，基本上都是对称形，大多数玩家裸连都能喜提一个Type C或者D。还好，拯救对称形网络是完全可行的。</p>
<figure>
<img data-src="https://user-images.githubusercontent.com/63339210/107102123-5ed9d900-6811-11eb-9c00-6165ed9c18a2.gif" alt="img" /><figcaption>img</figcaption>
</figure>
<h2 id="加速的思路">加速的思路</h2>
<p>通常网上常见的思路有两种，<del>DMZ法</del>，HTTP代理法，和透明代理法。<strong>这篇文章是基于透明代理的思路实现Switch联机加速</strong>。</p>
<h3 id="dmz法"><del>DMZ法</del></h3>
<p>这种方法通常没什么luan用，能通过DMZ提升NAT Type，仅适用于以下情况：</p>
<ul>
<li>运营商（ISP）给你家整了公网IP地址</li>
<li>你给你家整了路由器</li>
<li>同时路由器的防火墙设置比较严格</li>
</ul>
<p>考虑到绝大部分的人拿不到公网IP地址，这方法几乎不适用于绝大部分人群。就算有你家有公网IP地址，考虑到一般情况下你的数据包都会走稀烂的国际出口，你的Switch也不能稳定连接到其他玩家的设备。</p>
<h3 id="http代理法">HTTP代理法</h3>
<p>这个方法有一点luan用，确实能加速下载游戏（因为下载是TCP通信），但不能提升NAT Type，原因非常简单，<strong>HTTP代理不能处理UDP包</strong>，也就是对于一些游戏来说，开和没开代理没有任何区别，因为那部分游戏的联机依赖UDP通信。</p>
<h3 id="透明代理法">透明代理法</h3>
<p>这个基本上就是最后的大招了。参考下图，电脑手机游戏机的数据包其实是先发送给网关（Gateway）来处理（一般路由器充当了网关Gateway，交换机Switch，和猫Modem），也就是说<strong>网关会拿到所有的数据，包括TCP包和UDP包</strong>。</p>
<p>已知所有问题都是因为NAT，缺少公网IP造成的，那么如果我们刚好有一个有公网IP地址的VPS，能不能让Switch借用我们的VPS服务器的公网IP地址当作自己的IP地址完成通信？「借用身份」这个思想，其实就是「代理」这个词的含义，最初用于保护隐私，只不过我们通常用代理去干了一些别的事情。</p>
<p>因此，<strong>这篇文章的主要就是让你折腾一个透明代理</strong>，所谓透明代理，在这篇文章里就是路由器拿着Switch的数据包，先传送到VPS上，以VPS的公网IP地址完成收发，而不是直接用路由器的IP地址收发。</p>
<p>题外话，我还购买了腾讯加速器的服务，它要求修改Switch上的网关地址，本质上也是一种透明代理，而且也能提升到Type A，<del>不过感觉只有SVIP才能保证喷喷不掉线</del>。</p>
<figure>
<img data-src="https://www.globalspec.com/ImageRepository/LearnMore/20164/556af08d5e43aa768260f9e589dc547f-30246b5198cb214841beb88cefade318458a.png" alt="Network Diagram with Gateway Server via HowToForge" /><figcaption>Network Diagram with Gateway Server via HowToForge</figcaption>
</figure>
<h2 id="部署透明代理">部署透明代理</h2>
<p>可能你会说，说了大半天，不就是要上透明代理嘛，这种教程到处都是。确实，不过这篇文章不会过多的深入配置的细节。</p>
<h3 id="软件的选择">软件的选择</h3>
<p>一般的透明代理常用以下几种软件：</p>
<ul>
<li>Shadowsocks系：包括SS，SSR，SSRR等等</li>
<li>V2Ray系：包括V2Ray，V2Fly，和Xray</li>
<li>Trojan</li>
</ul>
<p>我个人倾向于使用V2Ray系，可玩性非常高，支持的协议非常的全面，同时一些分支（如Xray）迭代的速度非常快，大量引入新特性。此外，据Xray作者所述，V2Ray原版UDP代理的实现一言难尽，可以欣赏这篇文章<a href="https://v2xtls.org/进阶必读：代理协议-udp-全方位透彻解析/">进阶必读：代理协议 UDP 全方位透彻解析 - V2Ray XTLS黑科技 (v2xtls.org)</a>感受Xray作者的无奈。所以本文将会使用<strong>Xray</strong>这个实现，而不是原版V2Ray。</p>
<p>Shadowsocks系和Trojan当然没啥问题，只不过本文不会介绍它罢了。</p>
<h3 id="服务端配置">服务端配置</h3>
<p>略，可参考V2Ray的配置教程，毕竟这里老司机任意发挥各显神通的地方，我就不插嘴了，注意服务端和客户端<strong>一定都要用Xray</strong>，否则最后配置成的网络不是Full Cone的NAT，也会有UDP断流的问题（参见issue：<a href="https://github.com/V2Ray/V2Ray-core/issues/1614">玩彩6或者开Origin时，断流严重</a>），推荐使用Docker部署。</p>
<h3 id="路由器配置">路由器配置</h3>
<p>推荐按照先这篇文章<a href="https://www.solarck.com/openwrt-V2Ray.html">一文玩转V2Ray 透明代理 | Solarck</a>部署。注意最好使用<strong>官方原版OpenWRT</strong>，基于某个Snapshot构建的同时打包了一堆插件的OpenWRT可能会产生兼容问题，当然刚好集成了文章中提及的插件的包可以试着用用。</p>
<h3 id="替换路由器v2ray版本">替换路由器V2Ray版本</h3>
<p>由于原版V2Ray在处理UDP包的流程上有严重缺陷，所以必须要替换路由器上的V2Ray版本。首先在<a href="https://github.com/XTLS/Xray-core/releases">https://github.com/XTLS/Xray-core/releases</a>上下载Xray，注意区分路由器CPU指令集，如<code>armv7a</code>或者<code>x64</code>什么的。在电脑上下载再用<code>scp</code>上传，或者直接在路由器上<code>wget</code>都可以。将压缩包解压后，用解压出来的<code>xray</code>文件替换路由器上的<code>/usr/bin/v2ray</code>文件，再在OpenWRT网页端重载V2Ray服务即可，看到网页上显示V2Ray版本为Xray即可。</p>
<figure>
<img data-src="/images/pasted-63.png" alt="img" /><figcaption>img</figcaption>
</figure>
<h3 id="验证配置">验证配置</h3>
<p>当然用Switch直接做测试就可以了，不出意外的话能看到NAT Type A了，如果不是，可以检查VPS的防火墙配置。</p>
<p>Windows下测试推荐使用<a href="https://github.com/HMBSbige/NatTypeTester">NatTypeTester</a>，注意关闭Windows防火墙以免其影响测试结果。</p>
<figure>
<img data-src="/images/pasted-64.png" alt="img" /><figcaption>img</figcaption>
</figure>
<h2 id="结论">结论</h2>
<p>不是吃饱了撑着或是有特殊需求，如用Switch看YouTube，建议还是上个加速器吧，VPS也是要钱的啊，而且人家付费加速器的线路大概率会比你随手买的VPS更好。</p>
<h2 id="参考文章强烈建议去看看">参考文章（强烈建议去看看）</h2>
<ul>
<li><a href="https://v2xtls.org/进阶必读：代理协议-udp-全方位透彻解析/">进阶必读：代理协议 UDP 全方位透彻解析 - V2Ray XTLS黑科技 (v2xtls.org)</a></li>
<li><a href="https://www.solarck.com/openwrt-V2Ray.html">一文玩转V2Ray 透明代理 | Solarck</a></li>
<li><a href="https://github.com/V2Ray/V2Ray-core/issues/1614">玩彩6或者开Origin时，断流严重</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>SC21回顾 - 赢了，但只赢了一点点</title>
    <url>/2022/01/01/SC21%E5%9B%9E%E9%A1%BE-%E8%B5%A2%E4%BA%86%EF%BC%8C%E4%BD%86%E5%8F%AA%E8%B5%A2%E4%BA%86%E4%B8%80%E7%82%B9%E7%82%B9/</url>
    <content><![CDATA[<p>SC21又又又又是在线上打的。第二年痛失美帝免费旅游机会了！！！第二年了！！！<del>没有机票，酒店，和大吃大喝的比赛能叫比赛吗！</del>不过结果还是不错的，远远的超出我的预期（原因请看下文分解）。</p>
<h2 id="sc20没有什么比这更绝望的了">SC20：没有什么比这更绝望的了</h2>
<p>时间回到去年，我并没有给SC20写回顾，因为这场比赛打得实在是——太！烂！了！烂到以至于取得了倒数第二的优异成绩，烂到了我都不好意思把这个比赛写进简历里，烂到了我到SC21开赛的时候才去问SC20的成绩。尽管SC20是我们第一次参加的SCC，但不至于烂的这么有特色。上一场比赛出现了包括但不限于以下这些情况，</p>
<ul>
<li>完全不存在的赛前准备，虽然时任队长已经尽力在准备Cyclecloud的环境了（甚至去研究了<code>cluster-init</code>），但其他队员似乎就完全没碰过云环境（伏笔1）</li>
<li>两个16级的跑路了（不过当时拉他们过来的时候，也说好了他们可以当placeholder）</li>
</ul>
<p>我自己那时候负责的是复现挑战，不过我当时根本就不知道复现挑战要干嘛，甚至把精力放在了改代码上。我用了GDR来优化GPU P2P通信来着，还觉得自己挺牛批的来着（伏笔2）。Webinar完全没有看，到了比赛的时候才知道要“在46小时的时间里写出具有发表在国际刊物水平的report”。我作为一个无paper选手（截至目前也还是没paper），用Excel都画不明白的那种，到了场上才发现——坏了。</p>
<p>要复现的论文里提出的程序MemXCT有CPU和GPU的版本，比赛要求用两个版本跑出来的数据画图写报告。GPU版本这边，由于之前完全没用过云集群，我完全不知道云上预装了什么东西。队长在强力推销他的HPCX OpenMPI库，而我自己在测试的时候用的是NVIDIA HPC SDK里的OpenMPI。我一想，HPCX是NVIDIA的，HPC SDK也是NVIDIA的，它们的OpenMPI应该是同一个东西吧。结果很显然，MPI炸得很灿烂，程序就是死活都跑不起来。在无穷无尽的MPI调参和重新编译，MCA的各种参数各种排列组合都试了一圈以后，嗯，没有什么效果。套GDB单步慢慢调，去找爆炸源（那一会我还不知道GDB可以直接Traceback），发现就是我改的GDR P2P那几行代码炸了，但HPCX的OpenMPI不是自称是CUDA Aware还支持GDR的吗，年少无知的我并没有对HPCX产生怀疑，从第一天开始，一直瞎勾巴试到第二天晚上，才想到用回NVIDIA HPC SDK试试。MPI一换，什么问题都没有了。得益于这段时间里，我享受了长达4个小时的精致睡眠，我的大脑throttle到完全没有意识到“放弃这个优化”这个操作（且复现题压根就不需要优化），哪怕是其他Application，把程序跑起来才是重中之重。</p>
<p>CPU版本这边，<del>总所周知（并没有）</del>，我们可以用<code>mpirun</code>的各种各样奇奇怪怪的参数（如<code>ppn</code>，<code>map-by</code>）或者Job Scheduler（如Slurm）来绑核。然而当时我既不懂Slurm，又不懂<code>mpirun</code>的参数，完了这程序还是Hybrid的（MPI + OpenMP），需要给MPI Rank分配多几个CPU核，而不是1个Rank一个核。我一顿操作猛如虎。好消息是，程序跑起来了。坏消息是，程序以一种很奇怪的姿势运行在多个节点上，比如明明要跑四节点，却出现了一节点有难，三个节点围观的情况。</p>
<p>到了比赛快结束的时候，两边才正常跑起来，由于根 本 没 有 提 前 写 论 文，也 不 知 道 怎 么 画 Academic的图，要不是有一个临时安排的帮手，在比赛结束前report写不完也就算了，估计连张图都画不出来。由于交的实在是太晚，这堆学术垃圾在提交到一半的时候比赛就结束了，这样也好，这篇完成度极低的黑历史就再也不会有其他人看到了。</p>
<p>其他人那边也没好到哪去，由于赛前准备什么的基本不存在（人还跑路了），Applications不能说是一塌糊涂，只能说是亿塌糊涂，基本上拿不到几个分，CESM跑不出，GROMACS只跑了一点，倒是MiniVite似乎还行。最后只能寄希望于Benchmarks，把剩下的Funding All in到Benchmarks上，说不定还能捞一个单项奖。当时他们刷了半天HPL，最后刷到了120TFlops，混到了<strong>暂时的</strong>第一，反手就被ETH的129T打成灰了，反手反手就被半夜想搞大新闻的THU搞出了大新闻，300T打得灰都不剩了。与此同时T队的HPCG，IO500分也把榜打爆了，这两玩意的分数是当时榜一（可怜的靶子）的3.89倍，5.76倍，似乎看到了摩尔定律复活的希望。在这种分数差面前，我们并没有任何反抗的余地，只能对其深夜5am炸鱼的行为表示强烈的谴责。</p>
<p>赛后才知道，HPL和HPCG方面，T队几个月前向组委会提交的plan里，早就盘算着把Azure机房洗劫一空，只要我GPU堆得越多，跑分速度就能快到其他队连尾气都闻不到，只要我操作够快，火速开机火速关机，一大堆GPU也花不掉几个钱。并且充分考虑到V100节点不够的问题，也准备了转用其他GPU节点的预案。组委会许可了他们的方案<del>，并搬出板凳坐等看戏</del>。反倒是我们的HPL因为超规格的问题，被扣分扣成了倒数。IO500更是离大谱，自研了打榜专用文件系统MadFS（详见<a href="https://www.youtube.com/watch?v=NRZhFoBC_Ak&amp;t=8s">金枪鱼之夜——IO500 S: There is rjgg behind MadFS - YouTube</a>），科研成果下放到学生超算竞赛，直接形成降维打击，不得不说THU的System方向真是tql，TUNA里个个都是人才，说话又好听。</p>
<p>总之，要不是SC21打得不错，我是再也不会去提SC20的事情了。</p>
<h2 id="sc21-phase-0队友人呢">SC21 Phase 0：队友人呢？</h2>
<p>今年招新的结果非常意外，忽悠到了一些《建议直接颁发硕士毕业证》的20级新人。今年招新是让感兴趣的入队的人做一份笔试题，目的当然是选出愿意去了解这个领域并去做一些搜索的人，由于计系没有哪门课介绍了超算，我对于他们的预期就是《言之有理即可》，aka《有字就行》，结果出现了这种情况，</p>
<blockquote>
<p>Neko.d&gt; 同学你好，由于你以一己之力让我怀疑题目出得太简单了，所以我希望今天能和你当面聊一下...</p>
</blockquote>
<p>怎么会有人开局（大一）就几乎啥都懂啊，那还要我们老油条干嘛？</p>
<p>但另一个问题出现了，这次招新一个妹子都没忽悠到，不像去年又有Female还有Transgender，Diversity直接拉满，四舍五入直接等于保送进决赛。今年我们队里现在全是臭男人，proposal就只能尬吹我们辉煌的过去。</p>
<p>在写proposal的时候，本想把任务拆分，先写个中文的大纲，offload给其他队友，让他们输出English paragraphs，再merge成一个完整的proposal。结果真到offload的时候，赶作业的赶作业，赶paper的赶paper，这也就算了，还有去外面嗨然后装死的。当队长这个大锅抛到我头上的时候，距离交proposal的ddl已经没几天了，还得去拉浪潮的赞助。发现队友都指望不上还没时间自己搞定的时候，我只能无能狂怒，</p>
<blockquote>
<p>Neko.d&gt; I AM REALLY ANGRY!</p>
</blockquote>
<p>但我angry并没有什么用，proposal还是得写，最后想到了一个惊为天人的解决方案：用谷歌翻译把提纲翻译一下，我看两眼改一改就交上去了，反正我只要坚信reviewer不喜欢看一大段一大段的屁话，我的良心就不会痛。</p>
<p>几个月以后收到消息，令人意外，我们用脚写的proposal过了，倒是T队挂了（不过靠着ISC冠军又回来赛场了，你大爷还是你大爷），听说还有几个国内的强校也挂了，目测多数死于Diversity。虽然我们Diversity吃了一个reviewer的低分，但其他的reviewer好像成功的被忽悠过去了。<del>参赛前务必把美式政治正确玩明白了。</del></p>
<h2 id="sc21-phase-1还能抢救一下">SC21 Phase 1：还能抢救一下</h2>
<p>众所周知，我是摸鱼之王，摸鱼从来就没输过，摸到组委会专门发邮件催我们上号，<del>摸到连队友不敢摸了。</del></p>
<blockquote>
<p>组委会&gt; Azure说你们从来没有上过号。马上比赛了，想问问你们是不是网络不好，登不上号啊？有问题的话要跟我们说啊。</p>
<p>组员1&gt; 所以什么时候练习啊</p>
<p>组员2&gt; 所以什么时候练习啊</p>
</blockquote>
<p>Oracle集群的试用期也就五天，到账号激活的第二天我才想起来还有这事（我紫菜）。集群配置比较常规，主要是不存在伸缩问题，在试用的时候没发现太多的问题（主要是因为很多东西没来得及试）。</p>
<p>一个不大不小的事故是，因为我想让队员在练习的时候熟悉Linux的账号机制，就让他们改<code>passwd</code>和<code>sudoer.d</code>。然而我低估了修改<code>sudoer.d</code>的风险，因为这个东西改炸了<code>sudo</code>就用不了，想还原<code>sudoer.d</code>的配置来抢救<code>sudo</code>本身又需要<code>sudo</code>权限，好家伙死锁了。不得已，只能寻求场外援助，Oracle的Technical Leader，Marcin老哥。老哥一看我的问题，见怪不怪，熟练的向我们推销serial console下grub改<code>bootargs init=/bin/bash</code>之术，想必他的客户自己（哦是我啊，那没事了）也没少搞炸系统。当grub的界面显示在Windows Terminal下的时候，我大受震撼，这还是我第一次看到在serial console下的grub，而且还保留了原汁原味的TUI。改好参数，顺利以root身份登录系统，直接把写坏的配置删掉就完事了。</p>
<blockquote>
<p>Marcin&gt; :) Sysadmin Sunday</p>
<p>Neko.d&gt; Oh. Sorry to disturb your beautiful Sunday morning lol.</p>
</blockquote>
<p>Marcin老哥是个大好人（会救我们的人是好人，周末来救我们的人就是大好人啦！），此外他还教我挺多实用的东西，比如，</p>
<ul>
<li>一键关掉超线程</li>
<li>一键添加集群账户（集群预装了LDAP的东西）</li>
<li><code>playbook</code>自动化工具（据说可用于重装部分软件）</li>
<li><code>ssh-agent</code></li>
<li>...</li>
</ul>
<p>到了Azure这边就没那么幸运了，赛前中后和其他队的运维瞎聊，大家无一例外的碰到了，</p>
<ul>
<li><code>cloud-init</code>更新的配置不被应用。公认的workaround是，要想改<code>cloud-init</code>脚本，重建集群吧！也就等十多分钟就好了！很快的！这导致我不敢写很复杂的init脚本</li>
<li>image的一堆坑
<ul>
<li>VM的世代数和Image支持的世代数不一致，需要手动指定隐藏镜像<code>OpenLogic:CentOS-HPC:7_9-gen2:latest</code>（后来发现这还是个陈年已知问题，上一任运维知道，但不说）
<ul>
<li>有个好心人给了个魔法PowerShell指令来捅出镜像列表</li>
</ul></li>
<li>只有CentOS 7.9的镜像带了驱动，8.1的没有
<ul>
<li>可以自己装驱动，GPU部分不仅需要GPU本身的驱动，还需要NVSwitch的驱动，叫Fabric Manager。如果NVSwitch的驱动不正常，会报一个<code>cudaErrorSystemNotReady</code>的错
<ul>
<li>补充：驱动的安装程序和安装目录不要都在NFS盘上，建议把全家桶拷到本地盘再安装，能大幅提升安装速度</li>
</ul></li>
<li>IB部分可以装OFED全家桶（还有坑，伏笔）</li>
</ul></li>
</ul></li>
<li>魔改过的Slurm会在VM发生不明原因初始化配置超时的时候把好不容易allocate到的VM释放掉，尽管VM能正常使用。（每次开节点都要排十多分钟的队，然后大概率配置超时，这谁顶得住啊）</li>
</ul>
<p>值得一提的是，我们几个运维一致认为Azure的技术支持Andy是个装死带师，我们三个都被Andy无视了。跑去跟SCC主席Kathleen complain，</p>
<blockquote>
<p>Kathleen&gt; 啊，Andy早在Webinar里说过自己最近忙了，你是不是没去听啊</p>
<p>Kathleen&gt; 还有你们Stand up meeting跑哪去了</p>
</blockquote>
<p>彳亍口巴。Andy告诉我唯一有用的东西就是，CycleCloud Console的<code>cloud-init</code>脚本可以不是<code>cloud-init</code>脚本。</p>
<p>实际试用的时候，Azure上来就是开幕雷击，先是遇到了世代数的那个问题。到比赛快开始的时候才开GPU节点练习，（因为A100很贵，27刀一小时，而且队员之前没准备好，还没把CPU版折腾清楚），这个时候才发现CentOS 8的镜像要啥驱动都没有，自己一装驱动又踩了NVSwitch的坑。搞了半天还搞不定，仔细一想每次开VM都要装驱动，难顶，只能碰运气看看7.9带不带驱动。还好驱动是全的（似乎也是唯一一个带全驱动的镜像）。降系统版本又造成了一些小问题，什么缺Lmod导致module load intel全家桶出锅啊，什么GCC版本太老导致C++ ABI出锅啊，好在这些问题还是能解决掉的。</p>
<p>除了被两边集群的“特性”折腾以外，似乎没有太多问题了，也就记得有</p>
<ul>
<li>Spack会把tmp目录挤爆，改TMPDIR环境变量就可以了</li>
<li>Spack不会自己更新和确认过时的编译器信息，然后还把错误的信息缓存了，需要clean一下bootstrap就好了（<code>spack clean -b</code>）
<ul>
<li>NVIDIA HPC SDK也有类似的问题，Any changes to your gcc compilers requires you to reinstall the HPC SDK</li>
</ul></li>
<li>默认情况下<code>nfslock</code>没启动，导致No locks available</li>
</ul>
<p>其他队友那边，一开始大家还自信得一批，仿佛人均编译带师，到了自己编译应用的时候，尤其是用Spack编译一些依赖（e.g., 比如OpenBLAS和FFTW）的时候，或者要编译GPU版代码的时候，编译器就能给你炸得妈都不认识。只好各种换编译器换姿势编译，什么GCC，ICC，ICX，NVC都用了一圈。年幼无知的队友甚至还对AMD有一丝信任，想用AOCC和AOCL平替，结果我就不说了，懂得都懂。最后发现还是老一套，ICC+MKL稳如老狗。（其实是一开始我忘装了MKL，所以让他们先试OpenBLAS，然后就欣赏编译器烟花了）还有NVCC经常会选错Host编译器，得加<code>--ccbin</code>啥的。总之，你永远不知道最终生成的看上去能运行但大概率会爆炸的二进制文件是几个编译器生成的代码缝合在一起的产物。</p>
<h2 id="sc21-phase-2演我们">SC21 Phase 2：演我们？</h2>
<p>Azure试用到没钱的后一天就正式比赛了，<del>可见我们什么时候才开始赛前准备</del>。按照基本上等于废话的计划，第一天开局打算先让复现和Cardioid跑，总之就是先把Oracle集群用起来，反正没有预算限制，QE和神秘应用这种要花Azure钱的晚一点再上也不迟。9.30am有个meeting，还以为要公布instructions了，结果除了打一个尬飞了的招呼以外，什么事都没发生，instructions一个字都没看到（后来才意识到这个meeting是用来把我们骗进breakout room然后给其他人直播比赛事故现场的）。</p>
<p>不得不说今年的instructions有点随意啊，不仅公布时间随意，而且，</p>
<ul>
<li>Submission的instruction甚至直接用的去年的，一个字都没改</li>
<li>有一题的instruction放在GitHub上，放出来不久又改回private返工了</li>
</ul>
<p>这潦草的instructions让本来就因为remote而显得不正经的比赛看起来更不正经了，好想打场正儿八经的SC现场赛啊<del>，但没机会了</del>。Anyway，比赛还得打。</p>
<h3 id="cardioid">Cardioid</h3>
<p>assign的同学巨屌无比（还是20级的），基本上可以称为修bug自动机，因为他有NVRTC和LLVM+PTX瞎搞的经验，这题就扔给他做了，总体来说没有遇到太多的问题（因为bug都瞬间被修掉了导致我对其并没有什么太深刻的印象）。</p>
<ul>
<li>在测试的时候就发现跑GPU多节点会出问题，但Oracle上只有一个GPU节点，那没事了。Cardioid似乎有几个variants，但只有一个能跑，但比赛就只用那一个，那又没事了</li>
<li>Cardioid看上去可以直接用Spack整体编译，但，试了的都说sucks。似乎有的队一直卡在Spack上，其实直接不用Spack，手动编译就好了</li>
<li>Oracle的集群用的是Oracle Linux 7，based on REHL 7，<del>也就是说和CentOS 7的环境差不多一样老</del>。所以也出了C++ ABI的问题，好在临时抱佛脚了</li>
</ul>
<p>比赛要求跑几十套参数，大概要换几种网格尺寸，精度，计算方法跑，总共要跑几十种组合。跑了一轮下来，发现某一类参数组合会炸，总结一下有几种爆炸的姿势。第一种炸法，用gdb Backtrace一查，哦就是文件权限没设对，低级错误。第二种炸法，算出了NaN。但仔细读instruction，发现出题人似乎早就预料到选手们能跑出NaN，因为有一个问题就在问”你们见过NaN了吗“之类的，那肯定就是出题人故意设的坑。年轻的队友看不懂人性的险恶，甚至萌生了改代码去修NaN的想法。第三种炸法，发现backtrace不出来，怀疑是栈炸了。先改了ulimit，无限栈空间，不行。单步调试到一个for循环读取数组，程序就异常了。我大脑一瘫，居然怀疑这个读取操作炸了栈（读取操作不会写入栈啊喂！），因为数组在高地址的堆里（<code>0x7ff</code>），离栈很近，说不定越界越到栈上了，甚至去算了base+size有没有大于esp的地址，结果是完全没事。继续debug，又遇到了一些匪夷所思的事情，比如不可复现的爆炸，第一次看到值异常，第二次就值正常了。我直接进行一个思考的放弃，1am了，到点睡觉了，day2还得通宵，于是就留这个守夜的队友就自己继续debug。</p>
<p>第一天晚上有三个在学校的队友守夜，主因是组委会完全无视50%队伍来自中国的事实，要求我们在12am-8am开摄像头供人围观（<del>直播睡觉？</del>）。跟Chair complain，</p>
<blockquote>
<p>Kathleen&gt; 你咋不早说</p>
</blockquote>
<p>我还指望其他中国队会比我更早发现这个问题然后去argue，怎么只有我被喷了。Chair最后还在Warp up meeting还说，有些队伍不喜欢social只想去睡觉。（<del>不会吧，不会吧，不会还有人打比赛还想睡觉吧。</del>）</p>
<p>洗完澡刚躺平的时候，那个队友就发消息说，de出来了，gdb不靠谱，还是printf大法好，最后查出来是integer overflow了。好家伙overflow和underflow都齐了，那肯定是出题的人故意的。这个overflow有一个tricky的workaround，让MPI跑在更多节点上就好了，因为会发生这个overflow的算式会除以节点数，节点数一搞大就不overflow了。八卡跑八进程，不能再多了？不存在的，一张卡跑两个MPI进程就完事了。（不过我估计还是栈烂了导致GDB行为诡异，说不定是RDMA把栈写坏了，因为这个overflow的结果似乎会propagate到MPI的参数）。</p>
<h3 id="复现">复现</h3>
<p>搞复现的同学因为饱读各种AI paper就被我抓过来做这题，最初他以为现场赛的难点是在写paper上，因为之前在Azure上测试的时候一切都稳如老狗，虽然没时间测Oracle，但问题应该不大吧......吗？</p>
<p>真到了在Oracle上就，不得不说真是充满了惊喜（指新bug）。Oracle这边不像Azure，没有自带MVAPICH，只能自己用Spack编译一个，IB卡配置得也比较复杂，似乎是双口100G的RoCE，不像Azure是单口IB。程序似乎能正常编译运行下来，能跑出一些结果，只不过嘛......偶尔会在计算末期爆炸一下啦。根据我没几年的丰富经验，只要MPI程序能够跑出结果，问题就不是很大。一开始盲猜是运气问题，爆炸是随机的，重跑一次就好了。重跑了几次发现，是特定组合下的参数100%会炸，而且似乎是MPI的内部错误，挂在了同一个MPI函数上。由于程序总是在几十分钟后炸，用gdb调试几次可能一两个小时就没了，就打算先试各种民间偏方，同时先把能跑的点跑下来。</p>
<p>诡异的是，改无限栈空间，换MVAPICH的版本，使用Slurm，加MPI运行参数，都<strong>有时候</strong>能让程序跑起来，之后又失效了。也发现一些方法根本就没用，比如改编译MVAPICH的fabric参数，或者换HPCX MPI（然而自带的这玩意就没成功运行过）。从白天调到大半夜，程序一直处于能运行与不能运行的叠加态。Day2早上回到会议室，看得出那个队友被折磨了一晚上，身体已经完全被掏空了，大脑完全停止了思考。在我睡觉期间，队友去问了大好人Oracle的工程师Marcin，他给了<a href="https://blogs.oracle.com/cloud-infrastructure/post/running-applications-on-oracle-cloud-using-cluster-networking">一个写满了各种魔法MPI参数的博文</a>， 然而这个魔法博文里提供了OpenMPI的参数，提供了Intel MPI的参数，提供了Platform MPI的参数，就是没有提供MVAPICH的，队友试着照着博文的参数复刻出一套MVAPICH的参数，然而并没有什么用。</p>
<blockquote>
<p>Fun Fact：大好人Marcin在第二天晚上也帮我们试了一下MVAPICH，并给了一套参数，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -hosts hpc-node-1,hpc-node-2 -env MV2_IBA_HCA=mlx5_2 -env MV2_USE_RoCE=1 /nfs/cluster/osu-micro-benchmarks-5.8/mpi/one-sided/osu_get_latency</span><br></pre></td></tr></table></figure>
<p>我队友除了没指明<code>MV2_IBA_HCA</code>以外，其他参数都是这么写的。（不过其实我怀疑加了<code>MV2_IBA_HCA</code>这个就好了，只不过到最后都没时间测）</p>
<p>于是，</p>
<blockquote>
<p>Neko.d&gt; 这个MPI大多数的时候能跑，少数时候会炸，说不定是MVAPICH的bug</p>
<p>Marcin&gt; we can take a look and report to Dr. DK Panda.</p>
</blockquote>
<p>古有简历直达boss直聘，现有bug report直达author。</p>
</blockquote>
<p>到了第二天中午，debug还是没什么进展。我还是觉得好像也不是非得用MVAPICH才行，一看instruction没要求，应该可以换吧。问了其他队，好家伙，有的队打一开始就是拿OpenMPI跑的。于是准备换Intel MPI，这玩意久经考验。虽然说不定Intel MPI能以一己之力扭转程序的性能特征，改变性能曲线的trend，进而颠覆了原论文的结论，但继续卡在这个问题上也不是个办法。用Intel MPI + 自己编译的GCC 9重新编译ramBLe，第一次运行的时候不加MPI参数，程序直接就爆炸了，甚至连计算都还没开始。我还以为又凉了。抱着死马当活马医的心态，试了一下博文里的参数，程序居然能跑起来了！还成功的跑完了！还第一次看到Intel MPI不加奇奇怪怪的参数还跑不了的情况（一般我觉得加太多参数，叠太多buff会让程序炸得更惨）。</p>
<blockquote>
<p>buff组合，只能说全是魔法，只有一点代码：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-iface ens800f0 -genv UCX_TLS rc,self,sm -genv UCX_NET_DEVICES mlx5_2:1 -genv I_MPI_FABRICS shm:ofi -genv I_MPI_FALLBACK 0</span><br></pre></td></tr></table></figure>
</blockquote>
<p>再次重跑之前不能跑的点，诶，能跑出结果了。然而这个时候，比赛时间不太够了，之前用MVAPICH跑的结果又不能用。为了赶上进度，队友还想着一个节点同时跑两个点，然而我这个学期的project就在研究co-located programs之间相互干扰的问题，所以这个想法被我毙掉了，反正大不了就把原来的MVAPICH的数据加个说明交上去凑数，不过其实最后绝大部分结果都赶上了。此外，还有绑核的问题，MVAPICH绑核默认会绑成一个非常奇怪的姿势，但instruction又没提绑核的事情，干脆让Intel MPI自由发挥，用默认绑核的顺序就完事了。最后与MVAPICH的结果相比较，绑核和换Intel MPI都没有造成太大的影响，trend还是一致的。</p>
<h3 id="qe-神秘应用">QE &amp; 神秘应用</h3>
<p>这两题都是要花钱跑的，作为一个常年抠门，特别是常年在云服务器上抠门的人（<del>但其实我作为AWS的Intern烧掉了AWS不少钱</del>），自然是不太舍得大手大脚的让QE和神秘应用在八CPU节点或者八卡上做测试的。抠门如我，给了他们一个有一张V100的Intel Haswell的节点，在这个便宜的节点上先测试好，再换到正式环境跑。虽然是Intel的CPU，但Haswell只支持到AVX2，它能跑的代码AMD平台应该也能跑。</p>
<p>其实这两个才是赛前我比较担心的应用，因为这两道题目在赛前就看上去还没有另外两题准备的充分的样子，特别是神秘应用的同学人在香港，只能线上沟通，但结果是，这两道题反而没有遇到太多问题（或者说队友靠自己就闷声把问题修好了），出乎我的意料。QE的同学先开始说CPU版的单元测试跑不过，修了一下，好像是缺了什么库之类的，过了没多久，就说CPU的单元测试跑通了。开始叠优化选项，CPU版的单元测试又跑不过了，他自己鼓捣一下，又能跑过了。之后又开始折腾GPU版，这次遇到问题总算棘手了那么一点，这个问题让他修到了第二天。保险起见，就让他在Day 1到Day 2的半夜用四个节点把保底的结果跑出来，然后去思考用什么机器能刷高分数，跑完benchmarks有闲钱了就去刷高分数（然而最后是有闲钱但没时间了）。如果GPU版本能跑了，可以考虑明天和神秘应用一起时分复用GPU节点。为了省钱，还不让他开八节点来跑（不过仔细一想，其实好像花不了几个钱，但应该能提高不少分数）。</p>
<p>神秘应用那边，Day 1，他上来就列好了用来编译安装程序的<strong>所有的</strong>命令（他是怎么把命令列的这么全的？他能预知未来？）我看了两眼，给他补充了一些东西，他就自己去折腾了。我预期他会出现各种各样的状况，然而他安静得就像跑路了一样，之间就问过一次MPI相关的（HPCX又跑不起来，换MPI重新编译就好了），Python软件包缺失，NVCC和MPI的环境变量问题，吓得我以为他跑不出来就开始摆烂了。到了Day 2，他遇到了只有在多卡节点上才能测试的东西，给他开了A100节点后没多久，他下一句话就是，</p>
<blockquote>
<p>Neko.d&gt; 应该可以连进去（八卡节点）了 <span class="citation" data-cites="12:25">@12:25</span></p>
<p>队友&gt; 现在应该是跑完了 <span class="citation" data-cites="14:48">@14:48</span></p>
</blockquote>
<p>这顺利的就离谱。想到跑多节点可能会各种出锅，需要花不少时间<strong>用两个GPU节点</strong>debug，加上我对我多机多GPU的debug经验和速度都不太有自信，不如把钱省下来给benchmark。神秘应用在A100上跑的时候，QE的GPU版似乎还是不太行的样子。</p>
<blockquote>
<p>所有的task在八卡单节点都搞定了。</p>
</blockquote>
<h2 id="sc21-phase-3演你们">SC21 Phase 3：演你们！</h2>
<p>跑benchmarks的老哥人在英国，大概是Day 2中午的时候终于想起来要上号了，此前训练的时候，</p>
<blockquote>
<p>队友&gt; 现在是在训练还是比赛啊？</p>
</blockquote>
<p><del>看起来中国到英国网络不通。</del></p>
<p>跑IO500不烧钱，他就先跑这个玩玩。起初我们还对CycleCloud自带的分布式BeeGFS抱有期望，先跑了一个五节点的分。第一次，8分，不知道是什么水平，只知道是T队去年的10%不到的分数。虽然对这届IO500来说，我们直接进行一个烂的摆才是最优策略，浪费时间提升10分，在某些打榜专用FS面前，跟没有提升没有区别，但交个8分似乎也太丢人了。又跑了一下单节点的，10分。好家伙，上了分布式还负优化了（大概是通信的锅？或者集群配置有问题？）</p>
<p>跑完IO500热热身，他就......去睡觉了。他那边已经是当地时间的早上了，他再次上号的时候已经10个小时过去了，我们这边已经是Day 2的晚上了，看起来他还挺自信的，睡觉睡得很踏实。</p>
<p>QE和神秘应用跑的非常的经济，愣是省了1k多刀给benchmarks烧。我们的原本想到了A100根本开不出来的情况，就准备退而求其次开V100，然后发现了...V100也开不出来。（估计是T队此时也在拿V100跑benchmark）。好不容易开出两台V100，又发现坑爹Azure的Image里，有IB驱动，但只有完全用不了的IB驱动。Image里只带了支持新网卡的驱动，但机器上只有旧网卡，赛前根本就没试过V100节点的我们防不胜防，想不到还有这种事（然而队友aka前运维去年也是用的V100节点，咋啥都不记得了）。总之，如果硬要用V100节点，我们只能准备手动装OFED。（然而T队后来说他们早在测试的时候就发现了这个问题，估计自动化脚本都写好了）</p>
<p>然而，我从来没见过队友用过clusterssh和其他能broadcast input的terminal，对他自称能在短时间内给10+台节点配好OFED的说法深感怀疑。而且我自己装OFED的时候遇到过升级Linux内核的同时把GPU内核模块整没了的情况，说不定好不容易配好了OFED了，CUDA又坏了，所以不是很放心让他继续把时间花在V100上。</p>
<p>折腾V100的期间，ShanghaiTech的运维问我们要不要接盘他们的两台A100，他们准备释放了，但我那个时候还不知道IB驱动的坑，就没接盘。等到发现IB驱动的坑的时候，我只有非常的后悔，不过我又发现我顺手一开就开出两台A100，就是排了大半天的队。感觉V100那边跑不出来了，干脆不如能开出几台A100就跑几台。算了一下钱，发现，</p>
<blockquote>
<p>Neko.d&gt; 出现了有钱花不出去的问题</p>
</blockquote>
<p>我们有足够的钱等A100开出来，哪怕最后开出了8台A100，我们的钱也不一定能花的完。并且我大胆假定，大部分的队伍会在比赛末期因为经费不够把A100让出来（后来发现，还得感谢某些搞事情的队高抬贵手，没有跑去抢A100），于是我就让队友一边在A100集群上调参一边等机子。从第三台机子开始，Azure开始0连排队都不让排了，但只要多试几次就能排上队，平均下来进入排队的状态要花10分钟，排队再花10分钟，也就是说20分钟能开出一个节点。反正大家的进度整体良好，没有我运维什么事，我就去当一个没有感情的点鼠标机器好了。</p>
<blockquote>
<p>本来想写个脚本自动轮询，发现公司给的Mac不让Chrome访问不安全的网站（CycleCloud Web Console的HTTPS的证书没配好），用不了开发者工具来生成模拟请求的curl命令，所以只能人工点鼠标了。</p>
</blockquote>
<p>用了差不多两个小时，总算开出了6台A100节点，但从此再也排不上队了。虽然我觉得没有哪个队钱多到占着A100到最后一秒（然而真的有这种队），但之后真的就一台也开不出来了。</p>
<p>队友那边，他掏出了不知道哪来的<strong>祖传HPL和HPCG二进制文件</strong>，复制粘贴，执行<strong>含有祖传参数的祖传脚本</strong>（怕不是ASC那会用的）就开始跑分了！现在Linux的二进制兼容性这么好了吗？不过6节点HPL一开始只能跑出100T左右的成绩，用htop看CPU占用，红红一大片，非常的不对劲。结果就是MPI进程/线程数设置得不对而已，经典Context Switch了。改了改参数，跑分期间看到了不错的预测结果，但居然跑炸了。队友突发奇想，改低了线程数，好了，太怪了。（某队还碰到了非常神奇的Verification failed，开眼界了）</p>
<p>队友自称在校内集群跑HPL的时候成功的把节点直接跑崩，这里没把Azure的物理机跑崩真是谢天谢地了。</p>
<p>后面的故事就比较简单了，48张A100加持下，钱到位了，金钱的力量绝不让人失望。狗贼T队先扔了一个很低的HPL分卖弱，到比赛快结束的时候，终于把真正的成绩放出来了，HPL，HPCG，IO500全部领先当时榜一一大截，仿佛SC20重演。看了一眼我们刚跑出来的分数，那没事了，就让T队开心那么几十分钟吧，然后再让他们感受资本主义的险恶（大雾）。</p>
<p>抖S的队友总觉得没有榨干A100的性能，从理论性能上看，HPL还是有希望跑上300T的，可惜到了最后几分钟也只跑到了284T。但我脑子一抽，居然同意了让他们在最后几秒用这个成绩override掉原来提交的280T的成绩，差点SC20重演，这是这一次比赛距离翻车最近的一次。还好负责提交的同学足够聪明，是先提交再删除，不是先删除再提交。结果是在ddl前提交成功了，但来不及删掉已经提交的成绩了，要是这个update的顺序反了就emmm。但赛方Grafana还是傻掉了，不能处理多份成绩的样子，显示不出我们的HPL成绩，于是我们创造了SC21最高LINPACK分高达0 GFLOPS的奇迹！（大雾）</p>
<p>另外，IO500原先是跑出了10分的“好”成绩，但忘了保存了。再跑单节点的时候又只有8分了，队友直到最后一刻都还想装Lustre来刷高IO500，但就算分数高了一点，也并没有什么*用。</p>
<h2 id="sc21-phase-3.5interview">SC21 Phase 3.5：Interview</h2>
<p>去年需要我们在最后做一个完整的答辩，今年就变成了Poster+各赛题单独interview。Poster答辩前我还在吹水，<strong>完全没有意识到Poster答辩还占分</strong>，结果iPad（用来在比赛期间挂着线上会议）突然冒出来一句声音让我答辩，我《完全没有任何准备》<del>（自豪）</del>，自然是讲得稀烂，我甚至都不记得我做的Poster里写了啥，只能对着评委说，</p>
<blockquote>
<p>Neko.d&gt; 嗯嗯你们自己看看吧，反正这个也不是最终比赛的配置，看看就好</p>
</blockquote>
<p>结果发现最后Poster分并不高（我紫菜）。</p>
<p>其他队友的分赛题Interview比我靠谱多了，基本上问题都答得上来（你们是什么时候知道这些赛题的物理背景的？）。特别的是，负责Cardioid的的大二队友不太能说英语，但在我们另一个队友，托福100+的大师的协助下，加上interviewer照顾我们把问题打在了聊天框里，这场interview就在</p>
<ul>
<li>我听不懂Cardioid队友跟翻译说了什么</li>
<li>我听不懂翻译跟interviewer说了什么</li>
</ul>
<p>的情况下完成了。我只知道</p>
<ul>
<li>评委很满意我们的回答</li>
<li>他们笑得很开心，但我不知道他们在笑什么</li>
<li>评委问：“假如你患了绝症，你愿意用我的模拟器造的心脏吗？”
<ul>
<li>回答：”去tm的simulation，我直接成为赛博人，肉体是不需要的“</li>
</ul></li>
</ul>
<h2 id="ending">Ending</h2>
<p>其实这1w字的流水账早就在10月的时候写完了，只不过拖到了第二年才发出来，欸嘿。说起来这也是我最后一次以正式队员/队长的身份打SC比赛了，想想好气啊，因为这破疫情，痛失2x美帝 2x新加坡 2x北京 1x厦门免费旅游机会，没能帮学校花钱，我感到非常的愧疚。果然还是想续一续我的学生身份，继续努力的帮学校花钱。希望今年能以Year 0 PhD Student的身份打ASC22（<del>offer不会下不来了吧</del>），然后在未来某一年以Presenter的身份回到SC的会场，并成为目击证人，亲眼见证在nike的successor在SC SCC把其他队锤爆的那一刻。</p>
]]></content>
  </entry>
  <entry>
    <title>Slurm Quick Installation for Cluster on Ubuntu 20.04</title>
    <url>/2022/09/02/Slurm-Quick-Installation-for-Cluster-on-Ubuntu-20-04/</url>
    <content><![CDATA[<p>Slurm will make a bunch of seperated machines look much like a cluster, is it right?</p>
<h2 id="naming-convention-of-nodes">Naming Convention of Nodes</h2>
<p>A common cluster should comprise management nodes and compute nodes. This aritcle will take our cluster as an example to demostrate steps to install and configure Slurm. In our case, the management node is called <code>clab-mgt01</code> while the compute nodes are named from <code>clab01</code> to <code>clab20</code> in order.</p>
<h2 id="install-dependencies">Install Dependencies</h2>
<p>Execute the following command to install the dependencies <strong>on all machines</strong>. (<code>clab-all</code> refers to all machines including management and compute nodes).</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">clab-all$ sudo apt install slurm-wlm slurm-client munge</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Tips: There are several tools that may help to manage multiple nodes easily:</p>
<ul>
<li>iTerm2 (on Mac) / Terminator (on Linux)</li>
<li>csshX (on Mac) / cssh (on Linux)</li>
<li>Parallel SSH (at cluster side)</li>
</ul>
</blockquote>
<h2 id="generate-slurm-configuration">Generate Slurm Configuration</h2>
<p>There is <a href="https://slurm.schedmd.com/configurator.html">an official online configuration generator</a>. And we should carefully check the fields below.</p>
<ul>
<li><strong>SlurmctldHost</strong>: <code>clab-mgt01</code> in our case.</li>
<li><strong>NodeName</strong>: <code>clab[01-20]</code> in our case.</li>
<li><strong>CPUs</strong>: It is recommended to leave it blank.</li>
<li><strong>Sockets</strong>: For a dual-socket server we commonly see, it should be <code>2</code>.</li>
<li><strong>CoresPerSocket</strong>: Number of physical cores per socket.</li>
<li><strong>ThreadsPerCore</strong>: For a regular x86 server, if hyperthreading is enabled, it should be <code>2</code>, otherwise <code>1</code>.</li>
<li><strong>RealMemory</strong>: Optional.</li>
</ul>
<p>Click <code>submit</code>, then we could copy the file content to <code>/etc/slurm-llnl/slurm.conf</code> <strong>on all machines</strong>.</p>
<blockquote>
<p>Tips: Don't forget the shared storage (e.g. NFS storage) on the cluster. We could utilize it to distribute files.</p>
</blockquote>
<h2 id="distribute-munge-key">Distribute Munge Key</h2>
<p>Once Munge is installed successfully, the key <code>/etc/munge/munge.key</code> will be automatically generated. It is requried for all machines to hold the same key. Therefore, we could distribute the key <strong>on the management node</strong> to <strong>the remaining nodes</strong> including compute nodes and other backup management node if existing.</p>
<blockquote>
<p>Tips: Again. We could also utilize the shared storage to distribute the key.</p>
</blockquote>
<p>Then make sure the permission and the ownership are correctly set.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">clab-all$ sudo chmod 400 /etc/munge/munge.key</span><br><span class="line">clab-all$ chown munge:munge /etc/munge/munge.key</span><br></pre></td></tr></table></figure>
<h2 id="patch-slurm-cgroup-integration">Patch Slurm Cgroup Integration</h2>
<p>By default, there Slurm cannot work with Cgroup well. If we start Slurm service right now, we may receive this error shown below.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">error: cgroup namespace <span class="string">&#x27;freezer&#x27;</span> not mounted. aborting</span><br></pre></td></tr></table></figure>
<p>Therefore, by pasting the following content to <code>/etc/slurm/cgroup.conf</code> <strong>on compute nodes</strong>, this issue can be fixed.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CgroupMountpoint=/sys/fs/cgroup</span><br></pre></td></tr></table></figure>
<p>or using this command:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> CgroupMountpoint=/sys/fs/cgroup &gt;&gt; /etc/slurm/cgroup.conf</span><br></pre></td></tr></table></figure>
<h2 id="fix-directory-permission">Fix Directory Permission</h2>
<p>For unknown reasons, the permission of the relevant directory is not set properly, which may lead to this error.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">slurmctld: fatal: mkdir(/var/spool/slurmctld): Permission denied</span><br></pre></td></tr></table></figure>
<p>The solution is executing the commands below <strong>on management nodes</strong>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">clab-mgt$ sudo mkdir -p /var/spool/slurmctld</span><br><span class="line">clab-mgt$ sudo chown slurm:slurm /var/spool/slurmctld/</span><br></pre></td></tr></table></figure>
<h2 id="start-slurm-service">Start Slurm Service</h2>
<p>So far, we have finished the basic configuration. Let us launch Slurm now.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># On management nodes</span></span><br><span class="line">clab-mgt$ sudo systemctl <span class="built_in">enable</span> munge</span><br><span class="line">clab-mgt$ sudo systemctl start munge</span><br><span class="line">clab-mgt$ sudo systemctl <span class="built_in">enable</span> slurmctld</span><br><span class="line">clab-mgt$ sudo systemctl start slurmctld</span><br><span class="line"></span><br><span class="line"><span class="comment"># On compute nodes</span></span><br><span class="line">clab-comp$ sudo systemctl <span class="built_in">enable</span> munge</span><br><span class="line">clab-comp$ sudo systemctl start munge</span><br><span class="line">clab-comp$ sudo systemctl <span class="built_in">enable</span> slurmd</span><br><span class="line">clab-comp$ sudo systemctl start slurmd</span><br></pre></td></tr></table></figure>
<p>Run <code>sinfo</code> and we should see all the compute nodes are ready.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sinfo</span><br><span class="line">PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST</span><br><span class="line">debug*       up   infinite     20   idle clab[01-20]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Tips: If your Slurm is not working correctly, you could try with these commands to debug.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">clab-mgt$ sudo slurmctld -D</span><br><span class="line">clab-comp$ sudo slurmd -D</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="references">References</h2>
<ul>
<li>https://www.cnblogs.com/aobaxu/p/16195237.html</li>
<li>[https://stackoverflow.com/questions/62641323/error-cgroup-namespace-freezer-not-mounted-aborting](</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Tips of configuring InfiniBand adapters</title>
    <url>/2022/08/31/Tips-of-configuring-InfiniBand-Adapters/</url>
    <content><![CDATA[<p>After reconfiguring clusters from scratch for several times, it seems that I am gradually adapting to this mystery and strange InfiniBand world...</p>
<h2 id="relationship-among-infiniband-roce-ipoib-and-ethernet-mode">Relationship among InfiniBand, RoCE, IPoIB, and Ethernet Mode</h2>
<p>Let us take Mellanox ConnectX Adapter as an example. Actually, this adapter can work in either InfiniBand Mode or Ethernet Mode, which is configurable with some tools provided by the vendor. As iWARP is not widely adopted, our article will not discuss this protocol.</p>
<table>
<colgroup>
<col style="width: 45%" />
<col style="width: 30%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>InfiniBand Mode</th>
<th>Ethernet Mode</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Supported by ConnectX</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>RDMA Support</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>Programmable with Verbs</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>TCP/IP Support</td>
<td>Needs IPoIB</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>Configurable with Netplan (e.g. Assign IP Address)</td>
<td>Needs IPoIB</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>Layout of RDMA Packet</td>
<td>IB Frame + IB Header</td>
<td>ETH Frame + RoCE Header</td>
</tr>
<tr class="odd">
<td>Layout of TCP Packet</td>
<td>IB Frame + IB/IPoIB/IP/TCP Headers</td>
<td>ETH Frame + IP/TCP Headers</td>
</tr>
</tbody>
</table>
<p>Note that RoCE Header is a general concept. And RoCEv1 and RoCEv2 give different detailed definitions of this part.</p>
<h2 id="identify-infiniband-ethernet-mode">Identify InfiniBand / Ethernet Mode</h2>
<p>The easiest way is to directly have a look at the interface name and link type with <code>ifconfig</code> or <code>ip</code> under Linux. An InfiniBand adapter working in Ethernet mode looks exactly the same as a regular Ethernet adapter.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ip a</span><br><span class="line"><span class="comment"># InfiniBand Mode</span></span><br><span class="line">4: ibp129s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 2044 qdisc mq state UP group default qlen 256</span><br><span class="line">    link/infiniband ...</span><br><span class="line">    inet 192.168.7.100/24 brd 192.168.7.255 scope global ibp129s0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ethernet Mode</span></span><br><span class="line">7: ens1f1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000</span><br><span class="line">    link/ether ...</span><br><span class="line">    inet 10.200.0.1/24 brd 10.200.0.255 scope global ens1f1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Besides, <code>ibdev2netdev</code> can also help.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ibdev2netdev</span><br><span class="line">mlx4_0 port 1 ==&gt; ibp129s0 (Up)</span><br><span class="line">mlx5_0 port 1 ==&gt; ens1f0 (Up)</span><br></pre></td></tr></table></figure>
<p>Another approach is through <code>ibstat</code>. And the field <code>Link layer</code> shows which mode the adapter is working in.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ibstat</span><br><span class="line"><span class="comment"># InfiniBand Mode</span></span><br><span class="line">CA <span class="string">&#x27;mlx4_0&#x27;</span></span><br><span class="line">	CA <span class="built_in">type</span>: MT4099</span><br><span class="line">	Number of ports: 1</span><br><span class="line">	Firmware version: 2.42.5000</span><br><span class="line">	Hardware version: 1</span><br><span class="line">	Node GUID: </span><br><span class="line">	System image GUID: </span><br><span class="line">	Port 1:</span><br><span class="line">		State: Active</span><br><span class="line">		Physical state: LinkUp</span><br><span class="line">		Rate: 56</span><br><span class="line">		Base lid: 1</span><br><span class="line">		LMC: 0</span><br><span class="line">		SM lid: 1</span><br><span class="line">		Capability mask: 0x0251486a</span><br><span class="line">		Port GUID: </span><br><span class="line">		Link layer: InfiniBand</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ethernet Mode</span></span><br><span class="line">CA <span class="string">&#x27;mlx5_0&#x27;</span></span><br><span class="line">	CA <span class="built_in">type</span>: MT4119</span><br><span class="line">	Number of ports: 1</span><br><span class="line">	Firmware version: 16.25.1020</span><br><span class="line">	Hardware version: 0</span><br><span class="line">	Node GUID: </span><br><span class="line">	System image GUID: </span><br><span class="line">	Port 1:</span><br><span class="line">		State: Active</span><br><span class="line">		Physical state: LinkUp</span><br><span class="line">		Rate: 100</span><br><span class="line">		Base lid: 0</span><br><span class="line">		LMC: 0</span><br><span class="line">		SM lid: 0</span><br><span class="line">		Capability mask: 0x00010000</span><br><span class="line">		Port GUID: </span><br><span class="line">		Link layer: Ethernet</span><br></pre></td></tr></table></figure>
<h2 id="change-infiniband-ethernet-mode">Change InfiniBand / Ethernet Mode</h2>
<p>To alter the work mode, there doesn't exist a general way for now. For Mellanox ConnectX Adapter, the vendor provided a tool called <code>mlxconfig</code>. Here is the usage listed in <a href="https://docs.nvidia.com/networking/display/MFTv4110/Using+mlxconfig">the official document</a>, where you can find more information about it.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo mlxconfig -d /dev/mst/mt4103_pci_cr0 <span class="built_in">set</span> LINK_TYPE_P1=1 LINK_TYPE_P2=1</span><br><span class="line"> </span><br><span class="line">Device <span class="comment">#1:</span></span><br><span class="line">----------</span><br><span class="line">Device <span class="built_in">type</span>:   ConnectX3Pro</span><br><span class="line">PCI device:    /dev/mst/mt4103_pci_cr0</span><br><span class="line">Configurations:        Next Boot        New</span><br><span class="line">  LINK_TYPE_P1         ETH(2)           IB(1)</span><br><span class="line">  LINK_TYPE_P2         ETH(2)           IB(1)</span><br><span class="line"> </span><br><span class="line">Apply new Configuration? ? (y/n) [n] : y</span><br><span class="line">Applying... Done!</span><br><span class="line">-I- Please reboot machine to load new configurations.</span><br></pre></td></tr></table></figure>
<p>Note that P1 and P2 are referring to two separated ports on the adapter. <strong>Attention: Please make sure the network switch is capable of handling InfiniBand or Ethernet Frame before altering the work mode .</strong> If the switch cannot recognize the data frame sent from the server, you might observer <code>Physical state: Polling</code> reported by <code>ibstat</code>, as the packet is not forwarded by the switch correctly. Certain network switches can only forward one type of data frame at a time, which means you may need to manually reconfigure the switch to let it work with the other type of data frame.</p>
<h2 id="configure-ipoib">Configure IPoIB</h2>
<p>By default, the IPoIB will be automatically configured when the IP address is assigned to the interface. The IP address can be managed by <code>netplan</code> or <code>NetworkManager</code>, which depends on your Linux distro. As for the configuration file, there is no difference between the InfiniBand and regular Ethernet Adapters.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Assign a static IP address with netplan for an InfiniBand interface</span></span><br><span class="line"><span class="attr">network:</span></span><br><span class="line">  <span class="attr">ethernets:</span></span><br><span class="line">    <span class="attr">ibp129s0:</span></span><br><span class="line">      <span class="attr">addresses:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">192.168</span><span class="number">.7</span><span class="number">.100</span><span class="string">/24</span></span><br><span class="line">  <span class="attr">version:</span> <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>Once the above configuration is applied and the interface is brought up successfully. We can see <code>ib_ipoib</code> module is loaded.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ lsmod | grep ipoib</span><br><span class="line">ib_ipoib              180224  0</span><br><span class="line">$ ip a</span><br><span class="line">4: ibp129s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 2044 qdisc mq state UP group default qlen 256</span><br><span class="line">    link/infiniband ...</span><br><span class="line">    inet 192.168.7.100/24 brd 192.168.7.255 scope global ibp129s0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>
<p>If the IP address doesn't appear in <code>ip a</code>, we need to check the status of the InfiniBand adapter and make sure its state is active in <code>ibstat</code>. A common mistake is forgetting to enable <code>opensm</code> / <code>opensmd</code>, which will make the adapter stuck at <code>State: Initializing</code>. Note that <code>opensmd</code> will not launch on startup by default.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Start OpenSM</span></span><br><span class="line">$ sudo opensm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start OpenSM As Daemon</span></span><br><span class="line">$ sudo service opensmd start <span class="comment"># Method 1</span></span><br><span class="line">$ sudo systemctl start opensmd <span class="comment"># Method 2</span></span><br><span class="line">$ sudo /etc/init.d/opensmd start <span class="comment"># Method 3</span></span><br></pre></td></tr></table></figure>
<h2 id="identify-roce-version">Identify RoCE Version</h2>
<p>The major difference between RoCEv1 and RoCEv2 is that RoCEv2 is able to utilize IP networking to route while RoCEv1 is routing via MAC addresses. A funny fact is RoCEv1 and RoCEv2 may be enable simultaneously, and we could choose the version at runtime through specifying Group ID (GID). There is a script written by Mellanox named <code>show_gids</code> and it will display RoCE versions associated to GIDs.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ show_gids</span><br><span class="line">DEV	PORT	INDEX	GID					IPv4  		VER	DEV</span><br><span class="line">---	----	-----	---					------------  	---	---</span><br><span class="line">mlx5_0	1	0	fe80:0000:0000:0000:...			v1	ens1f0</span><br><span class="line">mlx5_0	1	1	fe80:0000:0000:0000:...			v2	ens1f0</span><br><span class="line">mlx5_0	1	2	0000:0000:0000:0000:...	11.0.0.201  	v1	ens1f0</span><br><span class="line">mlx5_0	1	3	0000:0000:0000:0000:...	11.0.0.201  	v2	ens1f0</span><br></pre></td></tr></table></figure>
<h2 id="check-adapter-speed">Check Adapter Speed</h2>
<p><code>ethtool</code> can read out this information and it can work with both InfiniBand and Ethernet mode.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ethtool ibp129s0</span><br><span class="line">Settings <span class="keyword">for</span> ibp129s0:</span><br><span class="line">...</span><br><span class="line">	Speed: 56000Mb/s</span><br><span class="line">	Duplex: Full</span><br><span class="line"></span><br><span class="line">$ ethtool ens1f0</span><br><span class="line">Settings <span class="keyword">for</span> ens1f0:</span><br><span class="line">...</span><br><span class="line">	Speed: 100000Mb/s</span><br><span class="line">	Duplex: Full</span><br></pre></td></tr></table></figure>
<h2 id="references">References</h2>
<ul>
<li><a href="https://www.advancedclustering.com/act_kb/infiniband-port-states/">https://www.advancedclustering.com/act_kb/infiniband-port-states/</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/32105832">https://zhuanlan.zhihu.com/p/32105832</a></li>
<li><a href="https://wiki.archlinux.org/title/InfiniBand">https://wiki.archlinux.org/title/InfiniBand</a></li>
<li><a href="https://docs.nvidia.com/networking/display/MLNXOFEDv461000/OpenSM">https://docs.nvidia.com/networking/display/MLNXOFEDv461000/OpenSM</a></li>
<li><a href="https://www.cnblogs.com/juzib/p/13273380.html">https://www.cnblogs.com/juzib/p/13273380.html</a></li>
<li><a href="https://blog.51cto.com/liangchaoxi/4044293">https://blog.51cto.com/liangchaoxi/4044293</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Ubuntu 学习笔记</title>
    <url>/2019/06/13/Ubuntu-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="ubuntu-手动释放获取ip地址">Ubuntu 手动释放获取IP地址</h2>
<p><a href="https://www.linuxquestions.org/questions/linux-newbie-8/commands-to-request-and-release-of-an-ipv6-address-from-a-dhcp-server-4175469096/">参考文章</a></p>
<p>不知道电脑搞什么飞机，电脑开机不会获取IPv6地址，导致无法连入IPv6网络。</p>
<p>释放IPv4地址</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dhclient -4 -r eth0 //或 dhclient -r eth0</span><br></pre></td></tr></table></figure>
<p>获取IPv4地址</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dhclient -4 eth0 //或 dhclient eth0</span><br></pre></td></tr></table></figure>
<p>释放IPv6地址 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dhclient -6 -r eth0</span><br></pre></td></tr></table></figure></p>
<p>获取IPv6地址 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dhclient -6 eth0</span><br></pre></td></tr></table></figure></p>
<p>直接获取IPv6地址即可解决我的问题</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Unattended Ubuntu 20.04 Server Offline Installation</title>
    <url>/2022/01/16/Unattended-Ubuntu-20-04-Server-Offline-Installation/</url>
    <content><![CDATA[<p>Last year, I wrote <a href="/2021/04/27/How-to-make-an-unattended-Ubuntu-Server-Installation-ISO-with-cloud-init/">a post</a> about how to install Ubuntu 18.04 Server automatically. The major reason why I choose to install the older version is I failed to make Ubuntu 20.04 install without pressing any key at that time while the approach for the offline installation recommended by the official is not working.</p>
<p>There is <a href="https://www.pugetsystems.com/labs/hpc/How-To-Make-Ubuntu-Autoinstall-ISO-with-Cloud-init-2213/">an article</a> already described the detailed steps about the automatic installation of Ubuntu 20.04 Server, but according what its author said, their blog system ripped out some important characters. So, by checking with <a href="https://gist.github.com/s3rj1k/55b10cd20f31542046018fcce32f103e">this script</a>, I figured out the correct way to achieve our goal.</p>
<h2 id="download-the-image">Download the image</h2>
<p>Download the live CD image in whichever way you prefer. For the user locates in China, I would suggest you download from <a href="https://mirrors.tuna.tsinghua.edu.cn/ubuntu-releases/focal/ubuntu-20.04.3-live-server-amd64.iso">https://mirrors.tuna.tsinghua.edu.cn/ubuntu-releases/focal/ubuntu-20.04.3-live-server-amd64.iso</a>.</p>
<h2 id="update-some-files-in-iso-image">Update some files in ISO image</h2>
<p>Only thing we need to do is updating several files. And here are some recommended editors.</p>
<ul>
<li>For Windows user, I strongly recommend you use <code>Ultraiso</code> to edit the ISO file.</li>
<li>For Linux user, <code>ISO Master</code> should work. (I didn't try it before.)</li>
<li>For the user who wants to deeply customize the ISO file, including unpacking <code>rootfs</code> image, <code>cubic</code> is everything you need. You can refer to <a href="(/2021/04/27/How-to-make-an-unattended-Ubuntu-Server-Installation-ISO-with-cloud-init/)">my previous post</a> and learn how it works.</li>
</ul>
<h3 id="add-kernel-arguments">Add Kernel Arguments</h3>
<p>Assume the root directory of ISO image is <code>/cdrom</code>. There are two bootloader configuration files need to modify, one for UEFI system, one for the legacy one. Append the kernel arguments like this,</p>
<ul>
<li><code>/cdrom/isolinux/txt.cfg</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">label live</span><br><span class="line">  menu label ^Install Ubuntu Server</span><br><span class="line">  kernel /casper/vmlinuz</span><br><span class="line">  append   initrd=/casper/initrd quiet autoinstall ds=nocloud;s=/cdrom/  ---</span><br></pre></td></tr></table></figure>
<ul>
<li><code>/cdrom/boot/grub/grub.cfg</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">menuentry <span class="string">&quot;Install Ubuntu Server&quot;</span> &#123;</span><br><span class="line">	<span class="built_in">set</span> gfxpayload=keep</span><br><span class="line">	linux	/casper/vmlinuz   quiet autoinstall ds=nocloud\;s=/cdrom/ ---</span><br><span class="line">	initrd	/casper/initrd</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>If you would like to skip the integrity check, you could try to append the kernel argument <code>fsck.mode=skip</code> as the following example shows.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># File: /cdrom/isolinux/txt.cfg</span></span><br><span class="line"></span><br><span class="line">label live</span><br><span class="line">  menu label ^Install Ubuntu Server</span><br><span class="line">  kernel /casper/vmlinuz</span><br><span class="line">  append   initrd=/casper/initrd quiet fsck.mode=skip autoinstall ds=nocloud;s=/cdrom/ ---</span><br><span class="line"></span><br><span class="line"><span class="comment"># File: /cdrom/boot/grub/grub.cfg</span></span><br><span class="line"></span><br><span class="line">menuentry <span class="string">&quot;Install Ubuntu Server&quot;</span> &#123;</span><br><span class="line">	<span class="built_in">set</span> gfxpayload=keep</span><br><span class="line">	linux	/casper/vmlinuz   quiet fsck.mode=skip autoinstall ds=nocloud\;s=/cdrom/ ---</span><br><span class="line">	initrd	/casper/initrd</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: HWE Kernel is a higher version of Linux kernel compared to the default one, which is shipped with the newer drivers. Theoretically, it has a better support for the latest hardware.</p>
</blockquote>
<h3 id="add-auto-install-configurations">Add Auto-install Configurations</h3>
<p>Two new files are also required for automatic answering.</p>
<ul>
<li><code>/cdrom/user-data</code></li>
</ul>
<p>This configuration is what I am using now, and it is for the machine without Internet. I have verified that it can make the installation procedure fully automatic.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#cloud-config</span></span><br><span class="line"><span class="attr">autoinstall:</span></span><br><span class="line">  <span class="attr">version:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">storage:</span>  <span class="comment"># should set the interactive default but doesn&#x27;t seem to work??</span></span><br><span class="line">    <span class="attr">layout:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">direct</span></span><br><span class="line">  <span class="attr">locale:</span> <span class="string">en_US.UTF-8</span></span><br><span class="line">  <span class="attr">keyboard:</span></span><br><span class="line">    <span class="attr">layout:</span> <span class="string">us</span></span><br><span class="line">  <span class="attr">identity:</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">ubuntu-server</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">&quot;$6$exDY1mhS4KUYCE/2$zmn9ToZwTKLhCw.b4/b.ZRTIZM30JZ4QrOQ2aOXJ8yk96xpcCof0kxKwuX1kqLG/ygbJ1f8wxED22bTL4F46P0&quot;</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">tonny</span></span><br><span class="line">  <span class="attr">ssh:</span></span><br><span class="line">    <span class="attr">allow-pw:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">install-server:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">package_update:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">package_upgrade:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note:</p>
<ul>
<li><code>direct</code> storage layout means using and erasing the whole disk. (The default option provided by the interactive installer.)</li>
<li>The password is <code>ubuntu</code>. This can be generated by <code>mkpasswd</code>.</li>
</ul>
</blockquote>
<p>For more usages, check <a href="https://gist.github.com/dbkinghorn/c236aea31d76028b2b6ccdf6d3c6f07e">this example</a>.</p>
<ul>
<li><code>/cdrom/meta-data</code></li>
</ul>
<p>Just create an empty file and put it there.</p>
]]></content>
  </entry>
  <entry>
    <title>Understanding MPI map-by and bind-to option</title>
    <url>/2021/02/05/Understanding-MPI-map-by-and-bind-to-option/</url>
    <content><![CDATA[<p>This tutorial will introduce how to utilize <code>map-by</code> option to deal with many complex scenarios such as running a hybrid MPI program (mixture of OpenMP and MPI).</p>
<h2 id="before-starting">Before starting</h2>
<p>The behavior of MPI varies significantly if the environment changes (including MPI version and implementations, dependent libraries, and job schedulers). All the experiments mentioned in this article are conducted on <strong>OpenMPI 4.0.2</strong>, which means if you use different implementations or versions of MPI, you may encounter unexpected problems. For example, OpenMPI 2.1.1, the default version bundled in Ubuntu 18.04, will behave strangely and fail to control the number of OpenMP threads when running a hybrid program. Thus I strongly recommended to download the latest version of MPI.</p>
<h2 id="test-environment">Test Environment</h2>
<p>On the test platform, each machine contains <strong>2 NUMA nodes, 36 physical cores, 72 hardware threads</strong> overall. The test hybrid program could be downloaded from <a href="https://rcc.uchicago.edu/docs/running-jobs/hybrid/index.html">https://rcc.uchicago.edu/docs/running-jobs/hybrid/index.html</a>, and <strong>OpenMPI 4.0.2 and GCC 7.3.0</strong> are downloaded from Anaconda.</p>
<h2 id="map-by-unit">map-by unit</h2>
<p>This is the most fundamental syntax. And <code>unit</code> can be filled in <code>hwthread</code>, <code>core</code>, <code>L1cache</code>, <code>L2cache</code>, <code>L3cache</code>, <code>socket</code>, <code>numa</code>, <code>board</code>, <code>node</code>. Note that <code>hwthread</code> means hardware thread, while <code>core</code> means physical core. <code>numa</code> option is commonly used.</p>
<p>The following example illustrates the differences of each option. To make output clear, <code>PE=1</code> was added to limit thread numbers, and we will introduce it in the section <a href="#map-by%20unit:pe=n">map-by unit:pe=n</a>. <code>--report-bindings</code> is a proprietary option of OpenMPI to visualize bindings, and you can check <a href="#Appendix">Appendix</a> to figure out the similar usage of other MPI implementations.</p>
<h3 id="map-by-numa">map-by numa</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -n 4 --map-by numa:PE=1 --report-bindings ./a.out</span><br><span class="line">[asialab-01:69587] MCW rank 0 bound to socket 0[core 0[hwt 0-1]]: [BB/../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:69587] MCW rank 1 bound to socket 1[core 18[hwt 0-1]]: [../../../../../../../../../../../../../../../../../..][BB/../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:69587] MCW rank 2 bound to socket 0[core 1[hwt 0-1]]: [../BB/../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:69587] MCW rank 3 bound to socket 1[core 19[hwt 0-1]]: [../../../../../../../../../../../../../../../../../..][../BB/../../../../../../../../../../../../../../../..]</span><br><span class="line">Hello from thread 0 out of 2 from process 0 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 0 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 1 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 1 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 2 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 2 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 3 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 3 out of 4 on asialab-01</span><br></pre></td></tr></table></figure>
<h3 id="map-by-hwthread">map-by hwthread</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -n 4 --map-by hwthread:PE=1 --report-bindings ./a.out</span><br><span class="line">[asialab-01:69621] MCW rank 0 bound to socket 0[core 0[hwt 0]]: [B./../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:69621] MCW rank 1 bound to socket 0[core 0[hwt 1]]: [.B/../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:69621] MCW rank 2 bound to socket 0[core 1[hwt 0]]: [../B./../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:69621] MCW rank 3 bound to socket 0[core 1[hwt 1]]: [../.B/../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">Hello from thread 0 out of 1 from process 3 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 1 from process 2 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 1 from process 0 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 1 from process 1 out of 4 on asialab-01</span><br></pre></td></tr></table></figure>
<h3 id="map-by-core">map-by core</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -n 4 --map-by core:PE=1 --report-bindings ./a.out</span><br><span class="line">[asialab-01:69653] MCW rank 0 bound to socket 0[core 0[hwt 0-1]]: [BB/../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:69653] MCW rank 1 bound to socket 0[core 1[hwt 0-1]]: [../BB/../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:69653] MCW rank 2 bound to socket 0[core 2[hwt 0-1]]: [../../BB/../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:69653] MCW rank 3 bound to socket 0[core 3[hwt 0-1]]: [../../../BB/../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">Hello from thread 0 out of 2 from process 0 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 0 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 1 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 1 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 2 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 2 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 3 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 3 out of 4 on asialab-01</span><br></pre></td></tr></table></figure>
<p>Observe that when we set to <code>map-by numa</code>, MPI will take NUMA architecture into consideration and balance the workload of two NUMA nodes. Otherwise, MPI will ignore NUMA.</p>
<p>You may notice that when <code>map-by</code> is set to <code>hwthread</code>, only one thread is allocated to OpenMP in each rank. The section <a href="#bind-to%20unit">bind-to unit</a> explains this to some degree.</p>
<h2 id="bind-to-unit">bind-to unit</h2>
<p>The default option is core if we didn't specify this option. Although this option is not so important, but there are several interesting concepts to learn. You may have heard the word <strong>slot</strong>, and you can imagine each slot will hold one rank at most. My understanding is that it is <strong>slot</strong> will be <strong>bound to</strong> specified units such as hardware threads or physical cores. Let us go through some examples.</p>
<h3 id="bind-to-hwthread">bind-to hwthread</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -n 4 --bind-to hwthread --map-by numa --report-bindings ./a.out</span><br><span class="line">[asialab-01:71905] MCW rank 0 bound to socket 0[core 0[hwt 0]]: [B./../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:71905] MCW rank 1 bound to socket 1[core 18[hwt 0]]: [../../../../../../../../../../../../../../../../../..][B./../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:71905] MCW rank 2 bound to socket 0[core 0[hwt 1]]: [.B/../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:71905] MCW rank 3 bound to socket 1[core 18[hwt 1]]: [../../../../../../../../../../../../../../../../../..][.B/../../../../../../../../../../../../../../../../..]</span><br><span class="line">Hello from thread 0 out of 1 from process 1 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 1 from process 2 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 1 from process 3 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 1 from process 0 out of 4 on asialab-01</span><br></pre></td></tr></table></figure>
<h3 id="bind-to-core">bind-to core</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -n 4 --bind-to core --map-by numa --report-bindings ./a.out</span><br><span class="line">[asialab-01:71922] MCW rank 0 bound to socket 0[core 0[hwt 0-1]]: [BB/../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:71922] MCW rank 1 bound to socket 1[core 18[hwt 0-1]]: [../../../../../../../../../../../../../../../../../..][BB/../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:71922] MCW rank 2 bound to socket 0[core 1[hwt 0-1]]: [../BB/../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:71922] MCW rank 3 bound to socket 1[core 19[hwt 0-1]]: [../../../../../../../../../../../../../../../../../..][../BB/../../../../../../../../../../../../../../../..]</span><br><span class="line">Hello from thread 0 out of 2 from process 0 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 0 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 1 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 1 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 2 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 2 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 3 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 3 out of 4 on asialab-01</span><br></pre></td></tr></table></figure>
<h3 id="bind-to-numa">bind-to numa</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -n 2 --bind-to numa --map-by numa --report-bindings ./a.out</span><br><span class="line">[asialab-01:72100] MCW rank 0 bound to socket 0[core 0[hwt 0-1]], socket 0[core 1[hwt 0-1]], socket 0[core 2[hwt 0-1]], socket 0[core 3[hwt 0-1]], socket 0[core 4[hwt 0-1]], socket 0[core 5[hwt 0-1]], socket 0[core 6[hwt 0-1]], socket 0[core 7[hwt 0-1]], socket 0[core 8[hwt 0-1]], socket 0[core 9[hwt 0-1]], socket 0[core 10[hwt 0-1]], socket 0[core 11[hwt 0-1]], socket 0[core 12[hwt 0-1]], socket 0[core 13[hwt 0-1]], socket 0[core 14[hwt 0-1]], socket 0[core 15[hwt 0-1]], socket 0[core 16[hwt 0-1]], socket 0[core 17[hwt 0-1]]: [BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:72100] MCW rank 1 bound to socket 1[core 18[hwt 0-1]], socket 1[core 19[hwt 0-1]], socket 1[core 20[hwt 0-1]], socket 1[core 21[hwt 0-1]], socket 1[core 22[hwt 0-1]], socket 1[core 23[hwt 0-1]], socket 1[core 24[hwt 0-1]], socket 1[core 25[hwt 0-1]], socket 1[core 26[hwt 0-1]], socket 1[core 27[hwt 0-1]], socket 1[core 28[hwt 0-1]], socket 1[core 29[hwt 0-1]], socket 1[core 30[hwt 0-1]], socket 1[core 31[hwt 0-1]], socket 1[core 32[hwt 0-1]], socket 1[core 33[hwt 0-1]], socket 1[core 34[hwt 0-1]], socket 1[core 35[hwt 0-1]]: [../../../../../../../../../../../../../../../../../..][BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/BB]</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>If each slot is bound to a hardware thread, only one thread could be allocated to OpenMP in each rank. If each slot is bound to a physical core, all the threads in a physical core could be allocated. If each slot is bound to a NUMA node, all the threads in a NUMA node could be allocated.</p>
<h2 id="map-by-unitpen">map-by unit:pe=n</h2>
<p>In the previous section we introduce the concept <strong>slot</strong>. By default, each slot is bound to one physical core. This section we will dig deep into <code>pe</code>, and it may refer to <code>processing element</code> according to a website. This concept is ambiguous, and my understanding is that <code>pe=n</code> determines the number of units that each slot will occupy. Here are some examples.</p>
<h3 id="bind-to-core-pe1">bind-to core, PE=1</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -n 2 --bind-to core --map-by numa:PE=1 --report-bindings ./a.out</span><br><span class="line">[asialab-01:72668] MCW rank 0 bound to socket 0[core 0[hwt 0-1]]: [BB/../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:72668] MCW rank 1 bound to socket 1[core 18[hwt 0-1]]: [../../../../../../../../../../../../../../../../../..][BB/../../../../../../../../../../../../../../../../..]</span><br><span class="line">Hello from thread 0 out of 2 from process 0 out of 2 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 0 out of 2 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 1 out of 2 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 1 out of 2 on asialab-01</span><br></pre></td></tr></table></figure>
<h3 id="bind-to-core-pe2">bind-to core, PE=2</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -n 2 --bind-to core --map-by numa:PE=2 --report-bindings ./a.out</span><br><span class="line">[asialab-01:72700] MCW rank 0 bound to socket 0[core 0[hwt 0-1]], socket 0[core 1[hwt 0-1]]: [BB/BB/../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:72700] MCW rank 1 bound to socket 1[core 18[hwt 0-1]], socket 1[core 19[hwt 0-1]]: [../../../../../../../../../../../../../../../../../..][BB/BB/../../../../../../../../../../../../../../../..]</span><br><span class="line">Hello from thread 0 out of 4 from process 0 out of 2 on asialab-01</span><br><span class="line">Hello from thread 2 out of 4 from process 0 out of 2 on asialab-01</span><br><span class="line">Hello from thread 3 out of 4 from process 0 out of 2 on asialab-01</span><br><span class="line">Hello from thread 1 out of 4 from process 0 out of 2 on asialab-01</span><br><span class="line">Hello from thread 2 out of 4 from process 1 out of 2 on asialab-01</span><br><span class="line">Hello from thread 0 out of 4 from process 1 out of 2 on asialab-01</span><br><span class="line">Hello from thread 1 out of 4 from process 1 out of 2 on asialab-01</span><br><span class="line">Hello from thread 3 out of 4 from process 1 out of 2 on asialab-01</span><br></pre></td></tr></table></figure>
<h3 id="bind-to-hwthread-pe1">bind-to hwthread, PE=1</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -n 2 --bind-to hwthread --map-by numa:PE=1 --report-bindings ./a.out</span><br><span class="line">[asialab-01:72729] MCW rank 0 bound to socket 0[core 0[hwt 0]]: [B./../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:72729] MCW rank 1 bound to socket 1[core 18[hwt 0]]: [../../../../../../../../../../../../../../../../../..][B./../../../../../../../../../../../../../../../../..]</span><br><span class="line">Hello from thread 0 out of 1 from process 1 out of 2 on asialab-01</span><br><span class="line">Hello from thread 0 out of 1 from process 0 out of 2 on asialab-01</span><br></pre></td></tr></table></figure>
<h3 id="bind-to-hwthread-pe2">bind-to hwthread, PE=2</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -n 2 --bind-to hwthread --map-by numa:PE=2 --report-bindings ./a.out</span><br><span class="line">[asialab-01:72740] MCW rank 0 bound to socket 0[core 0[hwt 0-1]]: [BB/../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:72740] MCW rank 1 bound to socket 1[core 18[hwt 0-1]]: [../../../../../../../../../../../../../../../../../..][BB/../../../../../../../../../../../../../../../../..]</span><br><span class="line">Hello from thread 0 out of 2 from process 0 out of 2 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 0 out of 2 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 1 out of 2 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 1 out of 2 on asialab-01</span><br></pre></td></tr></table></figure>
<p>However, I failed to launch with the setting <code>-n 1 --bind-to numa --map-by node:PE=2</code>, and I expect that only one rank consumes all the resources (equivalent to <code>bind-to core, PE=36</code>, or <code>bind-to hwthread, PE=72</code>). Anyway, <code>pe=n</code> will work well when combining with <code>bind-to core</code> or <code>bind-to hwthread</code>.</p>
<h2 id="map-by-pprnunit">map-by ppr:n:unit</h2>
<p><code>ppr</code> is short for <code>processes per resource</code>. The <code>processes</code> here basically are equivalent to MPI Rank. This option actually limits the maximum number of ranks (number of slots) that each unit can hold. Let us verify this.</p>
<h3 id="bind-to-core-ppr4">bind-to core, ppr:4</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> mpirun -n 4 --bind-to core --map-by ppr:4:numa --report-bindings ./a.out</span><br><span class="line">[asialab-01:00520] MCW rank 0 bound to socket 0[core 0[hwt 0-1]]: [BB/../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:00520] MCW rank 1 bound to socket 0[core 1[hwt 0-1]]: [../BB/../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:00520] MCW rank 2 bound to socket 0[core 2[hwt 0-1]]: [../../BB/../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:00520] MCW rank 3 bound to socket 0[core 3[hwt 0-1]]: [../../../BB/../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">Hello from thread 0 out of 2 from process 0 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 0 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 1 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 1 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 2 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 2 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 3 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 3 out of 4 on asialab-01</span><br></pre></td></tr></table></figure>
<h3 id="bind-to-core-ppr2">bind-to core, ppr:2</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -n 4 --bind-to core --map-by ppr:2:numa --report-bindings ./a.out</span><br><span class="line">[asialab-01:00541] MCW rank 0 bound to socket 0[core 0[hwt 0-1]]: [BB/../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:00541] MCW rank 1 bound to socket 0[core 1[hwt 0-1]]: [../BB/../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:00541] MCW rank 2 bound to socket 1[core 18[hwt 0-1]]: [../../../../../../../../../../../../../../../../../..][BB/../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:00541] MCW rank 3 bound to socket 1[core 19[hwt 0-1]]: [../../../../../../../../../../../../../../../../../..][../BB/../../../../../../../../../../../../../../../..]</span><br><span class="line">Hello from thread 0 out of 2 from process 1 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 1 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 2 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 2 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 3 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 3 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 2 from process 0 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 2 from process 0 out of 4 on asialab-01</span><br></pre></td></tr></table></figure>
<h3 id="bind-to-core-ppr1">bind-to core, ppr:1</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> mpirun -n 4 --bind-to core --map-by ppr:1:numa --report-bindings ./a.out</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">Your job has requested more processes than the ppr <span class="keyword">for</span></span><br><span class="line">this topology can support:</span><br><span class="line"></span><br><span class="line">  App: ./a.out</span><br><span class="line">  Number of procs:  4</span><br><span class="line">  PPR: 1:numa</span><br><span class="line"></span><br><span class="line">Please revise the conflict and try again.</span><br><span class="line">--------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<p>Since each NUMA node is limited to hold one MPI process at most, and there are two NUMA nodes overall, it is reasonable to fail to run the program with four ranks.</p>
<h2 id="map-by-pprnunitpen">map-by ppr:n:unit:pe=n</h2>
<p>This is complete form of <code>map-by</code>. There is nothing new, so you should be able to explain the following complex example. Hint: <code>-host hostname:-1</code> will let MPI detect the number of available slots on the remote machine automatically.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpirun -n 4 -host asialab-01:-1,asialab-03:-1 --bind-to hwthread --map-by ppr:1:numa:pe=4 --report-bindings ./a.out</span><br><span class="line">[asialab-01:00614] MCW rank 0 bound to socket 0[core 0[hwt 0-1]], socket 0[core 1[hwt 0-1]]: [BB/BB/../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-01:00614] MCW rank 1 bound to socket 1[core 18[hwt 0-1]], socket 1[core 19[hwt 0-1]]: [../../../../../../../../../../../../../../../../../..][BB/BB/../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-03:73603] MCW rank 2 bound to socket 0[core 0[hwt 0-1]], socket 0[core 1[hwt 0-1]]: [BB/BB/../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../..]</span><br><span class="line">[asialab-03:73603] MCW rank 3 bound to socket 1[core 18[hwt 0-1]], socket 1[core 19[hwt 0-1]]: [../../../../../../../../../../../../../../../../../..][BB/BB/../../../../../../../../../../../../../../../..]</span><br><span class="line">Hello from thread 0 out of 4 from process 2 out of 4 on asialab-03</span><br><span class="line">Hello from thread 2 out of 4 from process 2 out of 4 on asialab-03</span><br><span class="line">Hello from thread 3 out of 4 from process 2 out of 4 on asialab-03</span><br><span class="line">Hello from thread 0 out of 4 from process 3 out of 4 on asialab-03</span><br><span class="line">Hello from thread 2 out of 4 from process 3 out of 4 on asialab-03</span><br><span class="line">Hello from thread 1 out of 4 from process 3 out of 4 on asialab-03</span><br><span class="line">Hello from thread 3 out of 4 from process 3 out of 4 on asialab-03</span><br><span class="line">Hello from thread 1 out of 4 from process 2 out of 4 on asialab-03</span><br><span class="line">Hello from thread 0 out of 4 from process 0 out of 4 on asialab-01</span><br><span class="line">Hello from thread 3 out of 4 from process 0 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 4 from process 0 out of 4 on asialab-01</span><br><span class="line">Hello from thread 2 out of 4 from process 0 out of 4 on asialab-01</span><br><span class="line">Hello from thread 1 out of 4 from process 1 out of 4 on asialab-01</span><br><span class="line">Hello from thread 0 out of 4 from process 1 out of 4 on asialab-01</span><br><span class="line">Hello from thread 2 out of 4 from process 1 out of 4 on asialab-01</span><br><span class="line">Hello from thread 3 out of 4 from process 1 out of 4 on asialab-01</span><br></pre></td></tr></table></figure>
<h2 id="appendix">Appendix</h2>
<h3 id="report-bindings">Report bindings</h3>
<ul>
<li>Intel MPI: <code>-print-rank-map</code></li>
<li>MVAPICH2: <code>MV2_SHOW_CPU_BINDING=1</code></li>
<li>OpenMPI: <code>--report-bindings</code></li>
</ul>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://www.ibm.com/support/knowledgecenter/SSZTET_10.2/admin/smpi02_proc_affinity_mapping.html">https://www.ibm.com/support/knowledgecenter/SSZTET_10.2/admin/smpi02_proc_affinity_mapping.html</a></li>
<li><a href="https://stackoverflow.com/questions/28216897/syntax-of-the-map-by-option-in-openmpi-mpirun-v1-8">https://stackoverflow.com/questions/28216897/syntax-of-the-map-by-option-in-openmpi-mpirun-v1-8</a></li>
<li><a href="https://rcc.uchicago.edu/docs/running-jobs/hybrid/index.html">https://rcc.uchicago.edu/docs/running-jobs/hybrid/index.html</a></li>
<li><a href="https://www.intel.com/content/dam/www/public/us/en/documents/presentation/things-mpi-library.pdf">https://www.intel.com/content/dam/www/public/us/en/documents/presentation/things-mpi-library.pdf</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Use tmux to debug distributed Python programs</title>
    <url>/2021/03/06/Use-tmux-to-debug-distributed-Python-programs/</url>
    <content><![CDATA[<p>It is always hard to debug distributed programs. Not only the concurrency is extremely naughty, but we don't have enough tools, or don't know there are several tools to debug the distributed programs. But I found that tmux is capable of handling multiple windows, which means it's possible to control numerous nodes without GUI.</p>
<h2 id="usage-of-tmux">Usage of tmux</h2>
<p>Here is my tmux cheating sheet. For more details, check the website <a href="https://gist.github.com/henrik/1967800">https://gist.github.com/henrik/1967800</a>.</p>
<h3 id="create-session-and-window">Create Session and Window</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Shell Commands</span></span><br><span class="line">tmux new -s s1 <span class="comment"># Create a session named s1</span></span><br><span class="line">tmux neww -t s1: htop <span class="comment"># Create a window in session s1 and launch htop</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tmux Control</span></span><br><span class="line">Ctrl-b 0 <span class="comment"># Switch to window 0</span></span><br><span class="line">Ctrl-b 1 <span class="comment"># Switch to window 1</span></span><br><span class="line">...</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="window-pane-conversion">Window / Pane Conversion</h3>
<p>Note: You are allowed to use autocomplete by clicking <code>tab</code> or check the history by clicking arrow keys after press <code>Ctrl-b</code> and <code>:</code>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Ctrl-b :join-pane -s :2 <span class="comment"># Move window 2 into a new split pane</span></span><br><span class="line">Ctrl-b :break-pane <span class="comment"># Move all inactive panes into windows</span></span><br></pre></td></tr></table></figure>
<p>Sometimes <code>-t</code> represents <code>target</code> while <code>-s</code> represents <code>source</code>.</p>
<h2 id="example">Example</h2>
<h3 id="rpc-via-ssh">RPC via SSH</h3>
<p>This is a launcher which will spawn several processes on remote machines. (Source: DGL Library)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">execute_remote</span>(<span class="params">cmd, ip, port, thread_list</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;execute command line on remote machine via ssh&quot;&quot;&quot;</span></span><br><span class="line">    cmd = <span class="string">&#x27;ssh -o StrictHostKeyChecking=no -p &#x27;</span> + <span class="built_in">str</span>(port) + <span class="string">&#x27; &#x27;</span> + ip + <span class="string">&#x27; \&#x27;&#x27;</span> + cmd + <span class="string">&#x27;\&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># thread func to run the job</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">cmd</span>):</span></span><br><span class="line">        subprocess.check_call(cmd, shell = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    thread = Thread(target = run, args=(cmd,))</span><br><span class="line">    thread.setDaemon(<span class="literal">True</span>)</span><br><span class="line">    thread.start()</span><br><span class="line">    thread_list.append(thread)</span><br></pre></td></tr></table></figure>
<p>To debug the program, we need to create a session on the login node first.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">login$ tmux new -s dgl</span><br></pre></td></tr></table></figure>
<p>Then modify the source code of the launcher to let newly spawned processes attach to tmux.</p>
<ul>
<li>Put <code>tmux neww</code> at the beginning of the command</li>
<li>Put <code>;bash -i</code> at the end to prevent window from closing after program exited</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">execute_remote</span>(<span class="params">cmd, ip, port, thread_list</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;execute command line on remote machine via ssh&quot;&quot;&quot;</span></span><br><span class="line">    cmd = <span class="string">&#x27;tmux neww -t dgl: ssh -o StrictHostKeyChecking=no -p &#x27;</span> + <span class="built_in">str</span>(port) + <span class="string">&#x27; &#x27;</span> + ip + <span class="string">&#x27; \&#x27;&#x27;</span> + cmd + <span class="string">&#x27;\&#x27;&#x27;</span> + <span class="string">&#x27;;bash -i&#x27;</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>Finally execute the modified launcher on login node directly. After that we could notice several windows are created and shown at the bottom of tmux.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">login$ python launch.py ...</span><br></pre></td></tr></table></figure>
<h3 id="rpc-via-mpi">RPC via MPI</h3>
<p>Just like what the previous section does, add something at the beginning or the end of the command.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tmux new -s mpi</span><br><span class="line">mpirun -n 4 tmux neww -t mpi: <span class="string">&quot;python ...; bash -i&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="with-debugger">with Debugger</h2>
<p>It is easier to debug distributed programs when each remote process shown in a separated window is attached by a separated debugger.</p>
<h3 id="pdb">PDB</h3>
<p>PDB is a built-in utility, and it is easy to use, especially it allows the program to trap in interactive debugging mode by inserting one instruction explictly. For example, try to execute the following code.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdb</span><br><span class="line">pdb.set_trace()</span><br></pre></td></tr></table></figure>
<p>Then your Python program will pause and a interactive dialogue like <code>gdb</code> appeared.</p>
<h3 id="pudb">PUDB</h3>
<p>This is basically PDB equipped with TUI (Text-based user interface), and its usage is quite similar to PDB's. But you have to download it before using it.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda install pudb <span class="comment"># Install by conda</span></span><br><span class="line">pip install pudb <span class="comment"># Install by pip</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pudb</span><br><span class="line">pdb.set_trace()</span><br></pre></td></tr></table></figure>
<p>However, the TUI heavily relies on some features of pseudo-tty. Without it, the TUI cannot work correctly. But, by default SSH will not allocate pseudo-tty when using SSH to launch a remote program instead of a console. Thus, we need to do some modifications to the launcher.</p>
<ul>
<li>specify a SSH argument <code>-t</code> to force pseudo-tty allocation.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">execute_remote</span>(<span class="params">cmd, ip, port, thread_list</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;execute command line on remote machine via ssh&quot;&quot;&quot;</span></span><br><span class="line">    cmd = <span class="string">&#x27;tmux neww -t dgl: ssh -t -o StrictHostKeyChecking=no -p &#x27;</span> + <span class="built_in">str</span>(port) + <span class="string">&#x27; &#x27;</span> + ip + <span class="string">&#x27; \&#x27;&#x27;</span> + cmd + <span class="string">&#x27;\&#x27;&#x27;</span> + <span class="string">&#x27;;bash -i&#x27;</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<figure>
<img data-src="/images/pasted-67.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://unix.stackexchange.com/questions/14300/moving-tmux-pane-to-window">https://unix.stackexchange.com/questions/14300/moving-tmux-pane-to-window</a></li>
<li><a href="https://unix.stackexchange.com/questions/17116/prevent-pane-window-from-closing-when-command-completes-tmux">https://unix.stackexchange.com/questions/17116/prevent-pane-window-from-closing-when-command-completes-tmux</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>VSCode Fortran MPI开发调试环境配置</title>
    <url>/2020/06/20/VSCode-Fortran-MPI%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>当前并没有充分支持Fortran+MPI的现代IDE，但借助vscode的灵活性<del>（a.k.a. 简陋）</del>还是可以获得比较好的Fortran开发体验的。</p>
<h2 id="安装插件">安装插件</h2>
<figure>
<img data-src="/images/pasted-46.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>这里推荐使用<code>FORTRAN IntelliSense</code>和<code>Modern Fortran</code>两个插件，前者主要能够提供查看定义的功能，后者主要提供调试和代码补全的功能。<code>FORTRAN IntelliSense</code>还需要一个外部的<code>Fortran Language Server</code>，用pip就可以很轻松的安装上。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install fortran-language-server</span><br></pre></td></tr></table></figure>
<h2 id="配置插件">配置插件</h2>
<figure>
<img data-src="/images/pasted-49.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>打开<code>File</code>-&gt;<code>Preferences</code>-&gt;<code>Settings</code>，搜索<code>Fortran</code>，需要配置的地方通常有<code>Fortran: Gfortran Executable</code>，这里可以输入编译器的路径或者名字。比如我使用的是PGI编译器，就填入<code>pgfortran</code>即可。也可以在这个设置里修改<code>Include Paths</code>。</p>
<h2 id="配置编译tasks">配置编译Tasks</h2>
<figure>
<img data-src="/images/pasted-52.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>按下<code>Ctrl</code>+<code>Shift</code>+<code>P</code>，输入<code>tasks</code>，选择<code>Tasks: Configure Default Build Task</code>，然后看到类似如下的<code>json</code>配置。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;label&quot;</span>: <span class="string">&quot;build&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;shell&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;command&quot;</span>: <span class="string">&quot;make -j20&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;problemMatcher&quot;</span>: [],</span><br><span class="line">    <span class="attr">&quot;group&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;kind&quot;</span>: <span class="string">&quot;build&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;isDefault&quot;</span>: <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<p><code>label</code>取一个<code>build</code>就可以了，这个名字后面要用到。<code>command</code>配置为编译这个项目的命令就可以了，我的<code>makefile</code>放在项目的根目录里，所以直接运行<code>make -j20</code>就可以编译了。</p>
<h2 id="配置gdb调试">配置GDB调试</h2>
<figure>
<img data-src="/images/pasted-53.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>点击最左边带一只bug的图标，然后点击<code>create a launch.json file</code>，接着选<code>C++ (GDB/LLDB)</code>，这里Fortran可以和C++共用GDB的配置，完事之后可以看到类似如下的配置。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;(gdb) 启动&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;cppdbg&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;request&quot;</span>: <span class="string">&quot;launch&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;program&quot;</span>: <span class="string">&quot;$&#123;workspaceFolder&#125;/main&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;args&quot;</span>: [],</span><br><span class="line">    <span class="attr">&quot;stopAtEntry&quot;</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">&quot;cwd&quot;</span>: <span class="string">&quot;$&#123;workspaceFolder&#125;&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;environment&quot;</span>: [],</span><br><span class="line">    <span class="attr">&quot;externalConsole&quot;</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">&quot;MIMode&quot;</span>: <span class="string">&quot;gdb&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;miDebuggerPath&quot;</span>: <span class="string">&quot;$&#123;workspaceFolder&#125;/scripts/gdbwarp&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;preLaunchTask&quot;</span>: <span class="string">&quot;build&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;setupCommands&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;description&quot;</span>: <span class="string">&quot;为 gdb 启用整齐打印&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;text&quot;</span>: <span class="string">&quot;-enable-pretty-printing&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;ignoreFailures&quot;</span>: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>要修改的地方首先有<code>program</code>。<code>$&#123;workspaceFolder&#125;</code>指项目根目录的路径，<code>main</code>是我编译出来的可执行文件的名字。也就是说我的可执行文件就会出现在根目录里。这里不同的项目可能会有不同的配置。</p>
<p>另外一个要改的地方是<code>miDebuggerPath</code>，这里本来应该填的是gdb的路径，或者gdb这个词。但调试MPI的程序肯定不能直接<code>gdb ./main</code>。通常启动<code>gdb</code>的命令是<code>mpirun -np 1 gdb ./main : -np 15 ./main</code>，所以我写了一个叫<code>gdbwarp</code>的脚本，放在项目的<code>scripts</code>文件夹里。脚本的内容如下。</p>
<p>最后要改的地方是<code>preLaunchTask</code>，这个会让在运行调试前启动<code>label</code>为<code>build</code>的task，这就是实现了运行调试前自动编译的效果。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">ROOT=$(dirname $(readlink -f <span class="string">&quot;<span class="variable">$0</span>&quot;</span>))/..</span><br><span class="line">mpirun -np 1 gdb <span class="variable">$@</span> : -np 15 <span class="variable">$ROOT</span>/main</span><br></pre></td></tr></table></figure>
<p><code>$(dirname $(readlink -f "$0"))</code>这个变量是获取脚本文件所在的绝对路径，因为<code>gdbwarp</code>在<code>根目录/script</code>文件夹里，所以<code>$ROOT</code>变量是指项目的根目录。<code>$ROOT/main</code>就是我的可执行文件。而<code>$@</code>变量会接收来自vscode的参数。</p>
<h2 id="启动调试">启动调试</h2>
<p>按下<code>F5</code>即可启动调试，记得添加断点。最终效果如下。</p>
<figure>
<img data-src="/images/pasted-54.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
]]></content>
  </entry>
  <entry>
    <title>WSL共享Windows的SSH配置</title>
    <url>/2021/01/21/WSL%E5%85%B1%E4%BA%ABWindows%E7%9A%84SSH%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>众所周知WSL和Windows各自维护一套SSH配置，也就是说Windows下配置的SSH别名不能在WSL下使用，同时Windows下也没有<code>ssh-copy-id</code>这个好东西。由于我经常在Windows下使用VSCode远程开发，所以之前我<del>非常愚蠢的</del>每次都切换到WSL下启动<code>ssh-copy-id -i</code>配置免密登录，因此想让WSL共享Windows的SSH别名和公钥。</p>
<h2 id="windows下生成ssh密钥">Windows下生成SSH密钥</h2>
<p>老掉牙的问题了，在Powershell下执行<code>ssh-keygen.exe</code>，然后狂按回车（如果不想每次SSH公钥登录都输一次密码的话）。公钥就会生成在Windows用户目录下的<code>.ssh</code>文件夹里。</p>
<h2 id="wsl下软连接.ssh文件夹">WSL下软连接<code>.ssh</code>文件夹</h2>
<p>这一步也很正常。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># WSL Environment</span></span><br><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line">ln -s /mnt/c/Users/&lt;Your Name&gt;/.ssh .</span><br></pre></td></tr></table></figure>
<h2 id="配置.ssh文件夹权限">配置<code>~/.ssh</code>文件夹权限</h2>
<p>这一步有点坑，默认情况下在WSL下修改Windows文件夹权限是不会生效的，所以需要稍加配置。编辑<code>/etc/wsl.conf</code>（没有就创建一个），建议使用nano编辑。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo nano /etc/wsl.conf</span><br></pre></td></tr></table></figure>
<p>并写入以下内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[automount]</span><br><span class="line">options = &quot;metadata&quot;</span><br></pre></td></tr></table></figure>
<p>保存并通过Powershell重启WSL。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Powershell Environment</span></span><br><span class="line">wsl.exe -<span class="literal">-shutdown</span></span><br></pre></td></tr></table></figure>
<p>最后给<code>~/.ssh</code>文件夹配置权限</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># WSL Environment</span></span><br><span class="line"><span class="built_in">cd</span> ~/.ssh</span><br><span class="line">chmod 644 config</span><br><span class="line">chmod 400 id_rsa</span><br></pre></td></tr></table></figure>
<h2 id="参考文章">参考文章</h2>
<ul>
<li><a href="https://superuser.com/questions/1323645/unable-to-change-file-permissions-on-ubuntu-bash-for-windows-10">https://superuser.com/questions/1323645/unable-to-change-file-permissions-on-ubuntu-bash-for-windows-10</a></li>
<li><a href="https://superuser.com/questions/1126721/rebooting-ubuntu-on-windows-without-rebooting-windows">https://superuser.com/questions/1126721/rebooting-ubuntu-on-windows-without-rebooting-windows</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>个人博客CDN选型和进阶玩法指北</title>
    <url>/2021/08/12/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2CDN%E9%80%89%E5%9E%8B%E5%92%8C%E8%BF%9B%E9%98%B6%E7%8E%A9%E6%B3%95%E6%8C%87%E5%8C%97/</url>
    <content><![CDATA[<p>网上几乎所有的文章都直接忽悠上CDN的车，难道上CDN就是提升速度的最优解？在CDN这条弯路上折腾了快两年，玩了一圈免备案的CDN，踩了各种各样的坑以后，恍然大悟，茅厕顿开，便在此大放厥词写下此文。本文主要介绍CDN的正确用法，以及性价比爆炸，便宜又效果好的网站加速方案。</p>
<h2 id="tldr">TL;DR</h2>
<p>在以下前提下，上CDN不如把网站搬到24块一个月的腾讯云香港轻量服务器</p>
<ul>
<li>回源稀烂</li>
<li>不考虑国外访问</li>
<li>CDN本身不太行</li>
<li>腾讯云香港还没有被玩坏</li>
</ul>
<p>已知的性价比最高的方案是Azure CDN (Microsoft Standard) + GitHub Pages。但网站本身才是影响访问速度的大头。</p>
<p>注：本文讨论的前提站长懒得备案。如果备案了，毫无疑问国内回源+国内CDN能吊打上述方案。</p>
<h2 id="上cdn一定提速吗">上CDN一定提速吗？</h2>
<p>啊这里有人可能会问了：“这个问题有必要问吗？”但仔细思考一下，免备案的CDN边缘节点最近就在香港，考虑到边缘节点是个公交车，还要服务别人，线路不一定比腾讯云的强。更令人智熄的是，基本上个人博客可以和访问量大不到哪去画个等号，你的网站被挤出Cache可太正常了，Cache Miss一下延迟就更爆炸了。无脑上CDN后发生的大概率事件就是CDN打不过三网直连的24块钱的腾讯云香港。</p>
<p>那怎么样才能让CDN搞快点呢？当然是头痛医头脚痛医脚，</p>
<ul>
<li>回源问题：弄一个好点的源站就好了，当然CDN本身的Cache策略和能力也非常关键</li>
<li>边缘节点承载能力的问题：弄一个好点的CDN就好了嘛</li>
</ul>
<p>所以问题就被简化为回源和CDN的选择问题了。</p>
<h2 id="源站的选择">源站的选择</h2>
<p>弄一个好点的源站，说着容易，实际上源站的选择还是很讲究的。</p>
<h3 id="源站的类型">源站的类型</h3>
<p>对于静态网站（如Hexo）来说，源站除了可以搭建在VPS上，更建议扔在对象存储上，因为</p>
<ul>
<li>更高的SLA：自己的VPS维护不当崩崩崩可太常见了，对象存储的SLA动不动就是99.9%以上</li>
<li>（可能）更高的性价比：个人博客一般不会太多空间，除非存了一堆视频。性能上可能有大厂的神秘优化
<ul>
<li>Azure Blob Storage：实测每天大概0.1-0.2美元，小贵</li>
<li>AWS S3 Bucket：免费额度应该能cover，计费也比Azure便宜</li>
</ul></li>
</ul>
<p>对象存储的缺点主要是</p>
<ul>
<li>第一次配置比较复杂，企业级的云通常需要反复折腾IAM权限</li>
<li>为了忽悠你买CDN，对象存储对换用自己的域名和HTTPS的支持多少会有问题</li>
<li>有坑（如果用一个厂家的全家桶的话坑会少一点）
<ul>
<li>Azure的官方文档就不会告诉你上传到<span class="math inline">\(web文件夹（容器）的\)</span>在Linux下要转义</li>
<li>AWS的S3 Bucket不兼容GeoDNS</li>
<li>...</li>
</ul></li>
</ul>
<p>不过调通了以后同步对象存储数据就像用网盘一样简单（因为这就是个网盘）。</p>
<h3 id="地理位置选择">地理位置选择</h3>
<p>之前也提到了，个人博客上CDN就要时刻准备好Cache Miss回源，所以缩短边缘节点从源站下载数据的时间非常的关键。解决这个问题最好的思路应该就是缩短边缘节点到源站的地理距离，最好在同一个地区，因为</p>
<ul>
<li>更短的延迟：这个没啥好说的，光速再快，理想情况下数据在中美之间走一圈都140毫秒起步</li>
<li>更大的带宽：一般来说城域网之间通信的带宽比国际线路的带宽大多了</li>
</ul>
<p>另一个好处就是，因为只需要考虑同地区内的通信，所以源站的国际线路质量完全不需要考虑，什么CN2 GIA都完全不需要，源站能通网就行。</p>
<p>由于一个源站只能照顾一个地区，如果只考虑国内访问的话，一个香港源站应该就足够了。但如果要</p>
<ul>
<li>照顾全世界的人民</li>
<li>照顾开着美国梯子的自己</li>
<li>刷高PageSpeed分数来优化SEO（谷歌应该是从美国访问你的网站）</li>
</ul>
<p>，就可能需要不止一个源站了。</p>
<h3 id="多地区延迟优化">多地区延迟优化</h3>
<p>多地区的优化是玩具级解决方案和企业级方案的分水岭之一，为啥这么说呢，因为从相关服务的定价来看，基本上云厂家就没考虑过个人玩家的死活。对于CDN来说，就是配置多个源站（这既是为了降低延迟，也是为了容灾），让CDN能根据访客的位置选择最近的源站。这大致有两种实现</p>
<ul>
<li>CDN自身支持多个源站并能选择最优的
<ul>
<li>Azure Front Door直接支持多个后端，并且可以自动根据延迟选择后端</li>
<li>Azure CDN (Standard Microsoft)的Rule Engine可以为不同地区指定一个源站</li>
</ul></li>
<li>（GeoDNS）让DNS根据地理位置将域名解析到不同后端，CDN通过这个域名回源。支持这个功能的DNS有
<ul>
<li>Azure Traffic Manager：大概4港币增加一个源站，30港币每百万解析</li>
<li>AWS Route 53：看到每月几十美元一个Policy Record后就没继续了解了</li>
<li>DNSPod（腾讯云）：360rmb每年，不乐意了</li>
<li>阿里云：免费版能按国内外区分（可香港也算国外，这没有区分度啊），从198rmb一年的企业版开始可以细分国外的国家地区</li>
</ul></li>
</ul>
<h3 id="我都要但我没钱咋办">我都要！但我没钱咋办</h3>
<p>多个源站，GeoDNS都是烧钱的东西（企业人傻钱多不在意），那普通人咋办？这里就要介绍这个无敌的存在了，GitHub Pages。这玩意除了能免费给你存东西以外，还安排上了Fastly CDN。GitHub Pages的架构我们不得而知，但从测速结果来看，很多地方的测速点测出的访问延迟都很低，应该是有做数据的geo-replication。也就是说DNS不用买，多地区存储也不要钱，唯一的毛病就是国内访问比较随缘，但作为CDN的源，这个毛病无伤大雅。而且像Hexo这种静态博客，甚至有插件能一键同步博客到GitHub Pages上。</p>
<h2 id="cdn的选择">CDN的选择</h2>
<h3 id="国内访问速度">国内访问速度</h3>
<p>根据我这两年来的观察，我<strong>主观</strong>的将我用过的CDN按照国内访问速度分为几个等级。</p>
<ul>
<li>T0：能和腾讯云香港五五开
<ul>
<li>Azure CDN：反正就不知道为什么它的香港节点又稳又快</li>
</ul></li>
<li>T1：不一定能干过腾讯云，但可能跑得赢CN2美国VPS的
<ul>
<li>AWS CloudFront</li>
<li>UDomain</li>
<li>CloudCone</li>
<li>这三家都有香港节点，但是表现属于时好时坏的那种</li>
</ul></li>
<li>T1.5：可能跑得赢辣鸡线路美国VPS的
<ul>
<li>Cloudflare：免费的还要什么自行车，主要是免费版没给香港节点，但美国节点的表现不算差</li>
</ul></li>
</ul>
<p>至于国外网站访问速度估计大家都差不太多。</p>
<h3 id="定价">定价</h3>
<ul>
<li>T0：看看就好
<ul>
<li>Azure Front Door：背靠Azure CDN (Standard Microsoft)，一条Rule也就每月170港币（至少会有一条，躲不掉的）</li>
</ul></li>
<li>T0.9：勉强可以接受
<ul>
<li>AWS Lightsail Distribution：背靠CloudFront，5美元50GB，但可惜用不完</li>
</ul></li>
<li>T1：穷人友好
<ul>
<li>Azure CDN (Standard)：真正的按量计费，1港币1GB，5条免费Rules，Azure少数不贵的东西</li>
<li>CloudFront：按量计费，0.12美元1GB</li>
<li>UDomain：按量计费，1.2港币1GB，充值的方式很怪，非常不现代</li>
<li>CloudCone：按量计费，0.045美元1GB，需要首充20美元的样子</li>
</ul></li>
<li>T2：博爱
<ul>
<li>Cloudflare：套餐0元起步</li>
</ul></li>
</ul>
<h3 id="结论">结论</h3>
<p>结论其实很明显，我肯定首推Azure CDN (Standard Microsoft)，因为Front Door这个价格就离谱，其他家的CDN会让你怀疑为什么要花这个钱买个减速器（当然CloudFlare配合廉价美国VPS能省钱）。当然Azure确实比较高冷，首先得有张外币卡，然后就是各种问就是企业级的设计，以及莫名其妙的设计，比如说对根域名不友好，CNAME验证各种不通过，官网文档只会让你去买他家DNS，用<code>cdnverify</code>绕过的方法就是不说，也不给根域名自动签TLS证书（AWS就可以）；不可以CDN前端用HTTPS后端HTTP（Front Door倒是可以）等等。但没办法谁让他家CDN国内访问就是快，看在价格不贵的份上原谅他了，免费5条规则也算良心，可以拿来配HTTPS强制跳转和HSTS，虽然这些东西可能在别家CDN面板上一键就能配好。</p>
<h2 id="summary">Summary</h2>
<p>Azure CDN (Microsoft Standard) + GitHub Pages这套方案可能比较绕，但一个月花不了几个钱（估计5rmb不到）速度又倍棒。不过还有一个问题值得思考，上这套方案就能让网站访问速度无人能敌？其实不是，从谷歌PageSpeed的分数看来，我从单回源（新加坡）+AWS CDN换到上述这套方案，PageSpeed也就提升了3分左右（国外访问速度）。另外提升的20多分靠的是对网站自身的调整，如减少了外部文件的加载数量。我曾今遇到过一个高度优化的网站，哪怕用的是Cloudflare，走国内国外网络的PageSpeed都是满分（用Chrome Lightroom测试）。</p>
<p>写到这里我才意识到这套方案最大的意义是给我省了一点钱，比起上腾讯云还便宜了不少，顺便提升了国内访问速度。</p>
]]></content>
  </entry>
  <entry>
    <title>使用virt-manager创建LXC容器</title>
    <url>/2020/11/14/%E4%BD%BF%E7%94%A8virt-manager%E5%88%9B%E5%BB%BALXC%E5%AE%B9%E5%99%A8/</url>
    <content><![CDATA[<p><del>virt-manager创建LXC容器是怎么回事呢？virt-manager相信大家都很熟悉，但是virt-manager创建LXC容器是怎么回事呢，下面就让小编带大家一起了解吧。virt-manager创建LXC容器，其实就是可以创建LXC容器，大家可能会很惊讶virt-manager怎么会创建LXC容器呢？但事实就是这样，小编也感到非常惊讶。</del></p>
<h2 id="下载容器rootfs">下载容器RootFS</h2>
<p>当然对于dalao来说，的确是可以用bootstrap或者busybox创建Linux的RootFS。显然为了省事，还是直接下载一个现成的比较方便。在<a href="http://uk.images.linuxcontainers.org/images">http://uk.images.linuxcontainers.org/images</a>选一个合适的镜像下载，注意要下载xz压缩包。我比较喜欢Ubuntu 20.04，就下载了<a href="http://uk.images.linuxcontainers.org/images/ubuntu/focal/amd64/default/20201114_07:42/rootfs.tar.xz">这个文件</a>。</p>
<h2 id="解压rootfs">解压RootFS</h2>
<p>找个合适的地方放镜像，比如<code>/data/tonny/ubuntu2004</code>，这里<code>/data</code>目录是我挂载的数据盘，然后解压<code>xz</code>文件。我的文件叫做<code>rootfs.tar.xz</code>，那么解压的命令如下。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">xz -d rootfs.tar.xz</span><br><span class="line">tar -xvf rootfs.tar</span><br></pre></td></tr></table></figure>
<figure>
<img data-src="/images/pasted-55.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h2 id="使用chroot修改密码">使用chroot修改密码</h2>
<p>反正我查了半天都没查到Image的默认密码是啥，但知道有个<code>ubuntu</code>的账户，不如直接切进RootFS改密码。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo chroot /data/tonny/ubuntu2004</span><br><span class="line">passwd ubuntu <span class="comment"># 或者可以直接passwd修改root密码</span></span><br></pre></td></tr></table></figure>
<figure>
<img data-src="/images/pasted-57.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h2 id="创建lxc容器">创建LXC容器</h2>
<p>首先要<code>Add Connection</code>，然后<code>Hypervisor</code>选择<code>Libvirt-LXC</code>再<code>Connect</code>。</p>
<figure>
<img data-src="/images/pasted-58.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<figure>
<img data-src="/images/pasted-59.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>接着<code>New Virtual Machine</code>，参数如下图。</p>
<figure>
<img data-src="/images/pasted-60.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<p>之后<code>root directory</code>选择<code>Browse</code>-&gt;<code>Browse Local</code>，找到<code>/data/tonny/ubuntu2004</code>并<code>Open</code>。最后像设置虚拟机一样配置CPU内存网络就可以启动LXC容器了。</p>
<figure>
<img data-src="/images/pasted-61.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
]]></content>
  </entry>
  <entry>
    <title>修复Chrome OS Crostini图标</title>
    <url>/2020/12/15/%E4%BF%AE%E5%A4%8DChrome-OS-Crostini%E5%9B%BE%E6%A0%87/</url>
    <content><![CDATA[<p>反正不知道为什么Chrome OS对Linux容器内的软件图标的支持偶尔会出问题，虽然不影响使用，但就是有点丑。</p>
<h2 id="参考文章">参考文章</h2>
<p><a href="https://www.reddit.com/r/Crostini/comments/bgcag0/how_to_force_the_app_launcher_to_update_the_icon/">how to force the app launcher to update the icon cache?</a></p>
<h2 id="刷新图标缓存">刷新图标缓存</h2>
<p>有时候可以更新图标缓存就可以恢复正常，或许是因为<code>apt</code>先创建了<code>desktop</code>文件再保存的图标，就迷惑到Chrome OS了。</p>
<h3 id="进入application文件夹">进入<code>application</code>文件夹</h3>
<p>即保存<code>desktop</code>文件的文件夹，这里以<code>xterm</code>为例，<code>xterm</code>的<code>desktop</code>文件保存在<code>/usr/share/applications</code>, 进入这个目录。</p>
<h3 id="移动desktop文件">移动<code>desktop</code>文件</h3>
<p>找到软件对应的<code>desktop</code>文件，如<code>debian-xterm.desktop</code>文件，把该文件暂时移到别的地方，如上级目录<code>..</code>。</p>
<h3 id="等待chrome-os内的图标消失">等待Chrome OS内的图标消失</h3>
<p>一段时间后，Chrome OS下的目标Linux软件就会自动消失。</p>
<h3 id="移回desktop文件">移回<code>desktop</code>文件</h3>
<p>把之前的<code>desktop</code>文件，如<code>debian-xterm.desktop</code>移回<code>application</code>文件夹。一段时间后软件图标会重新出现在Chrome OS的软件列表里。</p>
<h2 id="转换图标格式">转换图标格式</h2>
<p>截至Version 87，Chrome OS都不支持<code>xpm</code>格式的图标，所以有时候需要手动转换图标的格式。</p>
<h3 id="安装imagemagick">安装imagemagick</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt install imagemagick</span><br></pre></td></tr></table></figure>
<h3 id="找到图标的名字">找到图标的名字</h3>
<p>以<code>xterm</code>为例，打开<code>/usr/share/applications</code>下的<code>debian-xterm.desktop</code>文件。发现<code>Icon=mini.xterm</code>，所以图标的文件必须叫<code>mini.xterm.png</code>。</p>
<h3 id="进入存储图标的文件夹">进入存储图标的文件夹</h3>
<p><code>xterm</code>将图标保存在<code>/usr/share/pixmaps</code>里，发现两个图标文件<code>mini.xterm_32x32.xpm</code>, <code>mini.xterm_48x48.xpm</code>。把分辨率高的<code>mini.xterm_48x48.xpm</code>转换为<code>mini.xterm.png</code>。注意不同的程序会把图标存在不同的地方。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo convert mini.xterm_48x48.xpm mini.xterm.png</span><br></pre></td></tr></table></figure>
<h3 id="刷新图标缓存-1">刷新图标缓存</h3>
<p>参考上一章节刷新图标的缓存。</p>
<h2 id="查看错误日志">查看错误日志</h2>
<p>如果以上两个章节不能解决问题，试着查看错误报告来定位问题。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo journalctl -b -t garcon</span><br></pre></td></tr></table></figure>
<p>有一些错误应该不会产生什么影响，比如<code>[540]: MIME types file does not exist at: /home/user/.mime.types</code>。</p>
]]></content>
  </entry>
  <entry>
    <title>修复NVIDIA HPC SDK与CMake兼容问题</title>
    <url>/2021/01/10/%E4%BF%AE%E5%A4%8DNVIDIA-HPC-SDK%E4%B8%8ECMake%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p><code>CMake</code>和<code>GCC</code>+<code>NVCC</code>+<code>OpenMPI</code>那一套屁事没有，但<code>CMake</code>和<code>PGI</code>+<code>NVCC</code>+<code>OpenMPI</code>就经常出现各种各样的毛病，哦现在<code>PGI</code>改名叫<code>NVIDIA HPC SDK</code>了，改名也只是把错误信息改了改，反正还是照样报错。</p>
<h2 id="找不到cuda-toolkit">找不到CUDA Toolkit</h2>
<p><code>CMake</code>报<code>Could NOT find CUDA (missing: CUDA_INCLUDE_DIRS CUDA_CUDART_LIBRARY)</code>这样的错误，可以通过手动指定<code>CUDA Toolkit</code>的目录解决。有趣的是<code>NVIDIA HPC SDK</code>里自带的精简版<code>CUDA Toolkit</code>是可以给<code>CMake</code>使用的。</p>
<p>给<code>CMake</code>指定参数<code>CUDA_TOOLKIT_ROOT_DIR</code>，比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用NVIDIA HPC SDK里自带的精简版Toolkit</span></span><br><span class="line">cmake -DCUDA_TOOLKIT_ROOT_DIR=/home/apac/hpc_sdk/Linux_x86_64/2020/cuda/11.0</span><br><span class="line"><span class="comment"># 或者使用常规方法安装的Toolkit</span></span><br><span class="line">cmake -DCUDA_TOOLKIT_ROOT_DIR=/usr/<span class="built_in">local</span>/cuda-11.0</span><br></pre></td></tr></table></figure>
<h2 id="nvcc不兼容编译器">NVCC不兼容编译器</h2>
<p>在<code>make</code>的时候报错<code>nvcc fatal   : Unsupported PGI compiler found.  pgc++ is the only PGI compiler that is supported.</code>或者<code>Host compiler targets unsupported OS</code>，这个时候可以通过<code>make VERBOSE=1</code>来输出更多调试信息。</p>
<p>在输出中的出错的那几句话中找到调用<code>nvcc</code>的命令，然后找名为<code>--ccbin</code>的参数，这个参数可能会被愚蠢的<code>CMake</code>设置成了<code>gcc</code>或者<code>nvc</code>等一票C编译器而不是C++编译器，因此通过手动指定一个Host端的C++编译器可以解决问题。</p>
<p>给CMake指定参数<code>DCUDA_HOST_COMPILER</code>，比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用mpic++包装的C++编译器</span></span><br><span class="line">cmake -DCUDA_HOST_COMPILER=$(<span class="built_in">which</span> mpic++)</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>修复错误version GLIBCXX_3.4.20 not found的思路</title>
    <url>/2021/01/22/%E4%BF%AE%E5%A4%8D%E9%94%99%E8%AF%AFversion-GLIBCXX-3-4-20-not-found%E7%9A%84%E6%80%9D%E8%B7%AF/</url>
    <content><![CDATA[<p>实际上这次的情况有一些复杂，首先这个集群上跑的是<strong>活化石</strong>Cent OS，也就是说环境非常的古老（硬件倒是最新的），GCC还是4.8.5，甚至编译不了最新的DGL库。更悲伤的是我并没有这个公用集群的管理员权限，只能想方设法去绕开权限去安装软件，因此我用<strong>Conda</strong>装了CMake，GCC和G++。所以解决<code>version GLIBCXX_3.4.20 not found</code>这个问题就更加麻烦了，因此这篇文章的解决方法并不适用所有的情况，但可以作为一个参考。</p>
<p>注：用Conda无权限安装GCC等软件的方式非常简单</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create and activate a Conda environment named DGL</span></span><br><span class="line">conda create -n dgl </span><br><span class="line">conda activate dgl </span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a channel called Conda-Forge</span></span><br><span class="line">conda config --add channels conda-forge</span><br><span class="line"></span><br><span class="line"><span class="comment"># Install the software</span></span><br><span class="line">conda install gxx_linux-64 gcc_linux-64 cmake</span><br><span class="line"></span><br><span class="line"><span class="comment"># Verify whether GCC is working</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$CC</span> <span class="comment"># Should not be the default one (like /usr/bin/gcc)</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$CXX</span></span><br></pre></td></tr></table></figure>
<h2 id="原始毛病">原始毛病</h2>
<p>在编译的时候并不会出现问题，当执行<code>import dgl</code>（载入了DGL的动态链接库）的时候，就会报错，信息如下。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;string&gt;&quot;</span>, line 1, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">  File <span class="string">&quot;/work/gutz/miniconda3/envs/dgl/lib/python3.8/site-packages/dgl-0.6-py3.8-linux-x86_64.egg/dgl/__init__.py&quot;</span>, line 13, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    from .backend import load_backend, backend_name</span><br><span class="line">  File <span class="string">&quot;/work/gutz/miniconda3/envs/dgl/lib/python3.8/site-packages/dgl-0.6-py3.8-linux-x86_64.egg/dgl/backend/__init__.py&quot;</span>, line 96, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    load_backend(get_preferred_backend())</span><br><span class="line">  File <span class="string">&quot;/work/gutz/miniconda3/envs/dgl/lib/python3.8/site-packages/dgl-0.6-py3.8-linux-x86_64.egg/dgl/backend/__init__.py&quot;</span>, line 41, <span class="keyword">in</span> load_backend</span><br><span class="line">    from .._ffi.base import load_tensor_adapter <span class="comment"># imports DGL C library</span></span><br><span class="line">  File <span class="string">&quot;/work/gutz/miniconda3/envs/dgl/lib/python3.8/site-packages/dgl-0.6-py3.8-linux-x86_64.egg/dgl/_ffi/base.py&quot;</span>, line 45, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    _LIB, _LIB_NAME, _DIR_NAME = _load_lib()</span><br><span class="line">  File <span class="string">&quot;/work/gutz/miniconda3/envs/dgl/lib/python3.8/site-packages/dgl-0.6-py3.8-linux-x86_64.egg/dgl/_ffi/base.py&quot;</span>, line 35, <span class="keyword">in</span> _load_lib</span><br><span class="line">    lib = ctypes.CDLL(lib_path[0])</span><br><span class="line">  File <span class="string">&quot;/work/gutz/miniconda3/envs/dgl/lib/python3.8/ctypes/__init__.py&quot;</span>, line 381, <span class="keyword">in</span> __init__</span><br><span class="line">    self._handle = _dlopen(self._name, mode)</span><br><span class="line">OSError: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20<span class="string">&#x27; not found (required by /work/gutz/miniconda3/envs/dgl/lib/python3.8/site-packages/dgl-0.6-py3.8-linux-x86_64.egg/dgl/libdgl.so)</span></span><br></pre></td></tr></table></figure>
<h2 id="排查">排查</h2>
<p>在错误信息中值得关注的有三点，一是错误是由<code>libdgl.so</code>造成的，二是在试图加载<code>/lib64/libstdc++.so.6</code>时候出错，三是错误原因是<code>/lib64/libstdc++.so.6</code>这个东西太老了。</p>
<p>仔细一想事情其实非常不对，用Conda的G++编译出来的东西应该会调用Conda里面的C++库而不是古老的系统自带的那个。顺手用<code>ldd</code>和<code>readelf</code>去分析<code>libdgl.so</code>可以得到如下信息。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ldd /work/gutz/miniconda3/envs/dgl/lib/python3.8/site-packages/dgl-0.6-py3.8-linux-x86_64.egg/dgl/libdgl.so</span></span><br><span class="line">        linux-vdso.so.1 =&gt;  (0x00007ffde9722000)</span><br><span class="line">        libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00002aac0673e000)</span><br><span class="line">        librt.so.1 =&gt; /lib64/librt.so.1 (0x00002aac06942000)</span><br><span class="line">        libgomp.so.1 =&gt; /work/gutz/miniconda3/envs/dgl/lib/libgomp.so.1 (0x00002aac05929000)</span><br><span class="line">        libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00002aac06b4a000)</span><br><span class="line">        libstdc++.so.6 =&gt; /work/gutz/miniconda3/envs/dgl/lib/libstdc++.so.6 (0x00002aac05957000)</span><br><span class="line">        libm.so.6 =&gt; /lib64/libm.so.6 (0x00002aac06d66000)</span><br><span class="line">        libgcc_s.so.1 =&gt; /work/gutz/miniconda3/envs/dgl/lib/libgcc_s.so.1 (0x00002aac05acb000)</span><br><span class="line">        libc.so.6 =&gt; /lib64/libc.so.6 (0x00002aac07068000)</span><br><span class="line">        /lib64/ld-linux-x86-64.so.2 (0x00002aac058f6000)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># readelf -d /work/gutz/miniconda3/envs/dgl/lib/python3.8/site-packages/dgl-0.6-py3.8-linux-x86_64.egg/dgl/libdgl.so</span></span><br><span class="line"></span><br><span class="line">Dynamic section at offset 0xc14ef8 contains 32 entries:</span><br><span class="line">  Tag        Type                         Name/Value</span><br><span class="line"> 0x0000000000000001 (NEEDED)             Shared library: [libdl.so.2]</span><br><span class="line"> 0x0000000000000001 (NEEDED)             Shared library: [librt.so.1]</span><br><span class="line"> 0x0000000000000001 (NEEDED)             Shared library: [libgomp.so.1]</span><br><span class="line"> 0x0000000000000001 (NEEDED)             Shared library: [libpthread.so.0]</span><br><span class="line"> 0x0000000000000001 (NEEDED)             Shared library: [libstdc++.so.6]</span><br><span class="line"> 0x0000000000000001 (NEEDED)             Shared library: [libm.so.6]</span><br><span class="line"> 0x0000000000000001 (NEEDED)             Shared library: [libgcc_s.so.1]</span><br><span class="line"> 0x0000000000000001 (NEEDED)             Shared library: [libc.so.6]</span><br><span class="line"> 0x0000000000000001 (NEEDED)             Shared library: [ld-linux-x86-64.so.2]</span><br><span class="line"> 0x000000000000000e (SONAME)             Library soname: [libdgl.so]</span><br><span class="line"> 0x000000000000000f (RPATH)              Library rpath: [/work/gutz/miniconda3/envs/dgl/lib]</span><br><span class="line"> 0x000000000000000c (INIT)               0x19f000</span><br><span class="line"> 0x000000000000000d (FINI)               0xaae9c0</span><br><span class="line"> 0x0000000000000019 (INIT_ARRAY)         0xc10280</span><br><span class="line"> 0x000000000000001b (INIT_ARRAYSZ)       960 (bytes)</span><br><span class="line"> 0x0000000000000004 (HASH)               0x238</span><br><span class="line"> 0x000000006ffffef5 (GNU_HASH)           0xa0e8</span><br><span class="line"> 0x0000000000000005 (STRTAB)             0x45460</span><br><span class="line"> 0x0000000000000006 (SYMTAB)             0x15af0</span><br><span class="line"> 0x000000000000000a (STRSZ)              1191101 (bytes)</span><br><span class="line"> 0x000000000000000b (SYMENT)             24 (bytes)</span><br><span class="line"> 0x0000000000000003 (PLTGOT)             0xc16138</span><br><span class="line"> 0x0000000000000007 (RELA)               0x16c318</span><br><span class="line"> 0x0000000000000008 (RELASZ)             204672 (bytes)</span><br><span class="line"> 0x0000000000000009 (RELAENT)            24 (bytes)</span><br><span class="line"> 0x0000000000000018 (BIND_NOW)</span><br><span class="line"> 0x000000006ffffffb (FLAGS_1)            Flags: NOW</span><br><span class="line"> 0x000000006ffffffe (VERNEED)            0x16c098</span><br><span class="line"> 0x000000006fffffff (VERNEEDNUM)         9</span><br><span class="line"> 0x000000006ffffff0 (VERSYM)             0x16811e</span><br><span class="line"> 0x000000006ffffff9 (RELACOUNT)          1435</span><br><span class="line"> 0x0000000000000000 (NULL)               0x0</span><br></pre></td></tr></table></figure>
<p>这就很奇怪了，明明<code>libdgl.so</code>已经指明了使用这个C++库<code>/work/gutz/miniconda3/envs/dgl/lib/libstdc++.so.6</code>，而不是系统的<code>/lib64/libstdc++.so.6</code>。更奇怪的事是在<code>readelf</code>的结果中，<code>RPATH</code>项（run-time search path）已经指定了所需的库的位置<code>/work/gutz/miniconda3/envs/dgl/lib</code>，也就是说将要加载的动态链接库的<strong>绝对路径</strong>都已经<strong>写死在文件里了</strong>。而且对<code>/work/gutz/miniconda3/envs/dgl/lib/libstdc++.so.6</code>稍加验证一下，可以看出来这个库是支持<code>GLIBCXX_3.4.20</code>的。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># strings /work/gutz/miniconda3/envs/dgl/lib/libstdc++.so.6 | grep GLIBCXX</span></span><br><span class="line">...</span><br><span class="line">GLIBCXX_3.4.18</span><br><span class="line">GLIBCXX_3.4.19</span><br><span class="line">GLIBCXX_3.4.20</span><br><span class="line">GLIBCXX_3.4.21</span><br><span class="line">GLIBCXX_3.4.22</span><br><span class="line">GLIBCXX_3.4.23</span><br><span class="line">GLIBCXX_3.4.24</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>那么是什么原因导致了DGL加载了错误的C++库？我并没有什么头绪，甚至去翻了源代码去看看DGL有没有做什么手动指定库加载路径的呆逼操作，结果发现并没有，加载库的代码只有两行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_load_lib</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Load libary by searching possible path.&quot;&quot;&quot;</span></span><br><span class="line">    lib_path = libinfo.find_lib_path()</span><br><span class="line">    lib = ctypes.CDLL(lib_path[<span class="number">0</span>]) <span class="comment"># lib_path[0] = &#x27;/work/gutz/miniconda3/envs/dgl/lib/python3.8/site-packages/dgl-0.6-py3.8-linux-x86_64.egg/dgl/libdgl.so&#x27;</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>一筹莫展之际，随便试了试网上强烈推荐的调试方法<code>export LD_DEBUG=libs</code>，输出加载动态链接库时的额外信息。尽管信息很多，但还是发现加载了<code>/lib64/libstdc++.so.6</code>的罪魁祸首不是DGL，而是PyTorch。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">197196:      search path=/work/gutz/miniconda3/envs/dgl/lib/python3.8/site-packages/torch/lib               (RUNPATH from file /work/gutz/miniconda3/envs/dgl/lib/python3.8/site-packages/torch/lib/libtorch_global_deps.so)</span><br><span class="line">197196:       trying file=/work/gutz/miniconda3/envs/dgl/lib/python3.8/site-packages/torch/lib/libgcc_s.so.1</span><br><span class="line">197196:      search cache=/etc/ld.so.cache</span><br><span class="line">197196:       trying file=/lib64/libgcc_s.so.1</span><br><span class="line">197196:</span><br><span class="line">197196:</span><br><span class="line">197196:     calling init: /lib64/libgcc_s.so.1</span><br><span class="line">197196:</span><br><span class="line">197196:</span><br><span class="line">197196:     calling init: /lib64/libstdc++.so.6</span><br></pre></td></tr></table></figure>
<p>用<code>ldd</code>看看就可以发现<code>libtorch_global_deps.so</code>这个死东西会去加载<code>/lib64/libstdc++.so.6</code>。在<code>libdgl.so</code>加载前就把<code>/lib64/libstdc++.so.6</code>加载进内存了，<code>rpath</code>指定的C++库就不会被载入了。</p>
<p>用<code>readelf</code>分析<code>libtorch_global_deps.so</code>，发现其<code>rpath</code>指定为<code>$ORIGIN</code>，也就是<code>libtorch_global_deps.so</code>所在的目录。当然这个目录有PyTorch依赖的其他库，如Profiling用的<code>libnvToolsExt</code>，显然这里并没有C++库，系统就自动去搜寻默认路径，就把<code>/lib64/libstdc++.so.6</code>加载了。</p>
<h2 id="解决方案">解决方案</h2>
<p>如果对自己的技术充分自信并有大量空闲时间，可以用Conda的G++把PyTorch重新编译就可以解决这个问题。</p>
<p>如果想试试花里胡哨的，可以试试<code>patchelf</code>去给<code>libtorch_global_deps.so</code>加一个指向新C++库的<code>rpath</code>。</p>
<p>像我懒狗就直接在<code>LD_LIBRARY_PATH</code>这个环境变量里指定一下默认搜索路径就完事了。当然这样非常的不优雅就是了。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/work/gutz/miniconda3/envs/dgl/lib:<span class="variable">$LD_LIBRARY_PATH</span></span><br></pre></td></tr></table></figure>
<h2 id="参考文章">参考文章</h2>
<ul>
<li><a href="http://shibing.github.io/2016/08/20/%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E4%B8%8Erpath/">http://shibing.github.io/2016/08/20/%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E4%B8%8Erpath/</a></li>
<li><a href="https://stackoverflow.com/questions/12851184/dlopen-failed-cannot-open-shared-object-file-no-such-file-or-directory">https://stackoverflow.com/questions/12851184/dlopen-failed-cannot-open-shared-object-file-no-such-file-or-directory</a></li>
<li><a href="https://nehckl0.medium.com/creating-relocatable-linux-executables-by-setting-rpath-with-origin-45de573a2e98">https://nehckl0.medium.com/creating-relocatable-linux-executables-by-setting-rpath-with-origin-45de573a2e98</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>博客年度总结既 Hexo 第三次魔改记录</title>
    <url>/2022/01/31/%E5%8D%9A%E5%AE%A2%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93%E6%97%A2-Hexo-%E7%AC%AC%E4%B8%89%E6%AC%A1%E9%AD%94%E6%94%B9%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<p>在除夕前那么几天终于有一点闲空了，早在半年前，我就对原来的博客很不爽了，原来的主题丑到我了，博客系统也废了很久（不过怎么还有人能成功评论了，我自己都不能登录上去）。突然又发现 NexT 主题悄悄换了个仓库，早就更新了一个大版本了，连渲染后端都换成了 Nunjucks 了。总之，是时候爆改我博客的 Remix 主题了。</p>
<h2 id="更新日志">更新日志</h2>
<figure>
<img data-src="/images/pasted-96.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<figure>
<img data-src="/images/pasted-97.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<figure>
<img data-src="/images/pasted-98.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<ul>
<li>2022.1 NexT.Remix v3 (Preview)：目前的版本，基于 NexT.Gemini v8，融合了 <a href="https://dnocm.com/cake/">Hexo Cake</a> 和 <a href="https://github.com/CaiJimmy/hugo-theme-stack">Hugo Stack</a> 两个主题的风格</li>
<li>2021.8 NexT.Gemini (Remix v2)：速度优化</li>
<li>2020.5 NexT.Gemini (Remix v1)：初始的魔改版本，基于 NexT.Gemini v7，风格参考了 Hexo Terminal 和某个 Markdown Resume 模板</li>
</ul>
<p>由于NexT v8较v7有大量的代码改动，<del>加上我原来改代码的方式充满野性</del>，NexT.Remix 的代码并不继承于之前的魔改主题，且代码的改动遵守了 NexT 的魔改规范，使用了 Theme Inject 来魔改主题，仅增加数个文件，并未对原有文件进行修改，能够（相对）方便的合并 upstream 的新代码。</p>
<p>除了更新 upstream 和 Hexo 的版本以及界面风格调整外，还把烂掉了的 utterance 换成了 giscus。</p>
<h3 id="todo">TODO</h3>
<ul>
<li>暂时使用 jsdelivr 分发部分公共 JS 库，之后改成用博客的 CDN 来分发这些文件以提升国内访问速度和稳定性。</li>
<li>目前 giscus 的 integration 做的很粗糙，等到改好了就给 upstream 交个 PR 。</li>
</ul>
<h2 id="演进方向">演进方向</h2>
<h3 id="现代">现代</h3>
<p>NexT 作为一个有着丰富历史（比如换了两次仓库）的主题，它仍然不忘初心，到现在还保持着最初的模样。然而我更喜欢时下流行的 <strong>后·扁平化</strong> 风格，但又馋 NexT 丰富的功能，同时也懒得迁移平台，所以只能去把 NexT 变成我喜欢的样子了。</p>
<p>由于我并不是什么设计带师，就只好 ”参考“ 已有的优秀样式。</p>
<ul>
<li>Hexo Cake：在 NexT v7 上魔改的一个主题。总体很棒，由于都是 NexT·改，”参考“起来更方便了</li>
<li>Hugo Stack：喜欢它的阴影和配色</li>
</ul>
<p>实际上，NexT 的底子非常不错，随便改改就能完全满足我的审美。</p>
<h3 id="简洁">简洁</h3>
<p>如果配置得当，NexT本身的界面并不臃肿。这是 Remix v1 开始就在追求的目标。这一次进一步的删除掉不必要的元素，比如到处都是的下划线，友链上那一堆，文章目录上那一堆，还有日期上的下划线。另外 Pagination 也成了我重拳出击的对象。</p>
<p>此外，从很久以前开始，我就在弱化标签和分类这两个功能，因为我自己的习惯是从来不看博客文章的标签和分类，读者也都是从搜索引擎跳转过来的，搜索引擎也不需要标签就能自己从文中提取关键词，<del>当然更重要的原因就是我懒得加这些东西</del>，所以界面上关于标签和分类的元素也减少了。</p>
<h3 id="个性">个性</h3>
<p>这也是为什么要自己魔改主题的原因。一个显而易见的原因当然就是不希望自己的博客主题和其他大路货撞车。其次就是博客主题要符合自己的写作风格，不同于 <a href="https://www.whexy.com/">这位</a>，追求读者阅读的极致体验与获得感，我希望我能写出来：</p>
<ul>
<li>仅期望我自己，有时也包括事件相关者阅读的回忆类内容</li>
<li>（最好是独一无二的）技术类文章
<ul>
<li>在自己忘掉的时候给自己参考</li>
<li><strong>顺便</strong>给<strong>找不到其他资料</strong>的人参考</li>
</ul></li>
</ul>
<p>也就是说，我并不会花很多心思在提升读者阅读体验上。对我来说，我不喜欢把很多精力放在我不关心的东西上，一些不那么重要的问题就怎么省力怎么来。比如配图，别说统一配图的风格了，如果这个配图只是为了美观，我选择不配图。因此，没有文章配图也很好看的主题就是我需要的。那种不需要写摘要，会自动把文章第一段当作摘要的主题就是我需要的。</p>
<p>我希望我的文章能侧重于回答那些暂时无解或者没人总结答案的但很多人关心的问题上，<del>这样读者在救命稻草前肯定不会对阅读体验挑三拣四</del>。当然基本的阅读体验还是要有的，魔改主题提升文章可读性也是改善阅读体验的一部分。</p>
<p>还有就是，我指望魔改博客主题这件事能够一定程度的体现出博主的水平……什么，你说 dalao 都是自己造博客框架的？我又不是前端专业，我不揽这个瓷器活。</p>
<p>哦对了，现在博客使用一种叫 Neko 语的东西，这语言一部分是中英双语，一部分是被我改掉的 NexT 的塑料英语。</p>
<h2 id="总结">总结</h2>
<p>自我感觉这一年这个博客还是取得了显著的进步，看起来更 Professional 了。</p>
<h3 id="文章数量">文章数量</h3>
<p>似乎没有维持出一个月一篇的节奏。Anyway，我自认为文章质量比去年的还是强了一丢丢。（<del>可能是我太摸了，所以没有踩到什么坑。</del>）</p>
<h3 id="博客主题">博客主题</h3>
<p>改完之后我舒服了，从表面到代码实现都比原来美观了不少。</p>
<h3 id="访问速度">访问速度</h3>
<p>以前的方案又贵又拉，Azure CDN + Github Page 这套太强了。</p>
<h3 id="访问量">访问量</h3>
<p>只要写文章的速度比文章过气的速度快，访问量一定是会增长的。只不过百度死活还是只收录了主页，辣鸡玩意。</p>
]]></content>
  </entry>
  <entry>
    <title>导出Google Text-to-Speech的音频</title>
    <url>/2020/11/07/%E5%AF%BC%E5%87%BAGoogle-Text-to-Speech%E7%9A%84%E9%9F%B3%E9%A2%91/</url>
    <content><![CDATA[<p>Google Text-to-Speech用WaveNet神经网络整出来的声音过于好听，以至于非常适合代替懒狗充当PPT或者短视频的旁白，但是试用TTS的页面上并没有下载音频文件的选项，因此提取音频文件需要额外几个步骤。</p>
<p>启动Chrome，要用谷歌的软件薅谷歌的羊毛。按下<code>F12</code>启动万能的调试工具，切换到<code>Network</code>选项卡，然后按下页面中的<code>Speak it</code>，接着就在调试工具里观察到一个<code>proxy?url=</code>的文件在传输，对着这个文件右键选择<code>Copy</code>-&gt;<code>Copy Response</code>，创建一个Python脚本文件（文本文档改后缀名<code>.py</code>即可）后粘贴。应该可以观察到和下面代码类似的东西。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;audioContent&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;timepoints&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;audioConfig&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;audioEncoding&quot;</span>: <span class="string">&quot;LINEAR16&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;speakingRate&quot;</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">&quot;pitch&quot;</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">&quot;volumeGainDb&quot;</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">&quot;sampleRateHertz&quot;</span>: <span class="number">24000</span>,</span><br><span class="line">    <span class="attr">&quot;effectsProfileId&quot;</span>: []</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>把这个脚本修改为下面的样子并运行，就可以将音频导出为<code>wav</code>文件了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"></span><br><span class="line">dat = &#123;</span><br><span class="line">  <span class="string">&quot;audioContent&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">  <span class="string">&quot;timepoints&quot;</span>: [],</span><br><span class="line">  <span class="string">&quot;audioConfig&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;audioEncoding&quot;</span>: <span class="string">&quot;LINEAR16&quot;</span>,</span><br><span class="line">    <span class="string">&quot;speakingRate&quot;</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">&quot;pitch&quot;</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">&quot;volumeGainDb&quot;</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">&quot;sampleRateHertz&quot;</span>: <span class="number">24000</span>,</span><br><span class="line">    <span class="string">&quot;effectsProfileId&quot;</span>: []</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;output.wav&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(base64.b64decode(dat[<span class="string">&quot;audioContent&quot;</span>]))</span><br></pre></td></tr></table></figure>
<p>现在可以愉快的把音频插入到PPT里，设置动画自动播放音频自动切换了。</p>
]]></content>
  </entry>
  <entry>
    <title>滥用Docker容器当作虚拟机的方法</title>
    <url>/2021/09/06/%E6%8A%8ADocker%E5%AE%B9%E5%99%A8%E5%BD%93%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%94%A8/</url>
    <content><![CDATA[<p>把Docker当虚拟机用，虽然真的很不优雅，做出来的镜像又糙又肮脏，但是这真的很方便啊。</p>
<h2 id="注意事项">注意事项</h2>
<h3 id="best-practice">Best Practice</h3>
<p>理想情况下Docker Image最好使用Dockerfile来构建。把Docker Container当做虚拟机来构建Docker Image这个方法虽然非常省事，但该方法很容易做出来很大一坨镜像，很不轻量，所以仅推荐在测试时使用，不推荐在正式场合（如企业的生产环境）使用。</p>
<h3 id="权限问题">权限问题</h3>
<p>Docker的安装和使用（创建销毁容器等）都需要超级用户权限。若非系统管理员，务必确认环境里已经安装了Docker和拥有Docker的使用权限（已加入<code>docker</code>用户组）</p>
<p>注：Docker也有Rootless模式，但需要额外的配置。</p>
<h2 id="基础知识">基础知识</h2>
<h3 id="容器与镜像">容器与镜像</h3>
<p>镜像可以说是容器在某一个时刻的所有文件数据，包括运行环境，程序，临时文件等。而容器才是能产生进程运行程序的东西。所以镜像是静态的，容器是动态的。他们的生命周期和转换关系如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">      |---------push--&gt; (Docker Hub)</span><br><span class="line">      |---------save--&gt; (tar File)</span><br><span class="line">      |</span><br><span class="line">Docker Image----run---&gt; Docker Container    </span><br><span class="line">      ↑                       |</span><br><span class="line">      |---------commit--------|</span><br><span class="line">      |---------pull----(Docker Hub)</span><br><span class="line">      |---------load----(tar File)</span><br><span class="line">      |---------build---(Dockerfile)</span><br></pre></td></tr></table></figure>
<h3 id="命名">命名</h3>
<p>容器的名字没有太多讲究，镜像名字的构成是：<code>镜像名:Tag</code>，如<code>Ubuntu:18.04</code>的镜像名是<code>Ubuntu</code>，Tag是<code>18.04</code>。</p>
<h3 id="其他实用命令">其他实用命令</h3>
<ul>
<li><code>docker ps</code> 查看运行中的容器
<ul>
<li><code>docker ps -a</code> 查看所有容器（包含未运行的容器）</li>
</ul></li>
<li><code>docker rm -f</code> 删除容器</li>
<li><code>docker images</code> 查看已下载的镜像</li>
<li><code>docker pull</code> 下载镜像</li>
<li><code>docker rmi</code> 删除镜像</li>
</ul>
<h3 id="dockerhub下载加速">DockerHub下载加速</h3>
<p>暂未找到什么很好的加速方法</p>
<h2 id="创建容器">创建容器</h2>
<p>推荐命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -id --name your_ct_name --privileged --network host --restart always ubuntu:18.04 bash</span><br></pre></td></tr></table></figure>
<blockquote>
<p>参数含义：</p>
<ul>
<li><code>-d</code> + <code>-i</code> + <code>bash</code> 组合会启动容器里的<code>bash</code>，目的是让容器挂在后台</li>
<li><code>--restart always</code> 主机重启后自动启动容器，挂在后台</li>
<li><code>ubuntu:18.04</code> 推荐使用Ubuntu 18.04镜像</li>
<li><code>--privileged</code> 允许容器使用更多的内核功能</li>
<li><code>--network host</code> 使用主机网络（禁用网络空间隔离）</li>
</ul>
</blockquote>
<p>也可以使用老黄家的CUDA开发环境镜像：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -id --name your_ct_name --privileged --network host --restart always --gpus all nvidia/cuda:11.0.3-devel-ubuntu18.04 bash</span><br></pre></td></tr></table></figure>
<blockquote>
<p>参数含义：</p>
<ul>
<li><code>nvidia/cuda:11.0.3-devel-ubuntu18.04</code> 是包含CUDA 11.0.3对应工具链的Ubuntu 18.04镜像
<ul>
<li>镜像的CUDA版本需要和驱动支持的版本对应，<code>nvidia-smi</code> 右上角会显示最高支持的CUDA版本</li>
<li><code>devel</code>版镜像包含<code>nvcc</code>编译器等工具链，<code>runtime</code>版不含工具链</li>
</ul></li>
<li><code>--gpus all</code> 使用所有可用的GPU</li>
</ul>
</blockquote>
<p>所有黄家容器列表：<a href="https://hub.docker.com/r/nvidia/cuda/tags?page=1&amp;ordering=last_updated">https://hub.docker.com/r/nvidia/cuda/tags?page=1&amp;ordering=last_updated</a></p>
<h2 id="进入容器交互式bash">进入容器（交互式bash）</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it your_ct_name bash</span><br></pre></td></tr></table></figure>
<blockquote>
<p>参数含义：</p>
<ul>
<li><code>-i</code> + <code>-t</code> 启动交互式模式</li>
</ul>
</blockquote>
<blockquote>
<p>进入容器后如果想换apt源，建议使用下面的命令来换，因为镜像为了节约空间，往往不包含文字编辑器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">&quot;s#archive.ubuntu.com#mirrors.sustech.edu.cn#g&quot;</span> /etc/apt/sources.list</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="容器镜像文件的转换">容器、镜像、文件的转换</h2>
<p>容器到镜像</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker commit your_ct_name your_images_name:your_tag</span><br></pre></td></tr></table></figure>
<p>镜像到文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker save your_images_name:your_tag -o your_file.tar</span><br></pre></td></tr></table></figure>
<p>文件到镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker load -i your_file.tar</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>某神必的 Bash 代码分析</title>
    <url>/2019/08/18/%E6%9F%90%E7%A5%9E%E5%BF%85%E7%9A%84-Bash-%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>这个样例代码是$$的一键搭建脚本，老朽常年懒得看代码，唯独对这个<del>又臭又长的</del>神必脚本有点好奇（这里面可是有一千多行呢）</p>
<h2 id="控制台下的颜色">控制台下的颜色</h2>
<p>颜色定义</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">red=<span class="string">&#x27;\033[0;31m&#x27;</span></span><br><span class="line">green=<span class="string">&#x27;\033[0;32m&#x27;</span></span><br><span class="line">yellow=<span class="string">&#x27;\033[0;33m&#x27;</span></span><br><span class="line">plain=<span class="string">&#x27;\033[0m&#x27;</span></span><br></pre></td></tr></table></figure>
<p>使用方法</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;[<span class="variable">$&#123;red&#125;</span>Error<span class="variable">$&#123;plain&#125;</span>] This script must be run as root!&quot;</span></span><br></pre></td></tr></table></figure>
<p>记得把颜色切换回来啊</p>
<h2 id="判断是否为root用户执行脚本">判断是否为ROOT用户执行脚本</h2>
<h3 id="if的简略写法">if的简略写法</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[[ <span class="variable">$EUID</span> -ne 0 ]] &amp;&amp; <span class="built_in">echo</span> -e <span class="string">&quot;[<span class="variable">$&#123;red&#125;</span>Error<span class="variable">$&#123;plain&#125;</span>] This script must be run as root!&quot;</span> &amp;&amp; <span class="built_in">exit</span> 1</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>RUID</code>即用户<code>UID</code>，进程真实用户号。创建该进程的用户的<code>UID</code>为该进程的真实用户号<code>RUID</code> <code>EUID</code>用于系统决定用户对文件资源的访问权限，一般情况下等同于<code>RUID</code>。 <a href="https://www.jianshu.com/p/23f2f2be2b29">原文链接</a></p>
</blockquote>
<h2 id="关闭selinux">关闭SELinux</h2>
<h3 id="bash函数-if-sed-grep的用法">bash函数 if, sed, grep的用法</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">disable_selinux</span></span>()&#123;</span><br><span class="line">    <span class="keyword">if</span> [ -s /etc/selinux/config ] &amp;&amp; grep <span class="string">&#x27;SELINUX=enforcing&#x27;</span> /etc/selinux/config; <span class="keyword">then</span></span><br><span class="line">        sed -i <span class="string">&#x27;s/SELINUX=enforcing/SELINUX=disabled/g&#x27;</span> /etc/selinux/config</span><br><span class="line">        setenforce 0</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>安全增强式Linux（SELinux，Security-Enhanced Linux）是一个Linux内核的安全模块，其提供了访问控制安全策略机制 <a href="https://zh.wikipedia.org/wiki/%E5%AE%89%E5%85%A8%E5%A2%9E%E5%BC%BA%E5%BC%8FLinux">全文链接</a></p>
</blockquote>
<blockquote>
<p><code>setenforce 0</code>: 临时关闭selinux <a href="https://blog.csdn.net/zhoushengbin3/article/details/7883410">原文链接</a></p>
</blockquote>
<blockquote>
<p><code>-s</code> 的表达式用于判断文件存在且不为空。当config文件存在时，该表达式为真 <a href="https://stackoverflow.com/questions/47142729/whats-is-the-meaning-of-if-s-filename-in-shell">原文链接</a></p>
</blockquote>
<blockquote>
<p><code>grep</code>判断文件内是否存在某字符串，若字符串存在，即该命令成功执行，该表达式为真 <a href="https://www.jianshu.com/p/ed22db46965e">参考文章</a></p>
</blockquote>
<blockquote>
<p><code>sed s/textA/textB</code> 用于把<code>textA</code>替换为<code>textB</code> <code>-i</code> 参数代表直接修改读取的文件内容，而不是输出到终端 <code>/g</code> 代表若一行内多次出现被<code>textA</code>，则将所有<code>textA</code>全部替换为<code>textB</code> <a href="https://www.cnblogs.com/ggjucheng/archive/2013/01/13/2856901.html">更多资料</a></p>
</blockquote>
<h2 id="系统发行版判断">系统发行版判断</h2>
<h3 id="grep-if用法">grep, if用法</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> [[ -f /etc/redhat-release ]]; <span class="keyword">then</span></span><br><span class="line">    release=<span class="string">&quot;centos&quot;</span></span><br><span class="line">    systemPackage=<span class="string">&quot;yum&quot;</span></span><br><span class="line"><span class="keyword">elif</span> grep -Eqi <span class="string">&quot;debian|raspbian&quot;</span> /etc/issue; <span class="keyword">then</span></span><br><span class="line">    release=<span class="string">&quot;debian&quot;</span></span><br><span class="line">    systemPackage=<span class="string">&quot;apt&quot;</span></span><br><span class="line"><span class="keyword">elif</span> grep -Eqi <span class="string">&quot;ubuntu&quot;</span> /etc/issue; <span class="keyword">then</span></span><br><span class="line">    release=<span class="string">&quot;ubuntu&quot;</span></span><br><span class="line">    systemPackage=<span class="string">&quot;apt&quot;</span></span><br><span class="line"><span class="keyword">elif</span> grep -Eqi <span class="string">&quot;centos|red hat|redhat&quot;</span> /etc/issue; <span class="keyword">then</span></span><br><span class="line">    release=<span class="string">&quot;centos&quot;</span></span><br><span class="line">    systemPackage=<span class="string">&quot;yum&quot;</span></span><br><span class="line"><span class="keyword">elif</span> grep -Eqi <span class="string">&quot;debian|raspbian&quot;</span> /proc/version; <span class="keyword">then</span></span><br><span class="line">    release=<span class="string">&quot;debian&quot;</span></span><br><span class="line">    systemPackage=<span class="string">&quot;apt&quot;</span></span><br><span class="line"><span class="keyword">elif</span> grep -Eqi <span class="string">&quot;ubuntu&quot;</span> /proc/version; <span class="keyword">then</span></span><br><span class="line">    release=<span class="string">&quot;ubuntu&quot;</span></span><br><span class="line">    systemPackage=<span class="string">&quot;apt&quot;</span></span><br><span class="line"><span class="keyword">elif</span> grep -Eqi <span class="string">&quot;centos|red hat|redhat&quot;</span> /proc/version; <span class="keyword">then</span></span><br><span class="line">    release=<span class="string">&quot;centos&quot;</span></span><br><span class="line">    systemPackage=<span class="string">&quot;yum&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>if</code>的<code>-f</code>判断文件是否存在 <a href="https://stackoverflow.com/questions/15511690/shell-scripting-if-f-file">参考资料</a> <code>grep</code>的<code>-E</code>是使用正则表达式的扩展语法, <code>-q</code>不打印任何标准输出, <code>-i</code>忽略大小写 <a href="http://man.linuxde.net/grep">更多资料</a></p>
</blockquote>
<h2 id="检查内核版本是否高于3.7.0">检查内核版本是否高于3.7.0</h2>
<h3 id="tr-cut-sort-head-test-uname的用法linux特殊变量">tr, cut, sort, head, test, uname的用法，Linux特殊变量</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">version_gt</span></span>()&#123;</span><br><span class="line">    <span class="built_in">test</span> <span class="string">&quot;<span class="subst">$(echo <span class="string">&quot;<span class="variable">$@</span>&quot;</span> | tr <span class="string">&quot; &quot;</span> <span class="string">&quot;\n&quot;</span> | sort -V | head -n 1)</span>&quot;</span> != <span class="string">&quot;<span class="variable">$1</span>&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">check_kernel_version</span></span>()&#123;</span><br><span class="line">    <span class="built_in">local</span> kernel_version=$(uname -r | cut -d- -f1)</span><br><span class="line">    <span class="keyword">if</span> version_gt <span class="variable">$&#123;kernel_version&#125;</span> 3.7.0; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">return</span> 0</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">return</span> 1</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>uname</code>用于打印当前系统相关信息 <code>-r</code> 显示操作系统的发行编号 <a href="http://man.linuxde.net/uname">uname的更多用法</a> <code>cut</code>命令用来显示行中的指定部分，删除文件中指定字段 <code>-d</code> 指定字段的分隔符 <code>-f</code> 显示指定字段的内容 <a href="http://man.linuxde.net/cut">cut的更多用法</a></p>
</blockquote>
<p>Example <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># uname -r</span></span><br><span class="line"><span class="comment"># uname -r | cut -d- -f1</span></span><br><span class="line"><span class="comment"># uname -r | cut -d- -f2</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">4.15.0-52-generic</span><br><span class="line">4.15.0</span><br><span class="line">52</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>test</code> 命令用于检查某个条件是否成立 <a href="http://www.runoob.com/linux/linux-shell-test.html">test的样例代码</a> <code>$@</code> 传递给脚本或函数的所有参数 <code>$1</code> 表示第一个参数 <a href="http://c.biancheng.net/cpp/view/2739.html">更多特殊变量</a> <code>tr</code> 命令用于转换或删除文件中的字符 <a href="http://www.runoob.com/linux/linux-comm-tr.html">tr的更多资料</a> <code>sort -V</code> 命令用于版本的排序 <a href="https://stackoverflow.com/questions/39504944/sort-numerically-in-unix-linux-where-sort-v-not-available">参考资料</a> <code>head -n 1</code> 只显示第一行的内容 <a href="http://man.linuxde.net/head">head的更多资料</a></p>
</blockquote>
<p>Example 脚本文件 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">fun1</span></span>() &#123;</span><br><span class="line">        <span class="built_in">echo</span> ---fun1---</span><br><span class="line">        <span class="built_in">echo</span> <span class="variable">$@</span></span><br><span class="line">        <span class="built_in">echo</span> ---end---</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="title">fun2</span></span>() &#123;</span><br><span class="line">        <span class="built_in">echo</span> ---fun2---</span><br><span class="line">        <span class="built_in">echo</span> <span class="variable">$1</span></span><br><span class="line">        <span class="built_in">echo</span> ---end---</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">fun3</span></span>() &#123;</span><br><span class="line">        <span class="built_in">echo</span> ---fun3---</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$@</span>&quot;</span> | tr <span class="string">&quot; &quot;</span> <span class="string">&quot;\n&quot;</span> | sort -V</span><br><span class="line">        <span class="built_in">echo</span> ---end---</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fun1 4.15.0 3.7.0</span><br><span class="line">fun2 4.15.0 3.7.0</span><br><span class="line">fun3 4.15.0 3.7.0</span><br><span class="line">fun3 2.15.0 3.7.0</span><br></pre></td></tr></table></figure></p>
<p>脚本输出 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">---fun1---</span><br><span class="line">4.15.0 3.7.0</span><br><span class="line">---end---</span><br><span class="line">---fun2---</span><br><span class="line">4.15.0</span><br><span class="line">---end---</span><br><span class="line">---fun3---</span><br><span class="line">3.7.0</span><br><span class="line">4.15.0</span><br><span class="line">---end---</span><br><span class="line">---fun3---</span><br><span class="line">2.15.0</span><br><span class="line">3.7.0</span><br><span class="line">---end---</span><br></pre></td></tr></table></figure></p>
<h2 id="判断是否为64位系统">判断是否为64位系统</h2>
<h3 id="if判断命令输出内容">if判断命令输出内容</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">is_64bit</span></span>()&#123;</span><br><span class="line">    <span class="keyword">if</span> [ `getconf WORD_BIT` = <span class="string">&#x27;32&#x27;</span> ] &amp;&amp; [ `getconf LONG_BIT` = <span class="string">&#x27;64&#x27;</span> ] ; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">return</span> 0</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">return</span> 1</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>getconf</code> 命令获取系统配置变量值 <a href="https://www.ibm.com/support/knowledgecenter/zh/ssw_aix_71/com.ibm.aix.cmds2/getconf.htm">更多信息</a></p>
</blockquote>
<h2 id="获取具体发行版版本">获取具体发行版版本</h2>
<h3 id="awk用法-捕获标准输出作为变量值">awk用法, 捕获标准输出作为变量值</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">get_opsy</span></span>()&#123;</span><br><span class="line">    [ -f /etc/redhat-release ] &amp;&amp; awk <span class="string">&#x27;&#123;print ($1,$3~/^[0-9]/?$3:$4)&#125;&#x27;</span> /etc/redhat-release &amp;&amp; <span class="built_in">return</span></span><br><span class="line">    [ -f /etc/os-release ] &amp;&amp; awk -F<span class="string">&#x27;[= &quot;]&#x27;</span> <span class="string">&#x27;/PRETTY_NAME/&#123;print $3,$4,$5&#125;&#x27;</span> /etc/os-release &amp;&amp; <span class="built_in">return</span></span><br><span class="line">    [ -f /etc/lsb-release ] &amp;&amp; awk -F<span class="string">&#x27;[=&quot;]+&#x27;</span> <span class="string">&#x27;/DESCRIPTION/&#123;print $2&#125;&#x27;</span> /etc/lsb-release &amp;&amp; <span class="built_in">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">debianversion</span></span>()&#123;</span><br><span class="line">    <span class="keyword">if</span> check_sys sysRelease debian;<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">local</span> version=$( get_opsy )</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>AWK</code> 是一种处理文本文件的语言 <code>-F</code> 指定输入文件折分隔符 `<code>[awk的更多例子](http://www.runoob.com/linux/linux-comm-awk.html)</code>/DESCRIPTION/{print $2}<code>用正则表达式匹配</code>DESCRIPTION`字符串，并输出该行第2列的内容</p>
</blockquote>
<p>Example</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat /etc/lsb-release</span></span><br><span class="line">DISTRIB_ID=Ubuntu</span><br><span class="line">DISTRIB_RELEASE=18.04</span><br><span class="line">DISTRIB_CODENAME=bionic</span><br><span class="line">DISTRIB_DESCRIPTION=<span class="string">&quot;Ubuntu 18.04.1 LTS&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># awk -F&#x27;[=&quot;]+&#x27; &#x27;/DESCRIPTION/&#123;print $2&#125;&#x27; /etc/lsb-release</span></span><br><span class="line">Ubuntu 18.04.1 LTS</span><br><span class="line"></span><br><span class="line"><span class="comment"># awk -F&#x27;[=&quot;]+&#x27; &#x27;/DESCRIPTION/&#123;print $1&#125;&#x27; /etc/lsb-release</span></span><br><span class="line">DISTRIB_DESCRIPTION</span><br><span class="line"></span><br><span class="line"><span class="comment"># awk -F&#x27;[=_&quot;]+&#x27; &#x27;/DESCRIPTION/&#123;print $1&#125;&#x27; /etc/lsb-release</span></span><br><span class="line">DISTRIB</span><br></pre></td></tr></table></figure>
<h2 id="获得公网ipv4地址">获得公网IPv4地址</h2>
<h3 id="ip-egrep-wget用法">ip, egrep, wget用法</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">get_ip</span></span>()&#123;</span><br><span class="line">    <span class="built_in">local</span> IP=$( ip addr | egrep -o <span class="string">&#x27;[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;&#x27;</span> | egrep -v <span class="string">&quot;^192\.168|^172\.1[6-9]\.|^172\.2[0-9]\.|^172\.3[0-2]\.|^10\.|^127\.|^255\.|^0\.&quot;</span> | head -n 1 )</span><br><span class="line">    [ -z <span class="variable">$&#123;IP&#125;</span> ] &amp;&amp; IP=$( wget -qO- -t1 -T2 ipv4.icanhazip.com )</span><br><span class="line">    [ -z <span class="variable">$&#123;IP&#125;</span> ] &amp;&amp; IP=$( wget -qO- -t1 -T2 ipinfo.io/ip )</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$&#123;IP&#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>ip</code>命令是网路管理命令，<code>ip addr</code> 查看所有已分配到网络接口的地址 <code>egrep</code> 即等于 <code>grep -E</code> ，使用扩展的正则表达式语法， <code>-o</code> 只输出匹配的行， <code>-v</code> 只输出不匹配的结果</p>
</blockquote>
<ul>
<li><code>egrep -o '[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;'</code> 是匹配出IPv4地址</li>
<li><code>egrep -v "^192\.168|^172\.1[6-9]\.|^172\.2[0-9]\.|^172\.3[0-2]\.|^10\.|^127\.|^255\.|^0\."</code> 过滤掉本地地址，如192.168.1.1</li>
<li><code>[ -z $&#123;IP&#125; ]</code> 如果IP变量为空，该表达式为真，<code>&amp;&amp;</code>后的语句会被执行</li>
</ul>
<blockquote>
<p><code>wget</code>命令用来从指定的URL下载文件 <code>-t</code> 设置下载失败重试最大次数 <code>-T</code> 设置网络超时时间 <code>-q</code> 安静模式 <code>-O-</code> 把结果输出到控制台（把结果输出到标准输出</p>
</blockquote>
<ul>
<li><code>ipv4.icanhazip.com</code>，<code>ipinfo.io/ip</code> 访问这两个网站可以得到公网IP地址</li>
</ul>
<h2 id="获得ipv6地址">获得IPv6地址</h2>
<h3 id="逻辑运算顺序">逻辑运算顺序</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">get_ipv6</span></span>()&#123;</span><br><span class="line">    <span class="built_in">local</span> ipv6=$(wget -qO- -t1 -T2 ipv6.icanhazip.com)</span><br><span class="line">    [ -z <span class="variable">$&#123;ipv6&#125;</span> ] &amp;&amp; <span class="built_in">return</span> 1 || <span class="built_in">return</span> 0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>&amp;&amp;</code>的运算优先级高于<code>||</code> <a href="https://baike.baidu.com/item/%E8%BF%90%E7%AE%97%E7%AC%A6%E4%BC%98%E5%85%88%E7%BA%A7">百度百科</a></p>
</blockquote>
<p>· 所以这句话可写为<code>( $&#123;ipv6&#125;为空 &amp;&amp; 返回1 ) || 返回0</code>，即<code>ipv6</code>变量为空的时候，返回值为1（报错）</p>
<h2 id="下载文件">下载文件</h2>
<h3 id="判断命令执行失败">判断命令执行失败</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">download</span></span>()&#123;</span><br><span class="line">    <span class="built_in">local</span> filename=$(basename <span class="variable">$1</span>)</span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="variable">$&#123;1&#125;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;filename&#125;</span> [found]&quot;</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;filename&#125;</span> not found, download now...&quot;</span></span><br><span class="line">        wget --no-check-certificate -c -t3 -T60 -O <span class="variable">$&#123;1&#125;</span> <span class="variable">$&#123;2&#125;</span></span><br><span class="line">        <span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line">            <span class="built_in">echo</span> -e <span class="string">&quot;[<span class="variable">$&#123;red&#125;</span>Error<span class="variable">$&#123;plain&#125;</span>] Download <span class="variable">$&#123;filename&#125;</span> failed.&quot;</span></span><br><span class="line">            <span class="built_in">exit</span> 1</span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>wget</code>命令, <code>--no-check-certificate</code>不检查HTTPS站点的证书, <code>-c</code> 继续下载之前未完成下载的文件, <code>-O</code> 输出到文件 <code>$?</code>是上个命令的退出状态，或函数的返回值，为0是正常退出，其他值为异常退出 <a href="http://c.biancheng.net/cpp/view/2739.html">更多特殊变量</a></p>
</blockquote>
<h2 id="输入密码不显示字符">输入密码不显示字符</h2>
<h3 id="stty用法">stty用法</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">get_char</span></span>()&#123;</span><br><span class="line">    SAVEDSTTY=$(stty -g)</span><br><span class="line">    stty -<span class="built_in">echo</span></span><br><span class="line">    stty cbreak</span><br><span class="line">    dd <span class="keyword">if</span>=/dev/tty bs=1 count=1 2&gt; /dev/null</span><br><span class="line">    stty -raw</span><br><span class="line">    stty <span class="built_in">echo</span></span><br><span class="line">    stty <span class="variable">$SAVEDSTTY</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>stty</code>命令修改终端命令行的相关设置 <a href="http://man.linuxde.net/stty">更多资料</a> <code>-g</code> 以stty可读方式打印当前的所有配置 <code>-echo</code> 禁止回显 <code>cbreak</code> 开启立即响应 <a href="https://blog.51cto.com/liveforlinux/1153196">参考资料</a> <a href="https://bbs.csdn.net/topics/120065482">立即响应的解释</a> <code>dd if=/dev/tty bs=1 count=1 2&gt;/dev/null</code>则是获取刚刚输入的字符 <a href="http://yaxin-cn.github.io/Linux/replace-password-with-stars-under-shell.html">全解析</a> <code>-raw</code> 不对输入的信息进行处理，如忽略Ctrl+C <a href="https://stackoverflow.com/questions/22832933/what-does-stty-raw-echo-do-on-os-x">更多信息</a></p>
</blockquote>
<ul>
<li>综上，这串代码可以模拟Linux输入密码无回显，但是一次只能读入一个字符，类似于C语言的<code>getchar()</code></li>
</ul>
<h2 id="带异常检测批量安装程序">带异常检测批量安装程序</h2>
<h3 id="字符串数组for循环stderr重定向">字符串数组，for循环，stderr重定向</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">error_detect_depends</span></span>()&#123;</span><br><span class="line">    <span class="built_in">local</span> <span class="built_in">command</span>=<span class="variable">$1</span></span><br><span class="line">    <span class="built_in">local</span> depend=`<span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;command&#125;</span>&quot;</span> | awk <span class="string">&#x27;&#123;print $4&#125;&#x27;</span>`</span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">&quot;[<span class="variable">$&#123;green&#125;</span>Info<span class="variable">$&#123;plain&#125;</span>] Starting to install package <span class="variable">$&#123;depend&#125;</span>&quot;</span></span><br><span class="line">    <span class="variable">$&#123;command&#125;</span> &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">    <span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> -e <span class="string">&quot;[<span class="variable">$&#123;red&#125;</span>Error<span class="variable">$&#123;plain&#125;</span>] Failed to install <span class="variable">$&#123;red&#125;</span><span class="variable">$&#123;depend&#125;</span><span class="variable">$&#123;plain&#125;</span>&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Please visit: https://teddyxxx.com/486.html and contact.&quot;</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">apt_depends=(</span><br><span class="line">    gettext build-essential unzip gzip python python-dev python-setuptools curl openssl libssl-dev</span><br><span class="line">    autoconf automake libtool gcc make perl cpio libpcre3 libpcre3-dev zlib1g-dev libev-dev libc-ares-dev git qrencode</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">apt-get -y update</span><br><span class="line"><span class="keyword">for</span> depend <span class="keyword">in</span> <span class="variable">$&#123;apt_depends[@]&#125;</span>; <span class="keyword">do</span></span><br><span class="line">    error_detect_depends <span class="string">&quot;apt-get -y install <span class="variable">$&#123;depend&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>$&#123;command&#125; &gt; /dev/null 2&gt;&amp;1</code>的<code>2&gt;&amp;1</code>是指把stderr的错误信息重定向到stdout <a href="https://stackoverflow.com/questions/818255/in-the-shell-what-does-21-mean">更多信息</a> <code>$&#123;apt_depends[@]&#125;</code>表示apt_depends内的所有元素 <a href="https://blog.csdn.net/qinglinsan/article/details/9217959">更多信息</a></p>
</blockquote>
<p>Example 测试脚本内容 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apt_depends=(</span><br><span class="line">    gettext build-essential unzip gzip python python-dev python-setuptools curl openssl libssl-dev</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;apt_depends[@]&#125;</span></span><br><span class="line"><span class="keyword">for</span> depend <span class="keyword">in</span> <span class="variable">$&#123;apt_depends[@]&#125;</span>; <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="variable">$&#123;depend&#125;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p>
<p>输出结果 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gettext build-essential unzip gzip python python-dev python-setuptools curl openssl libssl-dev</span><br><span class="line">gettext</span><br><span class="line">build-essential</span><br><span class="line">unzip</span><br><span class="line">gzip</span><br><span class="line">python</span><br><span class="line">python-dev</span><br><span class="line">python-setuptools</span><br><span class="line">curl</span><br><span class="line">openssl</span><br><span class="line">libssl-dev</span><br></pre></td></tr></table></figure></p>
<h2 id="用户输入数字并判断数值是否有效或使用随机数值">用户输入数字，并判断数值是否有效，或使用随机数值</h2>
<h3 id="shuf-if-read用法判断输入为纯数字的方法">shuf, if, read用法，判断输入为纯数字的方法</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">install_prepare_port</span></span>() &#123;</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">true</span></span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">    dport=$(shuf -i 9000-19999 -n 1)</span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">&quot;Please enter a port for <span class="variable">$&#123;software[<span class="variable">$&#123;selected&#125;</span>-1]&#125;</span> [1-65535]&quot;</span></span><br><span class="line">    <span class="built_in">read</span> -p <span class="string">&quot;(Default port: <span class="variable">$&#123;dport&#125;</span>):&quot;</span> shad0wsocksport</span><br><span class="line">    [ -z <span class="string">&quot;<span class="variable">$&#123;shad0wsocksport&#125;</span>&quot;</span> ] &amp;&amp; shad0wsocksport=<span class="variable">$&#123;dport&#125;</span></span><br><span class="line">    expr <span class="variable">$&#123;shad0wsocksport&#125;</span> + 1 &amp;&gt;/dev/null</span><br><span class="line">    <span class="keyword">if</span> [ $? -eq 0 ]; <span class="keyword">then</span></span><br><span class="line">        <span class="keyword">if</span> [ <span class="variable">$&#123;shad0wsocksport&#125;</span> -ge 1 ] &amp;&amp; [ <span class="variable">$&#123;shad0wsocksport&#125;</span> -le 65535 ] &amp;&amp; [ <span class="variable">$&#123;shad0wsocksport:0:1&#125;</span> != 0 ]; <span class="keyword">then</span></span><br><span class="line">            <span class="built_in">echo</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;port = <span class="variable">$&#123;shad0wsocksport&#125;</span>&quot;</span></span><br><span class="line">            <span class="built_in">echo</span></span><br><span class="line">            <span class="built_in">break</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">&quot;[<span class="variable">$&#123;red&#125;</span>Error<span class="variable">$&#123;plain&#125;</span>] Please enter a correct number [1-65535]&quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>shuf</code>命令的用法有很多，这里用来生成随机数 <a href="https://linux.cn/article-9635-1.html">更多用法</a> <code>echo -e</code>可让<code>echo</code>处理字符串内的特殊字符，例如输出<code>\n</code>时换行而不是显示一个斜杠和n <a href="https://unix.stackexchange.com/questions/189787/difference-between-echo-and-echo-e">参考资料</a> <code>expr</code>命令是一个手工命令行计数器，用于在UNIX/LINUX下求表达式变量的值 <a href="http://www.runoob.com/linux/linux-comm-expr.html">更多资料</a></p>
</blockquote>
<ul>
<li>值得注意的是，<code>expr $&#123;shad0wsocksport&#125; + 1 &amp;&gt;/dev/null</code>，这一句话利用了给非数字做加法会报错来判断输入内容是否为纯数字</li>
<li><code>$&#123;shad0wsocksport:0:1&#125;</code>这句的<code>:0:1</code>指获取字符串从0位置起长度为1的子串 <a href="https://stackoverflow.com/questions/21268933/what-means-bash-id01-expression">参考资料</a></li>
</ul>
<h2 id="多选一程序">多选一程序</h2>
<h3 id="for循环-case-while-数组用法">for循环, case, while, 数组用法</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">software=(shad0wsocks-Python shad0wsocksR shad0wsocks-Go shad0wsocks-libev)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">install_select</span></span>()&#123;</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    clear</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">true</span></span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&quot;Which shad0wsocks server you&#x27;d select:&quot;</span></span><br><span class="line">    <span class="keyword">for</span> ((i=1;i&lt;=<span class="variable">$&#123;#software[@]&#125;</span>;i++ )); <span class="keyword">do</span></span><br><span class="line">        hint=<span class="string">&quot;<span class="variable">$&#123;software[$i-1]&#125;</span>&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> -e <span class="string">&quot;<span class="variable">$&#123;green&#125;</span><span class="variable">$&#123;i&#125;</span><span class="variable">$&#123;plain&#125;</span>) <span class="variable">$&#123;hint&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">    <span class="built_in">read</span> -p <span class="string">&quot;Please enter a number (Default <span class="variable">$&#123;software[0]&#125;</span>):&quot;</span> selected</span><br><span class="line">    [ -z <span class="string">&quot;<span class="variable">$&#123;selected&#125;</span>&quot;</span> ] &amp;&amp; selected=<span class="string">&quot;1&quot;</span></span><br><span class="line">    <span class="keyword">case</span> <span class="string">&quot;<span class="variable">$&#123;selected&#125;</span>&quot;</span> <span class="keyword">in</span></span><br><span class="line">        1|2|3|4)</span><br><span class="line">        <span class="built_in">echo</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;You choose = <span class="variable">$&#123;software[<span class="variable">$&#123;selected&#125;</span>-1]&#125;</span>&quot;</span></span><br><span class="line">        <span class="built_in">echo</span></span><br><span class="line">        <span class="built_in">break</span></span><br><span class="line">        ;;</span><br><span class="line">        *)</span><br><span class="line">        <span class="built_in">echo</span> -e <span class="string">&quot;[<span class="variable">$&#123;red&#125;</span>Error<span class="variable">$&#123;plain&#125;</span>] Please only enter a number [1-4]&quot;</span></span><br><span class="line">        ;;</span><br><span class="line">    <span class="keyword">esac</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>$&#123;\#software\[@\]&#125;</code>可获取数组长度 <a href="https://unix.stackexchange.com/questions/80803/array-vs-array">更多写法</a></li>
<li><code>case "$&#123;selected&#125;" in 1|2|3|4)</code>指让<code>selected</code>这个变量匹配1-4的数字范围 <a href="https://stackoverflow.com/questions/25481799/how-to-make-case-statement-match-a-number-range/25482040#25482040">更多写法</a></li>
<li><code>*)</code>相当于<code>default</code>, <code>;;</code>标志着语块的结束 <a href="https://blog.csdn.net/guodongxiaren/article/details/39758457">更多写法</a></li>
</ul>
<h2 id="脚本输出配置文件">脚本输出配置文件</h2>
<h3 id="cat-eof用法">cat, EOF用法</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &gt; <span class="variable">$&#123;shad0wsocks_python_config&#125;</span>&lt;&lt;-<span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    &quot;server&quot;:&quot;0.0.0.0&quot;,</span></span><br><span class="line"><span class="string">    &quot;server_port&quot;:$&#123;shad0wsocksport&#125;,</span></span><br><span class="line"><span class="string">    &quot;local_address&quot;:&quot;127.0.0.1&quot;,</span></span><br><span class="line"><span class="string">    &quot;local_port&quot;:1080,</span></span><br><span class="line"><span class="string">    &quot;password&quot;:&quot;$&#123;shad0wsockspwd&#125;&quot;,</span></span><br><span class="line"><span class="string">    &quot;timeout&quot;:300,</span></span><br><span class="line"><span class="string">    &quot;method&quot;:&quot;$&#123;shad0wsockscipher&#125;&quot;,</span></span><br><span class="line"><span class="string">    &quot;fast_open&quot;:$&#123;fast_open&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>
<blockquote>
<blockquote>
<p><code>cat &lt;&lt; EOF</code>是Here Document相关语句，Here Document是在Linux Shell 中的一种特殊的重定向方式，它的作用就是将两个delimiter (EOF) 之间的内容 (Here Document Content部分) 传递给程序 (cat) 作为输入参数 <a href="https://my.oschina.net/u/1032146/blog/146941">更多信息</a> 如果重定向的操作符是<code>&lt;&lt;-</code>，那么分界符(EOF)所在行的开头部分的制表符(Tab)都将被去除 <a href="https://blog.51cto.com/13566681/2072434">更多信息</a></p>
</blockquote>
</blockquote>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>神威太湖之光 样例代码分析</title>
    <url>/2019/06/20/%E7%A5%9E%E5%A8%81%E5%A4%AA%E6%B9%96%E4%B9%8B%E5%85%89-%E6%A0%B7%E4%BE%8B%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="example-1-mpi-athread-clang">Example 1: MPI-Athread Clang</h1>
<h2 id="master.c">master.c：</h2>
<h3 id="定义计算规模">定义计算规模</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#define J 64</span><br><span class="line">#define I 1000</span><br></pre></td></tr></table></figure>
<h3 id="声明从核函数">声明从核函数</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">extern</span> <span class="title">SLAVE_FUN</span><span class="params">(func)</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这一句对应<code>slave.c</code>中的 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">()</span> </span>&#123;...&#125; ```</span><br><span class="line"></span><br><span class="line">### 创建数组</span><br><span class="line"></span><br><span class="line">```c</span><br><span class="line"><span class="keyword">double</span> a[J][I], b[J][I], c[J][I], cc[J][I];</span><br><span class="line"><span class="keyword">double</span> check[J];</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> counter[J];</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>因为这个程序运行在主核上，声明变量无修饰，故该数组实际存放在<code>用户共享连续</code>空间中<a href="http://tonny.icu/2019/06/19/%E7%A5%9E%E5%A8%81%E5%A4%AA%E6%B9%96%E4%B9%8B%E5%85%89-%E5%86%85%E5%AD%98%E5%AD%90%E7%B3%BB%E7%BB%9F/">更多信息</a></p>
</blockquote>
<h3 id="获取当前时间">获取当前时间</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="title">rpcc</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">long</span> time;</span><br><span class="line">        <span class="keyword">asm</span>(<span class="string">&quot;rtc %0&quot;</span></span><br><span class="line">            : <span class="string">&quot;=r&quot;</span>(time)</span><br><span class="line">            :);</span><br><span class="line">        <span class="keyword">return</span> time;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这是一段内联汇编的炫技代码，看看就好了，反正申威也没给指令手册</p>
<h3 id="初始化mpi环境">初始化MPI环境</h3>
<p>跳过一段变量的定义，看到main函数里</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">int</span> myid, numprocs;</span><br><span class="line"></span><br><span class="line">        MPI_Init(&amp;argc, &amp;argv);</span><br><span class="line">        MPI_Comm_size(MPI_COMM_WORLD, &amp;numprocs);</span><br><span class="line">        MPI_Comm_rank(MPI_COMM_WORLD, &amp;myid);</span><br></pre></td></tr></table></figure>
<p>主核输出信息，并刷新缓冲区保证文字能被显示</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123; ...</span><br><span class="line">        <span class="keyword">if</span> (myid == <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;!!!!!! C-EXAMPLE TOTAL PROCS is %d !!!!!!\n&quot;</span>, numprocs);</span><br><span class="line">                fflush(<span class="literal">NULL</span>);</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<h3 id="初始化a和b数组">初始化a和b数组</h3>
<blockquote>
<p><code>master.c</code>中定义全局变量 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> a[J][I], b[J][I], c[J][I], cc[J][I]; ```</span><br><span class="line"></span><br><span class="line">```<span class="function">c</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123; ...</span><br><span class="line"><span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; J; j++)</span><br><span class="line">               <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; I; i++)</span><br><span class="line">               &#123;</span><br><span class="line">                       a[j][i] = (i + j + <span class="number">0.5</span>);</span><br><span class="line">                       b[j][i] = (i + j + <span class="number">1.0</span>);</span><br><span class="line">               &#125;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h3 id="串行计算并统计时间">串行计算，并统计时间</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123; ...</span><br><span class="line">        st = rpcc();</span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; J; j++)</span><br><span class="line">                <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; I; i++)</span><br><span class="line">                &#123;</span><br><span class="line">                        cc[j][i] = (a[j][i]) / (b[j][i]);</span><br><span class="line">                &#125;</span><br><span class="line">        ed = rpcc();</span><br></pre></td></tr></table></figure>
<h3 id="并行计算部分">并行计算部分</h3>
<p>好了，关键的部分开始了</p>
<ul>
<li>初始化Athread库</li>
<li>使用从核进行计算</li>
<li>等待从核计算完毕</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123; ...</span><br><span class="line">        athread_init();</span><br><span class="line">        </span><br><span class="line">        st = rpcc();</span><br><span class="line"></span><br><span class="line">        athread_spawn(func, <span class="number">0</span>);</span><br><span class="line">        athread_join();</span><br><span class="line"></span><br><span class="line">        ed = rpcc();</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>athread_spawn</code>创建线程组</p>
<p>参数说明: <code>start_routine fpc</code>函数指针 <code>void * arg</code>函数 <code>f</code> 的参数起始地址</p>
</blockquote>
<p>因为<code>fun</code>没有参数，干脆指定个0</p>
<blockquote>
<p><code>athread_join</code>等待线程组终止</p>
</blockquote>
<blockquote>
<p>在<code>slave.c</code>中, <code>func</code>的定义如下 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">       ...</span><br><span class="line">       my_id = athread_get_id(<span class="number">-1</span>);</span><br><span class="line">       athread_get(...&amp;a[my_id][<span class="number">0</span>], &amp;a_slave[<span class="number">0</span>]...);</span><br><span class="line">       athread_get(...&amp;b[my_id][<span class="number">0</span>], &amp;b_slave[<span class="number">0</span>]...);</span><br><span class="line">       ...</span><br><span class="line">       <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; I; i++)</span><br><span class="line">       &#123;</span><br><span class="line">               c_slave[i] = a_slave[i] / b_slave[i];</span><br><span class="line">       &#125;</span><br><span class="line">       ...</span><br><span class="line">       athread_put(...&amp;c_slave[<span class="number">0</span>], &amp;c[my_id][<span class="number">0</span>]..);</span><br><span class="line">&#125; ```</span><br><span class="line"></span><br><span class="line">很显然，计算的工作被全部抛给了从核</span><br><span class="line"></span><br><span class="line">### 计算Checksum</span><br><span class="line"></span><br><span class="line">```<span class="function">c</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123; ...</span><br><span class="line">       checksum = <span class="number">0.0</span>;</span><br><span class="line">       checksum2 = <span class="number">0.0</span>;</span><br><span class="line">       <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; J; j++)</span><br><span class="line">               <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; I; i++)</span><br><span class="line">               &#123;</span><br><span class="line">                       checksum = checksum + c[j][i];</span><br><span class="line">                       checksum2 = checksum2 + cc[j][i];</span><br><span class="line">               &#125;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h3 id="关闭mpi-athread环境">关闭MPI Athread环境</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123; ...</span><br><span class="line">        athread_halt();</span><br><span class="line">        MPI_Finalize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="slave.c">slave.c</h2>
<h3 id="变量声明">变量声明</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">__thread_local <span class="keyword">volatile</span> <span class="keyword">unsigned</span> <span class="keyword">long</span> get_reply, put_reply;</span><br><span class="line">__thread_local <span class="keyword">volatile</span> <span class="keyword">unsigned</span> <span class="keyword">long</span> start, end;</span><br><span class="line"></span><br><span class="line">__thread_local <span class="keyword">int</span> my_id;</span><br><span class="line"></span><br><span class="line">__thread_local <span class="keyword">double</span> a_slave[I], b_slave[I], c_slave[I];</span><br></pre></td></tr></table></figure>
<blockquote>
<p>声明<code>volatile</code>的变量可能指向一个随时都能被计算机系统其他部分修改的地址，例如一个连接到中央处理器的设备的硬件寄存器，上面的代码永远检测不到这样的修改。如果不使用<code>volatile</code>关键字，编译器将假设当前程序是系统中唯一能改变这个值部分（这是到目前为止最广泛的一种情况）。 为了阻止编译器像上面那样优化代码，需要使用<code>volatile</code>关键字 <a href="https://zh.wikipedia.org/wiki/Volatile%E5%8F%98%E9%87%8F">更多信息</a></p>
</blockquote>
<blockquote>
<p><code>__thread_local</code>指把变量扔到LDM里(Scratch Pad Memory) <a href="http://tonny.icu/2019/06/19/%E7%A5%9E%E5%A8%81%E5%A4%AA%E6%B9%96%E4%B9%8B%E5%85%89-%E5%86%85%E5%AD%98%E5%AD%90%E7%B3%BB%E7%BB%9F/">更多信息</a></p>
</blockquote>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="keyword">double</span> a[J][I], b[J][I], c[J][I];</span><br><span class="line"><span class="keyword">extern</span> <span class="keyword">unsigned</span> <span class="keyword">long</span> counter[<span class="number">64</span>];</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在<code>master.c</code>中声明了a,b,c数组 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> a[J][I], b[J][I], c[J][I], cc[J][I];</span><br><span class="line"><span class="keyword">double</span> check[J];</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> counter[J]; ```</span><br><span class="line"></span><br><span class="line">[Extern关键字的更多信息](https:<span class="comment">//zh.wikipedia.org/wiki/%E5%A4%96%E9%83%A8%E5%8F%98%E9%87%8F)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 从主存中分割数据并储存到LDM</span><br><span class="line"></span><br><span class="line">```c</span><br><span class="line"><span class="keyword">void</span> func()</span><br><span class="line">&#123;</span><br><span class="line">       <span class="keyword">int</span> i, j;</span><br><span class="line"></span><br><span class="line">       my_id = athread_get_id(<span class="number">-1</span>);</span><br><span class="line"></span><br><span class="line">       get_reply = <span class="number">0</span>;</span><br><span class="line">       athread_get(PE_MODE, &amp;a[my_id][<span class="number">0</span>], &amp;a_slave[<span class="number">0</span>], I * <span class="number">8</span>, &amp;get_reply, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">       athread_get(PE_MODE, &amp;b[my_id][<span class="number">0</span>], &amp;b_slave[<span class="number">0</span>], I * <span class="number">8</span>, &amp;get_reply, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">       </span><br><span class="line">       <span class="keyword">while</span>(get_reply!=<span class="number">2</span>);</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p><code>athread_get_id</code>获得线程逻辑标识号</p>
</blockquote>
<blockquote>
<p><code>athread_get</code>运算核心<code>局存LDM</code>接收<code>主存MEM</code>数据</p>
<p>参数说明: <code>dma_mode mode</code>DMA<code>传输命令模式</code>； <code>void *src</code>DMA传输<code>主存源地址</code>； <code>void *dest</code>DMA传输<code>本地局存目标地址</code>； <code>int len</code>DMA传输<code>数据量</code>，以字节为单位； <code>void *reply</code>DMA传输<code>回答字地址</code>，必须为局存地址，地址4B对界； <code>char mask</code>DMA传输<code>广播有效向量</code>，有效粒度为核组中<code>一行</code>，某位为<code>1</code>表示对应的<code>行传输有效</code>，作用于<code>广播模式</code>和<code>广播行模式</code>； <code>int stride</code>主存<code>跨步</code>，以字节为单位； <code>int bsize</code>行集合模式下，必须配置，用于指示在每个运算核心上的<code>数据粒度大小</code>；其它模式下，在DMA跨步传输时有效，表示DMA传输的跨步向量块大小，以字节为单位。</p>
</blockquote>
<p><a href="http://tonny.icu/2019/06/19/%E7%A5%9E%E5%A8%81%E5%A4%AA%E6%B9%96%E4%B9%8B%E5%85%89-%E5%86%85%E5%AD%98%E5%AD%90%E7%B3%BB%E7%BB%9F/">关于DMA模式的更多信息</a></p>
<p>这里可以看出来，DMA传输用了最简单的<code>PE_MODE</code>，也就是自己单干，传输的时候不管其他从核的模式，只把主存上的两行数据(a, b各一行)复制到LDM上。</p>
<p><code>I*8</code>，其实就是因为a, b是double类型的，double是64bit长，也就是8byte长，<code>I*8</code>就是一行double(I个变量)实际占用的空间(byte为单位)</p>
<p>最后一句的<code>get_reply</code>，实际上是DMA传输完成后会给<code>get_reply</code>自动加上1，这个while循环就是在等待DMA传输完成</p>
<h3 id="计算部分">计算部分</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">()</span> </span>&#123; ...</span><br><span class="line">        <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;I;i++)&#123;</span><br><span class="line">                c_slave[i]=a_slave[i]/b_slave[i];</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>这里没啥好看的</p>
<h3 id="把计算结果传回主存">把计算结果传回主存</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">()</span> </span>&#123; ...</span><br><span class="line">        put_reply=<span class="number">0</span>;</span><br><span class="line">        athread_put(PE_MODE,&amp;c_slave[<span class="number">0</span>],&amp;c[my_id][<span class="number">0</span>],I*<span class="number">8</span>,&amp;put_reply,<span class="number">0</span>,<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">while</span>(put_reply!=<span class="number">1</span>);	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>athread_put</code>运算核心<code>局存LDM</code>往<code>主存MEM</code>发送数据，不支持<code>广播模式</code>和<code>广播行模式</code></p>
<p>参数说明: <code>dma_mode mode</code>DMA<code>传输命令模式</code>； <code>void *src</code>DMA传输<code>主存源地址</code>； <code>void *dest</code>DMA传输<code>本地局存目标地址</code>； <code>int len</code>DMA传输<code>数据量</code>，以字节为单位； <code>void *reply</code>DMA传输<code>回答字地址</code>，必须为局存地址，地址4B对界； <code>char mask</code>DMA传输<code>广播有效向量</code>，有效粒度为核组中<code>一行</code>，某位为<code>1</code>表示对应的<code>行传输有效</code>，作用于<code>广播模式</code>和<code>广播行模式</code>； <code>int stride</code>主存<code>跨步</code>，以字节为单位； <code>int bsize</code>行集合模式下，必须配置，用于指示在每个运算核心上的<code>数据粒度大小</code>；其它模式下，在DMA跨步传输时有效，表示DMA传输的跨步向量块大小，以字节为单位。</p>
</blockquote>
<p>这参数表其实是一样的，<code>put_reply</code>，因为只有一次DMA操作，所以只需要等待到其值为1的时候</p>
<h3 id="编译命令">编译命令</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sw5cc -host -I/usr/sw-mpp/mpi2/include -c master.c</span><br><span class="line">sw5cc -slave -c slave.c</span><br><span class="line">mpicc master.o slave.o -o example-c</span><br></pre></td></tr></table></figure>
<p>注意主从核程序分开编译，然后用mpicc链接(ld乙烷)</p>
<h3 id="提交运行">提交运行</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bsub -b -I -q q_sw_expr -n 2 -cgsp 64 -host_stack 256 -share_size 4096 ./example-c</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>-I</code>选项表示提交交互式作业，使作业输出在作业提交窗口； <code>-b</code>表示从核函数栈变量放在从核局部存储上，该选项为获取加速性能必须的提交选项； <code>-q</code>向指定的队列中提交作业； <code>-n</code>指定需要的所有主核数； <code>-cgsp</code>指定每个核组内需要的从核个数，指定时该参数必须&lt;=64； <code>-share_size</code>指定核组共享空间大小，一般最大可以用到7600MB； <code>-host_stack</code>指定主核栈空间大小，默认为8M，一般设置为128MB以上。</p>
</blockquote>
<h1 id="example-2-mpi-athread-c">Example 2: MPI-Athread C++</h1>
<h2 id="master.c-1">master.c</h2>
<p>其实这个与Example 1的区别不大</p>
<h3 id="约定从核函数接口">约定从核函数接口</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> &#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;athread.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">slave_func</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>extern "C"的真实目的是实现类C和C++的混合编程。在C++源文件中的语句前面加上extern "C"，表明它按照类C的编译和连接规约来编译和连接，而不是C++的编译的连接规约。这样在类C的代码中就可以调用C++的函数or变量等。 <a href="https://www.cnblogs.com/skynet/archive/2010/07/10/1774964.html">更多信息</a></p>
</blockquote>
<h3 id="并行计算部分-1">并行计算部分</h3>
<blockquote>
<p>Example 1下面这句代码 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line">athread_spawn(func, <span class="number">0</span>); ```</span><br><span class="line"></span><br><span class="line">被替换成了</span><br><span class="line"></span><br><span class="line">```c</span><br><span class="line">__real_athread_spawn((<span class="keyword">void</span> *)slave_func,<span class="number">0</span>);</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="slave.c-1">slave.c</h2>
<p>因为从核只支持C语言，所以这里的<code>slave.c</code>文件内容其实和Example 1是一样的</p>
<h2 id="编译命令-1">编译命令</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sw5CC -host -I/usr/sw-mpp/mpi2/include -c master.cpp</span><br><span class="line">sw5cc -slave -c slave.c</span><br><span class="line">mpiCC master.o slave.o -lstdc++ -o example-cpp</span><br></pre></td></tr></table></figure>
<p>注意一个坑爹的地方，在神威上，cc指C语言编译器，CC是C++的编译器，嗯就是大小写的区别</p>
<h2 id="提交命令">提交命令</h2>
<p>一样一样的，就是这次要运行example-cpp文件而不是example-c</p>
<h1 id="example-4-mpi-athread-allshare">Example 4: MPI-Athread Allshare</h1>
<p>Example 3是Fortran，暂时跳过不看</p>
<h2 id="master.c-2">master.c</h2>
<h3 id="定义数据规模">定义数据规模</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> DIM_I 1024 </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> DIM_J 1024</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> DIM_K 512</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> J 64</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> I 1000</span></span><br></pre></td></tr></table></figure>
<h3 id="声明变量和接口">声明变量和接口</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> a1[J][I], b1[J][I], c1[J][I], cc1[J][I];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">long</span> *a, *b, *c, *d;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">long</span> sum_total, size1;</span><br><span class="line">        ...</span><br><span class="line">        <span class="function"><span class="keyword">extern</span> <span class="keyword">void</span> <span class="title">slave_func</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>
<h3 id="分配初始化内存空间">分配&amp;初始化内存空间</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123; ...</span><br><span class="line">        size1 = DIM_I * DIM_J * DIM_K;</span><br><span class="line">        a = (<span class="keyword">unsigned</span> <span class="keyword">long</span> *)<span class="built_in">malloc</span>(size1 * <span class="keyword">sizeof</span>(<span class="keyword">unsigned</span> <span class="keyword">long</span>));</span><br><span class="line">        b = (<span class="keyword">unsigned</span> <span class="keyword">long</span> *)<span class="built_in">malloc</span>(size1 * <span class="keyword">sizeof</span>(<span class="keyword">unsigned</span> <span class="keyword">long</span>));</span><br><span class="line">        c = (<span class="keyword">unsigned</span> <span class="keyword">long</span> *)<span class="built_in">malloc</span>(size1 * <span class="keyword">sizeof</span>(<span class="keyword">unsigned</span> <span class="keyword">long</span>));</span><br><span class="line">        d = (<span class="keyword">unsigned</span> <span class="keyword">long</span> *)<span class="built_in">malloc</span>(size1 * <span class="keyword">sizeof</span>(<span class="keyword">unsigned</span> <span class="keyword">long</span>));</span><br></pre></td></tr></table></figure>
<p>size1 = 512M</p>
<p>sizeof(ulong) = 8Byte</p>
<p>a, b, c, d每个分配512M*8B=4GB的内存，属实嚣张</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123; ...</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; size1; i++)</span><br><span class="line">        &#123;</span><br><span class="line">                a[i] = <span class="number">1</span>;</span><br><span class="line">                b[i] = <span class="number">2</span>;</span><br><span class="line">                c[i] = <span class="number">3</span>;</span><br><span class="line">                d[i] = <span class="number">4</span>;</span><br><span class="line">                sum_total = sum_total + a[i] + b[i] / <span class="number">2</span> + c[i] / <span class="number">3</span> + d[i] / <span class="number">4</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        sum_total = sum_total / <span class="number">4</span>;</span><br></pre></td></tr></table></figure>
<p>a, b, c, d全部初始化为1, 2, 3, 4, 然后<code>sum_total</code>统计4个数组总共有多少个变量，除4就意味着1个数组有多少个变量</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123; ...</span><br><span class="line">        <span class="keyword">if</span> (sum_total == size1)</span><br><span class="line">        &#123;</span><br><span class="line">                size1 = <span class="number">4</span> * <span class="number">8</span> * size1 / (<span class="number">1024</span> * <span class="number">1024</span> * <span class="number">1024</span>);                        <span class="comment">/* a/b/c/d size is 4GB(8*512*1024*1024)*/</span></span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;Process %d Memery size is more than: %dGB \n&quot;</span>, myid, size1); <span class="comment">/*total size is 4*4GB=16GB*/</span></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>不太清楚为什么要比较<code>sum_total</code>和<code>size1</code>，这两个应该是一样的啊，否则就Rumtime Error了</p>
<h3 id="等待其他mpi线程完成初始化">等待其他MPI线程完成初始化</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123; ...</span><br><span class="line">        MPI_Barrier(MPI_COMM_WORLD);</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>MPI_Barrier</code>阻塞线程，直到Communicator范围内所有线程都执行完Barrier前的程序<a href="https://www.mpich.org/static/docs/latest/www3/MPI_Barrier.html">更多信息</a></p>
</blockquote>
<p>说起来你可能不信，下面的程序和Example 1真的是一毛一样，也就是说创建的abcd数组没有任何luan用，这个程序大概就是告诉你如何开这么大的内存空间</p>
<h1 id="example-5-mpi-athread-allshare-master">Example 5: MPI-Athread Allshare-Master</h1>
<p>不说了，这个其实就是给MPI第0线程开了个比其他线程都大的数组，其他和Example 4都是一样的</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>HPC</tag>
      </tags>
  </entry>
  <entry>
    <title>神威太湖之光 系统分析</title>
    <url>/2019/06/19/%E7%A5%9E%E5%A8%81%E5%A4%AA%E6%B9%96%E4%B9%8B%E5%85%89-%E7%B3%BB%E7%BB%9F%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="内存子系统">内存子系统</h1>
<h2 id="推荐阅读">0. 推荐阅读</h2>
<p><a href="https://miraclezqc.github.io/2018/10/25/Sunway-Taihu-Optimization/">Sunway-Taihu-Optimization</a></p>
<p><a href="https://miraclezqc.github.io/2018/11/16/ATHREAD/">Athread</a></p>
<h2 id="神威太湖之光简介">1. 神威太湖之光简介</h2>
<ul>
<li>每个节点有2片SW26010处理器</li>
<li>每片SW26010有4个CGs(核组, Core-Groups)</li>
<li>每个CG有1个MPE(主核, 运算控制核心, Management Processing Element)</li>
<li>每个CG有8x8=64个CPEs(从核, 运算核心, Computing Processing Elements)</li>
</ul>
<p>讲道理这SW26010确实像把4片PS3上的IBM Cell处理器用胶水糊在了一起</p>
<h2 id="cache">2. Cache</h2>
<p>主核存储系统：</p>
<table>
<thead>
<tr class="header">
<th>存储器</th>
<th>容量</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>L1 Cache</td>
<td>指令32KB 数据32KB</td>
</tr>
<tr class="even">
<td>L2 Cache</td>
<td>512KB</td>
</tr>
</tbody>
</table>
<p>从核存储系统：</p>
<table>
<thead>
<tr class="header">
<th>存储器</th>
<th>容量</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>L1 Cache</td>
<td>指令16KB</td>
</tr>
<tr class="even">
<td>L2 Cache</td>
<td>CG内共享指令64KB</td>
</tr>
<tr class="odd">
<td>Scratch Pad Memory</td>
<td>64KB</td>
</tr>
</tbody>
</table>
<p>这SPM真的是和Cell处理器一毛一样了，现在我也能感受PS3开发者的恐惧了www</p>
<p>PS: cache是由硬件控制，对程序员不可见，其实我们只需要榨干Scratch Pad Memory</p>
<h2 id="访存延迟">3. 访存延迟</h2>
<table>
<thead>
<tr class="header">
<th>项目</th>
<th>Cycle</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>主核到L1</td>
<td>4</td>
</tr>
<tr class="even">
<td>主核到L2</td>
<td>13</td>
</tr>
<tr class="odd">
<td>主核到主存</td>
<td>154</td>
</tr>
<tr class="even">
<td>主核到LDM</td>
<td>94</td>
</tr>
<tr class="odd">
<td>从核到主存</td>
<td>177-278</td>
</tr>
<tr class="even">
<td>从核到自己的LDM</td>
<td>4</td>
</tr>
<tr class="odd">
<td>从核到其他核的LDM</td>
<td>10</td>
</tr>
<tr class="even">
<td>LDM到主存(DMA方式)</td>
<td>25</td>
</tr>
<tr class="odd">
<td>从核行广播</td>
<td>14</td>
</tr>
<tr class="even">
<td>从核列广播</td>
<td>14</td>
</tr>
</tbody>
</table>
<p>官网的文档，直接说，这部分的描述就是一坨狗屎，还好找到了<a href="http://bbs.nsccwx.cn/assets/uploads/files/1528120200586-cpc%E5%9F%B9%E8%AE%AD_%E7%A5%9E%E5%A8%81%E5%A4%AA%E6%B9%96%E4%B9%8B%E5%85%89%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B%E4%B8%8E%E4%B8%8A%E6%9C%BA%E5%AE%9E%E8%B7%B5.pdf">CPC2018的培训资料</a></p>
<h2 id="存储模型">4. 存储模型</h2>
<blockquote>
<p>SW26010运算核心的用户虚空间分为<code>LDM空间</code>和<code>主存空间</code>，<code>主存空间</code>进一步可以分为<code>系统区</code>、<code>用户连续区</code>和<code>用户交叉区</code>。</p>
</blockquote>
<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th>虚空间内存地址</th>
<th>主核</th>
<th>从核</th>
<th>C语言修饰</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0x00 0000 0000</td>
<td>系统连续(可Cache)</td>
<td>LDM空间</td>
<td><code>__thread_local</code> <code>__thread</code> <code>__thread_local_fix</code> <code>__thread_local_kernel</code></td>
</tr>
<tr class="even">
<td>0x20 0000 0000</td>
<td>用户私有连续(可Cache)</td>
<td>用户私有连续</td>
<td><code>__thread</code></td>
</tr>
<tr class="odd">
<td>0x4F F000 0000</td>
<td>用户共享连续(可Cache)(只读)</td>
<td>用户共享连续(只读)</td>
<td><code>不加修饰</code></td>
</tr>
<tr class="even">
<td>0x50 0000 0000</td>
<td>用户共享连续(可Cache)(读写)</td>
<td>用户共享连续(读写)</td>
<td><code>不加修饰</code></td>
</tr>
<tr class="odd">
<td>0x60 0000 0000</td>
<td>用户共享交叉(不可Cache)</td>
<td>用户共享交叉</td>
<td><code>__thread_group</code></td>
</tr>
<tr class="even">
<td>0x80 0000 0000</td>
<td>核组IO空间</td>
<td>?</td>
<td>?</td>
</tr>
<tr class="odd">
<td>0xA0 0000 0000</td>
<td>芯片IO空间</td>
<td>?</td>
<td>?</td>
</tr>
</tbody>
</table>
<h3 id="openacc内存模型">OpenACC内存模型：</h3>
<table>
<thead>
<tr class="header">
<th>空间名称</th>
<th>存储位置</th>
<th>OpenACC修饰</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>主线程数据空间</td>
<td>主存</td>
<td>加速区外定义的变量</td>
</tr>
<tr class="even">
<td>加速线程私有空间</td>
<td>主存</td>
<td><code>private</code> <code>firstprivate</code></td>
</tr>
<tr class="odd">
<td>加速线程本地空间</td>
<td>LDM</td>
<td><code>local</code> <code>copy</code> 等</td>
</tr>
</tbody>
</table>
<h2 id="dma">5. DMA</h2>
<h3 id="dma命令模式">DMA命令模式</h3>
<table>
<thead>
<tr class="header">
<th>命令模式</th>
<th>代码</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>单运算核心模式</td>
<td><code>PE_MODE</code></td>
</tr>
<tr class="even">
<td>广播模式</td>
<td><code>BCAST_MODE</code></td>
</tr>
<tr class="odd">
<td>行模式</td>
<td><code>ROW_MODE</code></td>
</tr>
<tr class="even">
<td>广播行模式</td>
<td><code>BROW_MODE</code></td>
</tr>
<tr class="odd">
<td>行集合模式</td>
<td><code>RANK_MODE</code></td>
</tr>
</tbody>
</table>
<p>好了官方文档的作者估计写到这里饿了，又开始写得不清不楚了，还好我大Google帮我找到了<a href="http://bbs.nsccwx.cn/assets/uploads/files/1529047771770-%E7%A5%9E%E5%A8%81%E5%A4%AA%E6%B9%96%E4%B9%8B%E5%85%89%E9%AB%98%E7%BA%A7%E8%BF%9B%E9%98%B6.pdf">高级优化技术进阶</a></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>HPC</tag>
      </tags>
  </entry>
  <entry>
    <title>神威太湖之光上机摸索记录</title>
    <url>/2020/05/25/%E7%A5%9E%E5%A8%81%E5%A4%AA%E6%B9%96%E4%B9%8B%E5%85%89%E4%B8%8A%E6%9C%BA%E6%91%B8%E7%B4%A2%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h2 id="cpu端序">CPU端序</h2>
<p>sw26010和x86一样都是小端序。测试程序如下，输出均为1</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">is_little_endian</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="keyword">short</span> s = <span class="number">0x0110</span>;</span><br><span class="line">   <span class="keyword">char</span> *p = (<span class="keyword">char</span> *) &amp;s;</span><br><span class="line">   <span class="keyword">return</span> (p[<span class="number">0</span>] == <span class="number">0x10</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, is_little_endian() );</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="编译相关">编译相关</h2>
<h3 id="输出头文件路径">输出头文件路径</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> | sw5cc -host -E -Wp,-v -</span><br><span class="line"><span class="built_in">echo</span> | sw5cc -slave -E -Wp,-v -</span><br></pre></td></tr></table></figure>
<h3 id="关键的头文件路径">关键的头文件路径</h3>
<ul>
<li><code>/usr/sw-mpp/swcc/lib/gcc-lib/sw_64-swcc-linux/5.421-sw-500/include</code> 包含<code>SIMD</code>，<code>DMA</code>相关函数</li>
<li><code>/usr/sw-mpp/swcc/sw5gcc-binary/include</code> 包含<code>LDM</code>，<code>FFT</code>，<code>Athread</code>相关函数</li>
</ul>
<h2 id="调试相关">调试相关</h2>
<h3 id="作业系统">作业系统</h3>
<h4 id="设置log-level">设置Log Level</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">RMS_DEBUG=7</span><br></pre></td></tr></table></figure>
<h2 id="system相关">System相关</h2>
<p>x86节点系统：<code>Red Hat Enterprise Linux Server release 6.6</code> sw节点系统：<code>RaiseOS</code></p>
<h3 id="raiseos">RaiseOS</h3>
<p>大家都觉得这系统应该跟Busybox构建的rootfs差不多，也就是说整个申威节点就是大号开发板。下面是申威节点上某时刻的进程列表。顺带一提，这系统连<code>bash</code>都没有。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PID   USER     TIME   COMMAND</span><br><span class="line">    1 root       0:16 init</span><br><span class="line">    2 root       0:00 [kthreadd]</span><br><span class="line">    3 root       0:00 [ksoftirqd/0]</span><br><span class="line">    5 root       0:00 [kworker/0:0H]</span><br><span class="line">    6 root       0:00 [kworker/u:0]</span><br><span class="line">    7 root       0:00 [kworker/u:0H]</span><br><span class="line">    8 root       0:00 [migration/0]</span><br><span class="line">    9 root       0:00 [rcu_bh]</span><br><span class="line">   10 root       0:26 [rcu_sched]</span><br><span class="line">   11 root       0:00 [ksoftirqd/4]</span><br><span class="line">   12 root       0:02 [migration/4]</span><br><span class="line">   13 root       0:00 [kworker/4:0]</span><br><span class="line">   14 root       0:00 [kworker/4:0H]</span><br><span class="line">   15 root       0:00 [ksoftirqd/8]</span><br><span class="line">   16 root       0:00 [migration/8]</span><br><span class="line">   17 root       0:00 [kworker/8:0]</span><br><span class="line">   18 root       0:00 [kworker/8:0H]</span><br><span class="line">   19 root       0:00 [ksoftirqd/12]</span><br><span class="line">   20 root       0:00 [migration/12]</span><br><span class="line">   21 root       0:00 [kworker/12:0]</span><br><span class="line">   22 root       0:00 [kworker/12:0H]</span><br><span class="line">   23 root       0:00 [cpuset]</span><br><span class="line">   24 root       0:00 [khelper]</span><br><span class="line">   25 root       0:00 [netns]</span><br><span class="line">   26 root       0:00 [bdi-default]</span><br><span class="line">   27 root       0:00 [kblockd]</span><br><span class="line">   28 root       0:00 [rpciod]</span><br><span class="line">   29 root       0:06 [kworker/12:1]</span><br><span class="line">   30 root       0:01 [kswapd0]</span><br><span class="line">   31 root       0:00 [kswapd1]</span><br><span class="line">   32 root       0:00 [kswapd2]</span><br><span class="line">   33 root       0:00 [kswapd3]</span><br><span class="line">   34 root       0:00 [nfsiod]</span><br><span class="line">   35 root       0:00 [mlx4]</span><br><span class="line">   36 root       0:06 [kworker/8:1]</span><br><span class="line">   37 root       0:08 [kworker/4:1]</span><br><span class="line">   38 root       0:00 [kworker/0:1]</span><br><span class="line">   39 root       0:00 [ib_mcast]</span><br><span class="line">   40 root       0:00 [ib_cm]</span><br><span class="line">   41 root       0:00 [iw_cm_wq]</span><br><span class="line">   42 root       0:00 [ib_addr]</span><br><span class="line">   43 root       0:00 [rdma_cm]</span><br><span class="line">   44 root       0:00 [mthca_catas]</span><br><span class="line">   45 root       0:00 [mlx4_ib]</span><br><span class="line">   46 root       0:00 [mlx4_ib_mcg]</span><br><span class="line">   47 root       0:00 [ib_mad1]</span><br><span class="line">   48 root       0:00 [deferwq]</span><br><span class="line">   49 root       0:00 [kworker/u:1]</span><br><span class="line">   50 root       0:00 &#123;rcS&#125; /bin/sh /etc/init.d/rcS</span><br><span class="line">  120 root       0:00 /usr/sbin/telnetd</span><br><span class="line">  127 root       0:02 /usr/sw-mpp/sbin/rmsd_100p_std</span><br><span class="line">  130 root       0:00 /usr/sw-mpp/sbin/swres -c</span><br><span class="line">  135 root       0:00 sh /sbin/start_online1.sh</span><br><span class="line">  136 root       0:00 /sbin/ntpd -p *** -Nn</span><br><span class="line">  148 root       1:13 /usr/local/sbin/lwfs -f /etc/lwfs/lwfs.vol -l /dev/shm/lw</span><br><span class="line">  187 root       0:00 sh</span><br><span class="line">  197 root       0:41 /sbin/sotailf_brief -t *** -p *** /dev/shm/lwfs_onl</span><br><span class="line">  206 root       0:32 [kworker/0:2]</span><br><span class="line"> 3406 root       0:00 sleep 600</span><br><span class="line"> 3413 root       0:00 [flush-0:14]</span><br><span class="line"> 3420 root       0:00 /usr/sw-mpp/sbin/taskstarter -jobid 49200448 -rh mn005 -r</span><br><span class="line"> 3421 *       0:00 /bin/ps -ef</span><br></pre></td></tr></table></figure>
<p>顺带放出来cpuinfo和meminfo的信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cpu                     : SW_64</span><br><span class="line">cpu model               : SW5</span><br><span class="line">cpu variation           : 1</span><br><span class="line">cpu revision            : 0</span><br><span class="line">cpu serial number       :</span><br><span class="line">system type             : shenwei</span><br><span class="line">system variation        : 0</span><br><span class="line">system revision         : 0</span><br><span class="line">system serial number    :</span><br><span class="line">cycle frequency [Hz]    : 1450000000</span><br><span class="line">timer frequency [Hz]    : 0.24</span><br><span class="line">page size [bytes]       : 8192</span><br><span class="line">phys. address bits      : 44</span><br><span class="line">max. addr. space #      : 255</span><br><span class="line">BogoMIPS                : 0.81</span><br><span class="line">kernel unaligned acc    : 0 (pc=0,va=0)</span><br><span class="line">user unaligned acc      : 88465541 (pc=4ff0423298,va=5000281dcc)</span><br><span class="line">platform string         : N/A</span><br><span class="line">cpus detected           : 4</span><br><span class="line">cpus active             : 4</span><br><span class="line">cpu active mask         : 0000000000001111</span><br><span class="line">cpus core_start         : 000000000000000f</span><br><span class="line">mem cycle freq          : 500</span><br><span class="line">L1 Icache               : 64K, 2-way, 64b line</span><br><span class="line">L1 Dcache               : 64K, 2-way, 64b line</span><br><span class="line">L2 cache                : n/a</span><br><span class="line">L3 cache                : n/a</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MemTotal:        2038472 kB</span><br><span class="line">MemFree:          582544 kB</span><br><span class="line">Buffers:               0 kB</span><br><span class="line">Cached:          1199688 kB</span><br><span class="line">SwapCached:            0 kB</span><br><span class="line">Active:           830256 kB</span><br><span class="line">Inactive:         429920 kB</span><br><span class="line">Active(anon):     133568 kB</span><br><span class="line">Inactive(anon):     1120 kB</span><br><span class="line">Active(file):     696688 kB</span><br><span class="line">Inactive(file):   428800 kB</span><br><span class="line">Unevictable:       70912 kB</span><br><span class="line">Mlocked:            2904 kB</span><br><span class="line">SwapTotal:             0 kB</span><br><span class="line">SwapFree:              0 kB</span><br><span class="line">Dirty:                 0 kB</span><br><span class="line">Writeback:             0 kB</span><br><span class="line">AnonPages:        131376 kB</span><br><span class="line">Mapped:             4224 kB</span><br><span class="line">Shmem:              3888 kB</span><br><span class="line">Slab:              22480 kB</span><br><span class="line">SReclaimable:       6392 kB</span><br><span class="line">SUnreclaim:        16088 kB</span><br><span class="line">KernelStack:        1808 kB</span><br><span class="line">PageTables:          352 kB</span><br><span class="line">NFS_Unstable:          0 kB</span><br><span class="line">Bounce:                0 kB</span><br><span class="line">WritebackTmp:          0 kB</span><br><span class="line">CommitLimit:     1019232 kB</span><br><span class="line">Committed_AS:     201832 kB</span><br><span class="line">VmallocTotal:    8388608 kB</span><br><span class="line">VmallocUsed:       12208 kB</span><br><span class="line">VmallocChunk:    8376400 kB</span><br><span class="line">AnonHugePages:         0 kB</span><br><span class="line">HugePages_Total:       0</span><br><span class="line">HugePages_Free:        0</span><br><span class="line">HugePages_Rsvd:        0</span><br><span class="line">HugePages_Surp:        0</span><br><span class="line">Hugepagesize:       8192 kB</span><br><span class="line">======================= cg0 =====================</span><br><span class="line">UserPages_Mem_size:     8192 MB</span><br><span class="line">UserPages_Conti_Total:  7680 MB</span><br><span class="line">UserPages_Conti_Free:   7680 MB</span><br><span class="line">UserPages_Conti_Used:   0 MB</span><br><span class="line">UserPages_Cross_Size:   0 MB</span><br><span class="line">======================= cg1 =====================</span><br><span class="line">UserPages_Mem_size:     8192 MB</span><br><span class="line">UserPages_Conti_Total:  7680 MB</span><br><span class="line">UserPages_Conti_Free:   7680 MB</span><br><span class="line">UserPages_Conti_Used:   0 MB</span><br><span class="line">UserPages_Cross_Size:   0 MB</span><br><span class="line">======================= cg2 =====================</span><br><span class="line">UserPages_Mem_size:     8192 MB</span><br><span class="line">UserPages_Conti_Total:  7680 MB</span><br><span class="line">UserPages_Conti_Free:   7680 MB</span><br><span class="line">UserPages_Conti_Used:   0 MB</span><br><span class="line">UserPages_Cross_Size:   0 MB</span><br><span class="line">======================= cg3 =====================</span><br><span class="line">UserPages_Mem_size:     8192 MB</span><br><span class="line">UserPages_Conti_Total:  7680 MB</span><br><span class="line">UserPages_Conti_Free:   7680 MB</span><br><span class="line">UserPages_Conti_Used:   0 MB</span><br><span class="line">UserPages_Cross_Size:   0 MB</span><br></pre></td></tr></table></figure>
<h2 id="runtime相关">Runtime相关</h2>
<h3 id="从核">从核</h3>
<p>从核可以直接调用C语言的函数，这点比CUDA Kernel强不少。一个简单的测试程序，发现<code>printf</code>，<code>rand</code>，<code>memset</code>函数可以正常调用。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// host.c</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;athread.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">void</span> <span class="title">SLAVE_FUN</span><span class="params">(cpe_func)</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello world from MPE.\n&quot;</span>);</span><br><span class="line">    athread_init();</span><br><span class="line">    athread_spawn(cpe_func, <span class="literal">NULL</span>);</span><br><span class="line">    athread_join();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// slave.c</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;slave.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">cpe_func</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> thread_id;</span><br><span class="line">    thread_id = athread_get_id(<span class="number">-1</span>);</span><br><span class="line">    srand(time(<span class="literal">NULL</span>));</span><br><span class="line">    <span class="keyword">int</span> arr[<span class="number">10</span>], i;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;<span class="number">10</span>; ++i) &#123; arr[i] = rand(); &#125;</span><br><span class="line">    <span class="built_in">memset</span>(&amp;arr[<span class="number">5</span>], <span class="number">0</span>, <span class="keyword">sizeof</span>(<span class="keyword">int</span>)*<span class="number">3</span>);</span><br><span class="line">    <span class="keyword">if</span>(thread_id==<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Hello World from CPE. Generating Array:\n&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;<span class="number">10</span>; ++i) &#123; <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, arr[i]); &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="奇怪的问题">奇怪的问题</h2>
<h3 id="函数命名问题">函数命名问题</h3>
<p>函数名字不要以<code>slave_</code>开头，否则会引发<code>undefined reference to slave_slave_***</code>的错误。从核函数在编译过程中会被重命名为<code>slave_</code>加原名的函数。从编译器内置的一些宏可以看出来这点。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SLAVE_FUN(x)        slave_##x</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> athread_spawn(y,z) __real_athread_spawn(slave_##y,z)</span></span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>解决DHTMLX6窗口重叠异常的问题</title>
    <url>/2020/05/20/%E8%A7%A3%E5%86%B3DHTMLX6%E7%AA%97%E5%8F%A3%E9%87%8D%E5%8F%A0%E5%BC%82%E5%B8%B8%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>年少无知的我第一次看到酷炫的DHTMLX框架，便决定用DHTMLX写一发前端（第一次写前端），最后Chrome调试工具熟练度显著增加（？）</p>
<h2 id="问题">问题</h2>
<p>只要用上了<code>DHTMLX</code>的<code>Window</code>组件，不管是跟<code>DHX Suite</code>的其他组件组合，还是跟<code>DHX</code>家的其他库组合，都能出现各种各样的问题，其中最为常见的问题就是本来应该浮于组件上方的组件反而衬于组件的下方。</p>
<h2 id="解决方案">解决方案</h2>
<p>先介绍几个神奇的API</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">dhxWindow._handlers.setActive(); <span class="comment">// 激活Window窗口</span></span><br><span class="line">form.getItem(<span class="string">&quot;component-id&quot;</span>)._popup._popup.classList.add(<span class="string">&quot;dhx_popup--window_active&quot;</span>); <span class="comment">// 激活组件窗口</span></span><br></pre></td></tr></table></figure>
<p>我遇到的第一种问题，新建的窗口未被正确激活，显示在旧窗口下方，这个时候可以这么写</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">  dhxWindow.show();</span><br><span class="line">  dhxWindow._handlers.setActive();</span><br><span class="line">&#125;, <span class="number">100</span>);</span><br></pre></td></tr></table></figure>
<p>这里延迟100ms启动是因为，这个bug偶尔会出现在点击按钮创建窗口的时候，等待100ms其实是等待用户释放鼠标。</p>
<p>我遇到的第二种问题是，<code>Window</code>套<code>Form</code>套<code>Datepicker</code>，在同时有多个<code>Window</code>的情况下，<code>Datepicker</code>的日历出现在<code>Window</code>下方（能100%复现的bug），这个时候只要"激活"<code>Datepicker</code>的日历就好了。比如</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> form = <span class="keyword">new</span> dhx.Form(<span class="literal">null</span>, &#123;</span><br><span class="line">    <span class="attr">css</span>: <span class="string">&quot;dhx_widget--no-bordered&quot;</span>,</span><br><span class="line">    <span class="attr">rows</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">id</span>: <span class="string">&quot;iamid&quot;</span>,</span><br><span class="line">            <span class="attr">type</span>: <span class="string">&quot;datepicker&quot;</span>,</span><br><span class="line">            <span class="attr">name</span>: <span class="string">&quot;date&quot;</span>,</span><br><span class="line">            <span class="attr">gravity</span>: <span class="literal">true</span>,</span><br><span class="line">            <span class="attr">value</span>: <span class="string">&quot;2020-05-01&quot;</span>,</span><br><span class="line">            <span class="attr">dateFormat</span>: <span class="string">&quot;%Y-%m-%d&quot;</span>,</span><br><span class="line">            <span class="attr">label</span>: <span class="string">&quot;开行日期&quot;</span>,</span><br><span class="line">            <span class="attr">labelInline</span>: <span class="literal">true</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">    ]</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">form.getItem(<span class="string">&quot;iamid&quot;</span>)._popup._popup.classList.add(<span class="string">&quot;dhx_popup--window_active&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>这样就可以让日历正确显示了。</p>
<h2 id="分析">分析</h2>
<p><code>DHTMLX</code>框架是也是通过<code>CSS</code>的<code>z-index</code>来确定窗口的层次的，上面涉及到的两个神奇API干的都是同一件事情，添加内置<code>z-index</code>的<code>style</code> (<code>dhx_popup--window_active</code>)到组件上，实现激活窗口的效果。但是<code>DHX</code>那群nt工程师压根就没给<code>datepicker</code>之类的组件写自动添加<code>dhx_popup--window_active</code>的代码，至于<code>Window</code>组件，自动添加的代码有是有，就是有bug。</p>
<h2 id="牢骚">牢骚</h2>
<p><code>DHX</code>的库bug多也就算了，官网上放着的文档也是有一堆bug的假文档，作为一个历史悠久，功能酷炫，但没人用的库，是不是该考虑为什么过了那么多年自己还是那么冷门啊。</p>
]]></content>
  </entry>
  <entry>
    <title>配置WSL的SSH X11 Forwarding</title>
    <url>/2021/01/23/%E9%85%8D%E7%BD%AEWSL%E7%9A%84SSH-X11-Forwarding/</url>
    <content><![CDATA[<p>我最喜欢SSH的一个功能就是X11 Forwarding，可以把远程服务器的图形界面转发到本地的X11 Server上，然而WSL并不原生支持这个功能（因为Windows里没有原生的X11 Server）。但是其实稍加配置，其实WSL的SSH可以比较好的支持X11 Forwarding。（Chrome OS什么都不需要配置，yyds！）</p>
<h2 id="准备windows的x11-server">准备Windows的X11 Server</h2>
<p>我个人喜欢的是<code>VcXsrv</code>这个X11 Server，可以在<a href="https://sourceforge.net/projects/vcxsrv/">这里</a>下载它的安装包。</p>
<p>安装好以后，打开桌面上的<code>XLaunch</code>，然后选择<code>Multiple windows</code>-&gt;<code>Start no client</code>-&gt;勾选<code>Disable access control</code>-&gt;<code>Save Configuration</code>保存一下设置，方便以后使用-&gt;<code>Finish</code>。</p>
<h2 id="配置wsl的环境变量">配置WSL的环境变量</h2>
<p>编辑WSL的<code>~/.bashrc</code>文件，在文件末尾写入以下内容，注意仅仅<code>export DISPLAY=0.0</code>是不行的。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> DISPLAY=localhost:0.0</span><br></pre></td></tr></table></figure>
<p>然后通过<code>source ~/.bashrc</code>，或者打开新终端载入新配置。enjoy it！</p>
<figure>
<img data-src="/images/pasted-62.png" alt="upload successful" /><figcaption>upload successful</figcaption>
</figure>
<h2 id="参考文章">参考文章</h2>
<ul>
<li><a href="https://superuser.com/questions/1332709/setting-up-x11-forwarding-over-ssh-on-windows-10-subsystem-for-linux">https://superuser.com/questions/1332709/setting-up-x11-forwarding-over-ssh-on-windows-10-subsystem-for-linux</a></li>
<li><a href="https://ddadaal.me/articles/run-gui-on-wsl2-with-x11-forwarding">https://ddadaal.me/articles/run-gui-on-wsl2-with-x11-forwarding</a></li>
</ul>
]]></content>
  </entry>
</search>
